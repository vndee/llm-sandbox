{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LLM Sandbox Documentation","text":""},{"location":"#welcome-to-llm-sandbox","title":"Welcome to LLM Sandbox","text":"<p>LLM Sandbox is a lightweight and portable sandbox environment designed to run Large Language Model (LLM) generated code in a safe and isolated mode. It provides a secure execution environment for AI-generated code while offering flexibility in container backends and comprehensive language support.</p> <ul> <li> <p> Secure Execution</p> <p>Run untrusted LLM-generated code safely with customizable security policies and isolated container environments</p> <p> Security guide</p> </li> <li> <p> Multiple Backends</p> <p>Choose from Docker, Kubernetes, or Podman backends based on your infrastructure needs</p> <p> Backend options</p> </li> <li> <p> Multi-Language</p> <p>Execute code in Python, JavaScript, Java, C++, and Go with automatic dependency management</p> <p> Language guide</p> </li> <li> <p> LLM Integration</p> <p>Seamlessly integrate with LangChain, LangGraph, and LlamaIndex for AI-powered applications</p> <p> Integrations</p> </li> <li> <p> MCP Server</p> <p>Model Context Protocol server for AI assistants like Claude Desktop to execute code securely</p> <p> MCP Integration</p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#security-first","title":"\ud83d\udee1\ufe0f Security First","text":"<ul> <li>Isolated Execution: Code runs in isolated containers with no access to host system</li> <li>Security Policies: Define custom security policies to control code execution</li> <li>Resource Limits: Set CPU, memory, and execution time limits</li> <li>Network Isolation: Control network access for sandboxed code</li> </ul>"},{"location":"#flexible-container-backends","title":"\ud83d\ude80 Flexible Container Backends","text":"<ul> <li>Docker: Most popular and widely supported option</li> <li>Kubernetes: Enterprise-grade orchestration for scalable deployments</li> <li>Podman: Rootless containers for enhanced security</li> </ul>"},{"location":"#advanced-features","title":"\ud83d\udcca Advanced Features","text":"<ul> <li>Artifact Extraction: Automatically capture plots and visualizations</li> <li>Library Management: Install dependencies on-the-fly</li> <li>File Operations: Copy files to/from sandbox environments</li> <li>Custom Images: Use your own container images</li> <li>MCP Server: Model Context Protocol integration for AI assistants</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># ruff: noqa: T201\n\nimport base64\nfrom pathlib import Path\n\nfrom llm_sandbox import ArtifactSandboxSession\n\ncode = \"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.style.use('default')\n\n# Generate data\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x) + np.random.normal(0, 0.1, 100)\ny2 = np.cos(x) + np.random.normal(0, 0.1, 100)\n\n# Create plot\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes[0, 0].plot(x, y1, 'b-', alpha=0.7)\naxes[0, 0].set_title('Sine Wave')\naxes[0, 1].scatter(x[::5], y2[::5], c='red', alpha=0.6)\naxes[0, 1].set_title('Cosine Scatter')\naxes[1, 0].hist(y1, bins=20, alpha=0.7, color='green')\naxes[1, 0].set_title('Sine Distribution')\naxes[1, 1].bar(range(10), np.random.rand(10), alpha=0.7)\naxes[1, 1].set_title('Random Bar Chart')\nplt.tight_layout()\nplt.show()\n\nprint('Plot generated successfully!')\n\"\"\"\n\n# Create a sandbox session\nwith ArtifactSandboxSession(lang=\"python\", verbose=True) as session:\n    # Run Python code safely\n    result = session.run(code)\n\n    print(result.stdout)  # Output: Plot generated successfully!\n\n    for plot in result.plots:\n        with Path(\"docs/assets/example.png\").open(\"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre>"},{"location":"#installation","title":"Installation","text":""},{"location":"#basic-installation","title":"Basic Installation","text":"<pre><code>pip install llm-sandbox\n</code></pre>"},{"location":"#with-specific-backend","title":"With Specific Backend","text":"<pre><code># For Docker support\npip install 'llm-sandbox[docker]'\n\n# For Kubernetes support\npip install 'llm-sandbox[k8s]'\n\n# For Podman support\npip install 'llm-sandbox[podman]'\n</code></pre>"},{"location":"#why-llm-sandbox","title":"Why LLM Sandbox?","text":""},{"location":"#the-challenge","title":"The Challenge","text":"<p>As LLMs become more capable at generating code, there's an increasing need to execute this code safely. Running untrusted code poses significant security risks:</p> <ul> <li>System compromise through malicious commands</li> <li>Data exfiltration via network access</li> <li>Resource exhaustion from infinite loops</li> <li>File system damage from destructive operations</li> </ul>"},{"location":"#our-solution","title":"Our Solution","text":"<p>LLM Sandbox provides a secure, isolated environment that:</p> <ol> <li>Isolates code execution in containers</li> <li>Enforces security policies before execution</li> <li>Limits resource usage to prevent abuse</li> <li>Integrates seamlessly with LLM frameworks</li> </ol>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TD\n    A[LLM Application] --&gt;|Generated Code| B[LLM Sandbox]\n    A1[MCP Clients] --&gt;|MCP Protocol| B\n    B --&gt; C{Security Check}\n    C --&gt;|Pass| D[Container Backend]\n    C --&gt;|Fail| E[Reject Execution]\n    D --&gt; F[Docker]\n    D --&gt; G[Kubernetes]\n    D --&gt; H[Podman]\n    F --&gt; J[Isolated Execution]\n    G --&gt; J\n    H --&gt; J\n    J --&gt; K[Results &amp; Artifacts]\n    K --&gt; A\n    K --&gt; A1\n\n    A1 --&gt; L[Claude Desktop]\n    A1 --&gt; M[Other MCP Clients]</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to start using LLM Sandbox? Check out our Getting Started Guide for detailed setup instructions and your first sandbox session.</p>"},{"location":"#documentation-overview","title":"Documentation Overview","text":"<ul> <li>Getting Started - Installation and basic usage</li> <li>Configuration - Detailed configuration options</li> <li>Security - Security policies and best practices</li> <li>Backends - Container backend details</li> <li>Languages - Supported programming languages</li> <li>Integrations - LLM framework integrations</li> <li>MCP Integration - Model Context Protocol server setup and usage</li> <li>Existing Container Support - Connecting to existing containers/pods</li> <li>API Reference - Complete API documentation</li> <li>Examples - Real-world usage examples</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub: github.com/vndee/llm-sandbox</li> <li>Issues: Report bugs or request features</li> <li>Discussions: Join the community</li> <li>PyPI: pypi.org/project/llm-sandbox</li> </ul>"},{"location":"#license","title":"License","text":"<p>LLM Sandbox is open source software licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Comprehensive API documentation for LLM Sandbox.</p>"},{"location":"api-reference/#core-classes","title":"Core Classes","text":""},{"location":"api-reference/#sandboxsession","title":"SandboxSession","text":""},{"location":"api-reference/#llm_sandbox.SandboxSession","title":"SandboxSession  <code>module-attribute</code>","text":"<pre><code>SandboxSession = create_session\n</code></pre>"},{"location":"api-reference/#artifactsandboxsession","title":"ArtifactSandboxSession","text":""},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession","title":"ArtifactSandboxSession","text":"<pre><code>ArtifactSandboxSession(\n    backend: SandboxBackend = SandboxBackend.DOCKER,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    *,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str | None = \"/sandbox\",\n    enable_plotting: bool = True,\n    security_policy: SecurityPolicy | None = None,\n    container_id: str | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Sandbox session with artifact extraction capabilities.</p> <p>Create a new artifact sandbox session.</p> <p>The ArtifactSandboxSession provides a secure environment for running code that generates artifacts like plots, images, or other files. It supports multiple container backends (Docker, Kubernetes, Podman) and can capture and extract artifacts from the execution.</p> PARAMETER DESCRIPTION <code>backend</code> <p>Container backend to use (Docker, Kubernetes or Podman)</p> <p> TYPE: <code>SandboxBackend</code> DEFAULT: <code>DOCKER</code> </p> <code>image</code> <p>Container image to use (e.g., \"vndee/sandbox-python-311-bullseye\")</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>dockerfile</code> <p>Path to Dockerfile</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>lang</code> <p>Programming language (e.g., \"python\")</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYTHON</code> </p> <code>keep_template</code> <p>Whether to keep the container template</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>commit_container</code> <p>Whether to commit container changes</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>Enable verbose logging</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>runtime_configs</code> <p>Additional runtime configurations</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>workdir</code> <p>Working directory inside the container</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/sandbox'</code> </p> <code>enable_plotting</code> <p>Whether to enable plot extraction</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>security_policy</code> <p>Security policy to enforce</p> <p> TYPE: <code>SecurityPolicy</code> DEFAULT: <code>None</code> </p> <code>container_id</code> <p>ID of existing container/pod to connect to</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional keyword arguments for specific backends (e.g., client for Podman)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>MissingDependencyError</code> <p>If the required dependency for the chosen backend is not installed</p> <code>UnsupportedBackendError</code> <p>If the chosen backend is not supported</p> <p>Examples:</p> <p>Connect to existing container for artifact generation: <pre><code>from llm_sandbox import ArtifactSandboxSession, SandboxBackend\nfrom pathlib import Path\nimport base64\n\n# Connect to existing container\nwith ArtifactSandboxSession(\n    container_id='existing-container-id',\n    lang=\"python\",\n    verbose=True,\n    backend=SandboxBackend.DOCKER\n) as session:\n    # Code that generates plots in existing environment\n    code = '''\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Generate and plot data\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n\n    plt.figure()\n    plt.plot(x, y)\n    plt.title('Plot from Existing Container')\n    plt.show()\n    '''\n\n    result = session.run(code)\n    print(f\"Captured {len(result.plots)} plots\")\n\n    # Save captured plots\n    for i, plot in enumerate(result.plots):\n        plot_path = Path(\"plots\") / f\"existing_{i + 1:06d}.{plot.format.value}\"\n        with plot_path.open(\"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre></p> <p>Basic usage with Docker backend: <pre><code>from llm_sandbox import ArtifactSandboxSession, SandboxBackend\nfrom pathlib import Path\nimport base64\n\n# Create plots directory\nPath(\"plots/docker\").mkdir(parents=True, exist_ok=True)\n\n# Run code that generates plots\nwith ArtifactSandboxSession(\n    lang=\"python\",\n    verbose=True,\n    image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n    backend=SandboxBackend.DOCKER\n) as session:\n    # Example code that generates matplotlib, seaborn, and plotly plots\n    code = '''\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Generate and plot data\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n\n    plt.figure()\n    plt.plot(x, y)\n    plt.title('Simple Sine Wave')\n    plt.show()\n    '''\n\n    result = session.run(code)\n    print(f\"Captured {len(result.plots)} plots\")\n\n    # Save captured plots\n    for i, plot in enumerate(result.plots):\n        plot_path = Path(\"plots/docker\") / f\"{i + 1:06d}.{plot.format.value}\"\n        with plot_path.open(\"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre> Using Podman backend: <pre><code>from podman import PodmanClient\n\n# Initialize Podman client\npodman_client = PodmanClient(base_url=\"unix:///path/to/podman.sock\")\n\nwith ArtifactSandboxSession(\n    client=podman_client,  # Podman specific\n    lang=\"python\",\n    verbose=True,\n    image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n    backend=SandboxBackend.PODMAN\n) as session:\n    result = session.run(code)\n</code></pre></p> <p>Using Kubernetes backend: <pre><code>with ArtifactSandboxSession(\n    lang=\"python\",\n    verbose=True,\n    image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n    backend=SandboxBackend.KUBERNETES\n) as session:\n    result = session.run(code)\n</code></pre></p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def __init__(\n    self,\n    backend: SandboxBackend = SandboxBackend.DOCKER,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    *,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str | None = \"/sandbox\",\n    enable_plotting: bool = True,\n    security_policy: SecurityPolicy | None = None,\n    container_id: str | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create a new artifact sandbox session.\n\n    The ArtifactSandboxSession provides a secure environment for running code that generates artifacts\n    like plots, images, or other files. It supports multiple container backends (Docker, Kubernetes, Podman)\n    and can capture and extract artifacts from the execution.\n\n    Args:\n        backend (SandboxBackend): Container backend to use (Docker, Kubernetes or Podman)\n        image (str): Container image to use (e.g., \"vndee/sandbox-python-311-bullseye\")\n        dockerfile (str, optional): Path to Dockerfile\n        lang (str): Programming language (e.g., \"python\")\n        keep_template (bool, optional): Whether to keep the container template\n        commit_container (bool, optional): Whether to commit container changes\n        verbose (bool, optional): Enable verbose logging\n        runtime_configs (dict, optional): Additional runtime configurations\n        workdir (str, optional): Working directory inside the container\n        enable_plotting (bool, optional): Whether to enable plot extraction\n        security_policy (SecurityPolicy, optional): Security policy to enforce\n        container_id (str, optional): ID of existing container/pod to connect to\n        **kwargs: Additional keyword arguments for specific backends (e.g., client for Podman)\n\n    Raises:\n        MissingDependencyError: If the required dependency for the chosen backend is not installed\n        UnsupportedBackendError: If the chosen backend is not supported\n\n    Examples:\n        Connect to existing container for artifact generation:\n        ```python\n        from llm_sandbox import ArtifactSandboxSession, SandboxBackend\n        from pathlib import Path\n        import base64\n\n        # Connect to existing container\n        with ArtifactSandboxSession(\n            container_id='existing-container-id',\n            lang=\"python\",\n            verbose=True,\n            backend=SandboxBackend.DOCKER\n        ) as session:\n            # Code that generates plots in existing environment\n            code = '''\n            import matplotlib.pyplot as plt\n            import numpy as np\n\n            # Generate and plot data\n            x = np.linspace(0, 10, 100)\n            y = np.sin(x)\n\n            plt.figure()\n            plt.plot(x, y)\n            plt.title('Plot from Existing Container')\n            plt.show()\n            '''\n\n            result = session.run(code)\n            print(f\"Captured {len(result.plots)} plots\")\n\n            # Save captured plots\n            for i, plot in enumerate(result.plots):\n                plot_path = Path(\"plots\") / f\"existing_{i + 1:06d}.{plot.format.value}\"\n                with plot_path.open(\"wb\") as f:\n                    f.write(base64.b64decode(plot.content_base64))\n        ```\n\n        Basic usage with Docker backend:\n        ```python\n        from llm_sandbox import ArtifactSandboxSession, SandboxBackend\n        from pathlib import Path\n        import base64\n\n        # Create plots directory\n        Path(\"plots/docker\").mkdir(parents=True, exist_ok=True)\n\n        # Run code that generates plots\n        with ArtifactSandboxSession(\n            lang=\"python\",\n            verbose=True,\n            image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n            backend=SandboxBackend.DOCKER\n        ) as session:\n            # Example code that generates matplotlib, seaborn, and plotly plots\n            code = '''\n            import matplotlib.pyplot as plt\n            import numpy as np\n\n            # Generate and plot data\n            x = np.linspace(0, 10, 100)\n            y = np.sin(x)\n\n            plt.figure()\n            plt.plot(x, y)\n            plt.title('Simple Sine Wave')\n            plt.show()\n            '''\n\n            result = session.run(code)\n            print(f\"Captured {len(result.plots)} plots\")\n\n            # Save captured plots\n            for i, plot in enumerate(result.plots):\n                plot_path = Path(\"plots/docker\") / f\"{i + 1:06d}.{plot.format.value}\"\n                with plot_path.open(\"wb\") as f:\n                    f.write(base64.b64decode(plot.content_base64))\n        ```\n        Using Podman backend:\n        ```python\n        from podman import PodmanClient\n\n        # Initialize Podman client\n        podman_client = PodmanClient(base_url=\"unix:///path/to/podman.sock\")\n\n        with ArtifactSandboxSession(\n            client=podman_client,  # Podman specific\n            lang=\"python\",\n            verbose=True,\n            image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n            backend=SandboxBackend.PODMAN\n        ) as session:\n            result = session.run(code)\n        ```\n\n        Using Kubernetes backend:\n        ```python\n        with ArtifactSandboxSession(\n            lang=\"python\",\n            verbose=True,\n            image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n            backend=SandboxBackend.KUBERNETES\n        ) as session:\n            result = session.run(code)\n        ```\n\n    \"\"\"\n    # Create the base session\n    self._session: BaseSession = create_session(\n        backend=backend,\n        image=image,\n        dockerfile=dockerfile,\n        lang=lang,\n        keep_template=keep_template,\n        commit_container=commit_container,\n        verbose=verbose,\n        runtime_configs=runtime_configs,\n        workdir=workdir,\n        security_policy=security_policy,\n        container_id=container_id,\n        **kwargs,\n    )\n\n    self.enable_plotting = enable_plotting\n</code></pre>"},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession.__enter__","title":"__enter__","text":"<pre><code>__enter__() -&gt; ArtifactSandboxSession\n</code></pre> <p>Enter the context manager.</p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def __enter__(self) -&gt; \"ArtifactSandboxSession\":\n    \"\"\"Enter the context manager.\"\"\"\n    self._session.__enter__()\n    return self\n</code></pre>"},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession.__exit__","title":"__exit__","text":"<pre><code>__exit__(\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None\n</code></pre> <p>Exit the context manager.</p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None:\n    \"\"\"Exit the context manager.\"\"\"\n    return self._session.__exit__(exc_type, exc_val, exc_tb)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name: str) -&gt; Any\n</code></pre> <p>Delegate any other attributes/methods to the underlying session.</p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def __getattr__(self, name: str) -&gt; Any:\n    \"\"\"Delegate any other attributes/methods to the underlying session.\"\"\"\n    return getattr(self._session, name)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.session.ArtifactSandboxSession.run","title":"run","text":"<pre><code>run(code: str, libraries: list | None = None, timeout: int = 30) -&gt; ExecutionResult\n</code></pre> <p>Run code in the sandbox session and extract any generated artifacts.</p> <p>This method executes the provided code in an isolated environment and captures any generated artifacts (e.g., plots, figures). When plotting is enabled, it delegates to the language handler's run_with_artifacts method for language-specific artifact extraction.</p> PARAMETER DESCRIPTION <code>code</code> <p>The code to execute. Can include plotting commands from matplotlib,         seaborn, plotly, or other visualization libraries.</p> <p> TYPE: <code>str</code> </p> <code>libraries</code> <p>Additional libraries to install before running                                 the code. Defaults to None.</p> <p> TYPE: <code>list | None</code> DEFAULT: <code>None</code> </p> <code>timeout</code> <p>Timeout in seconds for the code execution. Defaults to 30.</p> <p> TYPE: <code>int</code> DEFAULT: <code>30</code> </p> RETURNS DESCRIPTION <code>ExecutionResult</code> <p>An object containing: - exit_code (int): The exit code of the execution - stdout (str): Standard output from the code execution - stderr (str): Standard error from the code execution - plots (list[Plot]): List of captured plots, each containing:     - content_base64 (str): Base64 encoded plot data     - format (PlotFormat): Format of the plot (e.g., 'png', 'svg')</p> <p> TYPE: <code>ExecutionResult</code> </p> RAISES DESCRIPTION <code>LanguageNotSupportPlotError</code> <p>If the language does not support plot detection</p> <p>Examples:</p> <p>Basic plotting example: <pre><code>with ArtifactSandboxSession(\n    lang=\"python\",\n    verbose=True,\n    image=\"ghcr.io/vndee/sandbox-python-311-bullseye\"\n) as session:\n    code = '''\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n    plt.plot(x, y)\n    plt.title('Sine Wave')\n    plt.show()\n    '''\n    result = session.run(code)\n    print(f\"Generated {len(result.plots)} plots\")\n</code></pre></p> <p>Multiple plot types and libraries: <pre><code>code = '''\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\n\n# Matplotlib plot\nplt.figure(figsize=(10, 6))\nx = np.linspace(0, 10, 100)\nplt.plot(x, np.sin(x))\nplt.title('Matplotlib: Sine Wave')\nplt.show()\n\n# Seaborn plot\ndata = pd.DataFrame({\n    'x': np.random.randn(100),\n    'y': np.random.randn(100)\n})\nsns.scatterplot(data=data, x='x', y='y')\nplt.title('Seaborn: Scatter Plot')\nplt.show()\n\n# Plotly plot\nfig = px.line(data, x='x', y='y', title='Plotly: Line Plot')\nfig.show()\n'''\n\nresult = session.run(code, libraries=['plotly'])\n\n# Save the generated plots\nfor i, plot in enumerate(result.plots):\n    with open(f'plot_{i}.{plot.format.value}', 'wb') as f:\n        f.write(base64.b64decode(plot.content_base64))\n</code></pre></p> <p>Installing additional libraries: <pre><code>code = '''\nimport torch\nimport torch.nn as nn\nprint(f\"PyTorch version: {torch.__version__}\")\n'''\n\nresult = session.run(code, libraries=['torch'])\nprint(result.stdout)\n</code></pre></p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def run(\n    self,\n    code: str,\n    libraries: list | None = None,\n    timeout: int = 30,\n) -&gt; ExecutionResult:\n    \"\"\"Run code in the sandbox session and extract any generated artifacts.\n\n    This method executes the provided code in an isolated environment and captures any\n    generated artifacts (e.g., plots, figures). When plotting is enabled, it delegates\n    to the language handler's run_with_artifacts method for language-specific artifact\n    extraction.\n\n    Args:\n        code (str): The code to execute. Can include plotting commands from matplotlib,\n                    seaborn, plotly, or other visualization libraries.\n        libraries (list | None, optional): Additional libraries to install before running\n                                            the code. Defaults to None.\n        timeout (int, optional): Timeout in seconds for the code execution. Defaults to 30.\n\n    Returns:\n        ExecutionResult: An object containing:\n            - exit_code (int): The exit code of the execution\n            - stdout (str): Standard output from the code execution\n            - stderr (str): Standard error from the code execution\n            - plots (list[Plot]): List of captured plots, each containing:\n                - content_base64 (str): Base64 encoded plot data\n                - format (PlotFormat): Format of the plot (e.g., 'png', 'svg')\n\n    Raises:\n        LanguageNotSupportPlotError: If the language does not support plot detection\n\n    Examples:\n        Basic plotting example:\n        ```python\n        with ArtifactSandboxSession(\n            lang=\"python\",\n            verbose=True,\n            image=\"ghcr.io/vndee/sandbox-python-311-bullseye\"\n        ) as session:\n            code = '''\n            import matplotlib.pyplot as plt\n            import numpy as np\n\n            x = np.linspace(0, 10, 100)\n            y = np.sin(x)\n            plt.plot(x, y)\n            plt.title('Sine Wave')\n            plt.show()\n            '''\n            result = session.run(code)\n            print(f\"Generated {len(result.plots)} plots\")\n        ```\n\n        Multiple plot types and libraries:\n        ```python\n        code = '''\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        import plotly.express as px\n        import pandas as pd\n        import numpy as np\n\n        # Matplotlib plot\n        plt.figure(figsize=(10, 6))\n        x = np.linspace(0, 10, 100)\n        plt.plot(x, np.sin(x))\n        plt.title('Matplotlib: Sine Wave')\n        plt.show()\n\n        # Seaborn plot\n        data = pd.DataFrame({\n            'x': np.random.randn(100),\n            'y': np.random.randn(100)\n        })\n        sns.scatterplot(data=data, x='x', y='y')\n        plt.title('Seaborn: Scatter Plot')\n        plt.show()\n\n        # Plotly plot\n        fig = px.line(data, x='x', y='y', title='Plotly: Line Plot')\n        fig.show()\n        '''\n\n        result = session.run(code, libraries=['plotly'])\n\n        # Save the generated plots\n        for i, plot in enumerate(result.plots):\n            with open(f'plot_{i}.{plot.format.value}', 'wb') as f:\n                f.write(base64.b64decode(plot.content_base64))\n        ```\n\n        Installing additional libraries:\n        ```python\n        code = '''\n        import torch\n        import torch.nn as nn\n        print(f\"PyTorch version: {torch.__version__}\")\n        '''\n\n        result = session.run(code, libraries=['torch'])\n        print(result.stdout)\n        ```\n\n    \"\"\"\n    # Check if plotting is enabled and language supports it\n    if self.enable_plotting and not self._session.language_handler.is_support_plot_detection:\n        raise LanguageNotSupportPlotError(self._session.language_handler.name)\n\n    # Delegate to language handler for language-specific artifact extraction\n    result, plots = self._session.language_handler.run_with_artifacts(\n        container=self._session,  # type: ignore[arg-type]\n        code=code,\n        libraries=libraries,\n        enable_plotting=self.enable_plotting,\n        output_dir=\"/tmp/sandbox_plots\",\n        timeout=timeout,\n    )\n\n    return ExecutionResult(\n        exit_code=result.exit_code,\n        stdout=result.stdout,\n        stderr=result.stderr,\n        plots=plots,\n    )\n</code></pre>"},{"location":"api-reference/#data-classes","title":"Data Classes","text":""},{"location":"api-reference/#consoleoutput","title":"ConsoleOutput","text":""},{"location":"api-reference/#llm_sandbox.data.ConsoleOutput","title":"ConsoleOutput  <code>dataclass</code>","text":"<pre><code>ConsoleOutput(exit_code: int = 0, stderr: str = '', stdout: str = '')\n</code></pre> <p>Represents the standard output and standard error from code execution or a command.</p> ATTRIBUTE DESCRIPTION <code>exit_code</code> <p>The exit code of the executed code or command. 0 typically indicates success.</p> <p> TYPE: <code>int</code> </p> <code>stderr</code> <p>The content written to the standard error stream.</p> <p> TYPE: <code>str</code> </p> <code>stdout</code> <p>The content written to the standard output stream.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api-reference/#llm_sandbox.data.ConsoleOutput-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.data.ConsoleOutput.success","title":"success","text":"<pre><code>success() -&gt; bool\n</code></pre> <p>Check if the execution was successful (exit code is 0).</p> RETURNS DESCRIPTION <code>bool</code> <p>True if <code>exit_code</code> is 0, False otherwise.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>llm_sandbox/data.py</code> <pre><code>def success(self) -&gt; bool:\n    r\"\"\"Check if the execution was successful (exit code is 0).\n\n    Returns:\n        bool: True if `exit_code` is 0, False otherwise.\n\n    \"\"\"\n    return not self.exit_code\n</code></pre>"},{"location":"api-reference/#llm_sandbox.data.ConsoleOutput.text","title":"text","text":"<pre><code>text() -&gt; str\n</code></pre> <p>Get the text representation of the console output (stdout).</p> <p>.. deprecated:: 0.1.0     The <code>text</code> property is deprecated and will be removed in a future version.     Use the <code>stdout</code> attribute directly instead.</p> RETURNS DESCRIPTION <code>str</code> <p>The content of the standard output stream.</p> <p> TYPE: <code>str</code> </p> Source code in <code>llm_sandbox/data.py</code> <pre><code>def text(self) -&gt; str:\n    r\"\"\"Get the text representation of the console output (stdout).\n\n    .. deprecated:: 0.1.0\n        The `text` property is deprecated and will be removed in a future version.\n        Use the `stdout` attribute directly instead.\n\n    Returns:\n        str: The content of the standard output stream.\n\n    \"\"\"\n    warnings.warn(\n        \"The 'text' property is deprecated and will be removed in a future version. \"\n        \"Use 'stdout' attribute directly instead.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return self.stdout\n</code></pre>"},{"location":"api-reference/#llm_sandbox.data.ConsoleOutput.to_json","title":"to_json","text":"<pre><code>to_json(include_plots: bool = False) -&gt; str\n</code></pre> <p>Get the JSON representation of the execution result.</p> PARAMETER DESCRIPTION <code>include_plots</code> <p>Whether to include the plots in the JSON representation.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The JSON representation of the execution result.</p> <p> TYPE: <code>str</code> </p> Source code in <code>llm_sandbox/data.py</code> <pre><code>def to_json(self, include_plots: bool = False) -&gt; str:\n    r\"\"\"Get the JSON representation of the execution result.\n\n    Args:\n        include_plots (bool): Whether to include the plots in the JSON representation.\n\n    Returns:\n        str: The JSON representation of the execution result.\n\n    \"\"\"\n    result = self.__dict__.copy()\n    if not include_plots and \"plots\" in result:\n        result.pop(\"plots\", None)\n\n    return json.dumps(result, indent=2)\n</code></pre>"},{"location":"api-reference/#executionresult","title":"ExecutionResult","text":""},{"location":"api-reference/#llm_sandbox.data.ExecutionResult","title":"ExecutionResult  <code>dataclass</code>","text":"<pre><code>ExecutionResult(\n    exit_code: int = 0, stderr: str = \"\", stdout: str = \"\", plots: list[PlotOutput] = list()\n)\n</code></pre> <p>               Bases: <code>ConsoleOutput</code></p> <p>Represents the comprehensive result of code execution within a sandbox session.</p> <p>This class extends <code>ConsoleOutput</code> to include any plots or other file artifacts that were generated and captured during the execution.</p> ATTRIBUTE DESCRIPTION <code>plots</code> <p>A list of <code>PlotOutput</code> objects, each representing a                         captured plot or visual artifact. Defaults to an empty list.</p> <p> TYPE: <code>list[PlotOutput]</code> </p>"},{"location":"api-reference/#plotoutput","title":"PlotOutput","text":""},{"location":"api-reference/#llm_sandbox.data.PlotOutput","title":"PlotOutput  <code>dataclass</code>","text":"<pre><code>PlotOutput(\n    format: FileType,\n    content_base64: str,\n    width: int | None = None,\n    height: int | None = None,\n    dpi: int | None = None,\n)\n</code></pre> <p>Represents a plot, chart, or other visual artifact output from code execution.</p> ATTRIBUTE DESCRIPTION <code>format</code> <p>The format of the plot (e.g., PNG, SVG, PDF).</p> <p> TYPE: <code>FileType</code> </p> <code>content_base64</code> <p>The raw content of the plot, base64 encoded.</p> <p> TYPE: <code>str</code> </p> <code>width</code> <p>The width of the plot in pixels. Defaults to None.</p> <p> TYPE: <code>int | None</code> </p> <code>height</code> <p>The height of the plot in pixels. Defaults to None.</p> <p> TYPE: <code>int | None</code> </p> <code>dpi</code> <p>The dots per inch (resolution) of the plot. Defaults to None.</p> <p> TYPE: <code>int | None</code> </p>"},{"location":"api-reference/#security-classes","title":"Security Classes","text":""},{"location":"api-reference/#securitypolicy","title":"SecurityPolicy","text":""},{"location":"api-reference/#llm_sandbox.security.SecurityPolicy","title":"SecurityPolicy","text":"<p>               Bases: <code>BaseModel</code></p> <p>A security policy.</p>"},{"location":"api-reference/#llm_sandbox.security.SecurityPolicy-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.security.SecurityPolicy.add_pattern","title":"add_pattern","text":"<pre><code>add_pattern(pattern: SecurityPattern) -&gt; None\n</code></pre> <p>Add a security pattern to the policy.</p> Source code in <code>llm_sandbox/security.py</code> <pre><code>def add_pattern(self, pattern: SecurityPattern) -&gt; None:\n    \"\"\"Add a security pattern to the policy.\"\"\"\n    if self.patterns is None:\n        self.patterns = []\n    self.patterns.append(pattern)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.security.SecurityPolicy.add_restricted_module","title":"add_restricted_module","text":"<pre><code>add_restricted_module(module: RestrictedModule) -&gt; None\n</code></pre> <p>Add a restricted module to the policy.</p> Source code in <code>llm_sandbox/security.py</code> <pre><code>def add_restricted_module(self, module: RestrictedModule) -&gt; None:\n    \"\"\"Add a restricted module to the policy.\"\"\"\n    if self.restricted_modules is None:\n        self.restricted_modules = []\n    self.restricted_modules.append(module)\n</code></pre>"},{"location":"api-reference/#securitypattern","title":"SecurityPattern","text":""},{"location":"api-reference/#llm_sandbox.security.SecurityPattern","title":"SecurityPattern","text":"<p>               Bases: <code>BaseModel</code></p> <p>A security pattern.</p>"},{"location":"api-reference/#llm_sandbox.security.SecurityPattern-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.security.SecurityPattern.validate_pattern","title":"validate_pattern  <code>classmethod</code>","text":"<pre><code>validate_pattern(v: str) -&gt; str\n</code></pre> <p>Validate that the pattern is a valid regex pattern.</p> Source code in <code>llm_sandbox/security.py</code> <pre><code>@field_validator(\"pattern\")\n@classmethod\ndef validate_pattern(cls, v: str) -&gt; str:\n    \"\"\"Validate that the pattern is a valid regex pattern.\"\"\"\n    try:\n        re.compile(v)\n    except re.error as e:\n        raise InvalidRegexPatternError(v) from e\n    return v\n</code></pre>"},{"location":"api-reference/#restrictedmodule","title":"RestrictedModule","text":""},{"location":"api-reference/#llm_sandbox.security.RestrictedModule","title":"RestrictedModule","text":"<p>               Bases: <code>BaseModel</code></p> <p>A dangerous module.</p>"},{"location":"api-reference/#securityissueseverity","title":"SecurityIssueSeverity","text":""},{"location":"api-reference/#llm_sandbox.security.SecurityIssueSeverity","title":"SecurityIssueSeverity","text":"<p>               Bases: <code>IntEnum</code></p> <p>Severity of a security issue.</p>"},{"location":"api-reference/#enumerations","title":"Enumerations","text":""},{"location":"api-reference/#sandboxbackend","title":"SandboxBackend","text":""},{"location":"api-reference/#llm_sandbox.const.SandboxBackend","title":"SandboxBackend","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumeration of supported sandbox backend technologies.</p> <p>Each value represents a different containerization or virtualization technology that can be used to isolate code execution.</p>"},{"location":"api-reference/#supportedlanguage","title":"SupportedLanguage","text":""},{"location":"api-reference/#llm_sandbox.const.SupportedLanguage","title":"SupportedLanguage","text":"<p>               Bases: <code>StrEnum</code></p> <p>Dataclass defining constants for supported programming languages.</p> <p>Each attribute represents a language identifier string used by the sandbox to select appropriate language handlers and container images.</p>"},{"location":"api-reference/#filetype","title":"FileType","text":""},{"location":"api-reference/#llm_sandbox.data.FileType","title":"FileType","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of file types supported by artifact extractors.</p> <p>This enum lists common file formats that can be generated by code running in the sandbox and subsequently extracted, such as images, data files, and documents.</p>"},{"location":"api-reference/#functions","title":"Functions","text":""},{"location":"api-reference/#create_session","title":"create_session","text":""},{"location":"api-reference/#llm_sandbox.create_session","title":"create_session","text":"<pre><code>create_session(\n    backend: SandboxBackend = SandboxBackend.DOCKER, *args: Any, **kwargs: Any\n) -&gt; BaseSession\n</code></pre> <p>Create a new sandbox session for executing code in an isolated environment.</p> <p>This function creates a sandbox session that supports multiple programming languages and provides features like package installation, file operations, and secure code execution. For backward compatibility, we also keep a <code>SandboxSession</code> alias for this function.</p> PARAMETER DESCRIPTION <code>backend</code> <p>Container backend to use. Options: - SandboxBackend.DOCKER (default) - SandboxBackend.KUBERNETES - SandboxBackend.PODMAN - SandboxBackend.MICROMAMBA</p> <p> TYPE: <code>SandboxBackend</code> DEFAULT: <code>DOCKER</code> </p> <code>*args</code> <p>Additional positional arguments passed to the session constructor</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to the session constructor.     Common options include:         - lang (str): Programming language (\"python\", \"java\", \"javascript\", \"cpp\", \"go\")         - verbose (bool): Enable verbose logging         - keep_template (bool): Keep the container template         - image (str): Custom container image to use         - container_id (str): ID of existing container/pod to connect to</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Session</code> <p>A sandbox session instance for the specified backend</p> <p> TYPE: <code>BaseSession</code> </p> RAISES DESCRIPTION <code>MissingDependencyError</code> <p>If the required dependency for the chosen backend is not installed</p> <code>UnsupportedBackendError</code> <p>If the chosen backend is not supported</p> <p>Examples:</p> <p>Connect to existing Docker container: <pre><code># Assumes you have a running container with ID 'abc123...'\nwith SandboxSession(container_id='abc123def456', lang=\"python\") as session:\n    result = session.run(\"print('Hello from existing container!')\")\n    print(result.stdout)\n\n    # Install libraries in existing container\n    session.install([\"numpy\"])\n    result = session.run(\"import numpy as np; print(np.random.rand())\")\n\n    # Execute commands\n    result = session.execute_command(\"ls -la\")\n\n    # Copy files\n    session.copy_to_runtime(\"local_file.py\", \"/container/path/file.py\")\n</code></pre></p> <p>Connect to existing Kubernetes pod: <pre><code># Assumes you have a running pod with name 'my-pod-abc123'\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    container_id='my-pod-abc123',  # pod name\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Hello from existing pod!')\")\n</code></pre></p> <p>Connect to existing Podman container: <pre><code>from podman import PodmanClient\n\nclient = PodmanClient()\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    container_id='podman-container-id',\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Hello from existing Podman container!')\")\n</code></pre></p> <p>Python session with package installation: <pre><code>with SandboxSession(lang=\"python\", keep_template=True, verbose=True) as session:\n    # Basic code execution\n    result = session.run(\"print('Hello, World!')\")\n    print(result.stdout)  # Output: Hello, World!\n\n    # Install and use packages\n    result = session.run(\n        \"import numpy as np\\nprint(np.random.rand())\",\n        libraries=[\"numpy\"]\n    )\n\n    # Install additional packages during session\n    session.install([\"pandas\"])\n    result = session.run(\"import pandas as pd\\nprint(pd.__version__)\")\n\n    # Copy files to runtime\n    session.copy_to_runtime(\"README.md\", \"/sandbox/data.csv\")\n</code></pre></p> <p>Java session: <pre><code>with SandboxSession(lang=\"java\", keep_template=True, verbose=True) as session:\n    result = session.run(\\\"\\\"\\\"\n        public class Main {\n            public static void main(String[] args) {\n                System.out.println(\"Hello, World!\");\n            }\n        }\n    \\\"\\\"\\\")\n</code></pre></p> <p>JavaScript session with npm packages: <pre><code>with SandboxSession(lang=\"javascript\", keep_template=True, verbose=True) as session:\n    # Basic code execution\n    result = session.run(\"console.log('Hello, World!')\")\n\n    # Using npm packages\n    result = session.run(\\\"\\\"\\\"\n        const axios = require('axios');\n        axios.get('https://jsonplaceholder.typicode.com/posts/1')\n            .then(response =&gt; console.log(response.data));\n    \\\"\\\"\\\", libraries=[\"axios\"])\n</code></pre></p> <p>C++ session: <pre><code>with SandboxSession(lang=\"cpp\", keep_template=True, verbose=True) as session:\n    result = session.run(\\\"\\\"\\\"\n        #include &lt;iostream&gt;\n        #include &lt;vector&gt;\n        #include &lt;algorithm&gt;\n        int main() {\n            std::vector&lt;int&gt; v = {1, 2, 3, 4, 5};\n            std::reverse(v.begin(), v.end());\n            for (int i : v) {\n                std::cout &lt;&lt; i &lt;&lt; \" \";\n            }\n            std::cout &lt;&lt; std::endl;\n            return 0;\n        }\n    \\\"\\\"\\\", libraries=[\"libstdc++\"])\n</code></pre></p> <p>Go session with external packages: <pre><code>with SandboxSession(lang=\"go\", keep_template=True, verbose=True) as session:\n    result = session.run(\\\"\\\"\\\"\n        package main\n        import (\n            \"fmt\"\n            \"github.com/spyzhov/ajson\"\n        )\n        func main() {\n            json := []byte(`{\"price\": 100}`)\n            root, _ := ajson.Unmarshal(json)\n            nodes, _ := root.JSONPath(\"$..price\")\n            for _, node := range nodes {\n                node.SetNumeric(node.MustNumeric() * 1.25)\n            }\n            result, _ := ajson.Marshal(root)\n            fmt.Printf(\"%s\", result)\n        }\n    \\\"\\\"\\\", libraries=[\"github.com/spyzhov/ajson\"])\n</code></pre></p> Source code in <code>llm_sandbox/session.py</code> <pre><code>def create_session(\n    backend: SandboxBackend = SandboxBackend.DOCKER,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; BaseSession:\n    r\"\"\"Create a new sandbox session for executing code in an isolated environment.\n\n    This function creates a sandbox session that supports multiple programming languages\n    and provides features like package installation, file operations, and secure code execution.\n    For backward compatibility, we also keep a `SandboxSession` alias for this function.\n\n    Args:\n        backend (SandboxBackend): Container backend to use. Options:\n            - SandboxBackend.DOCKER (default)\n            - SandboxBackend.KUBERNETES\n            - SandboxBackend.PODMAN\n            - SandboxBackend.MICROMAMBA\n        *args: Additional positional arguments passed to the session constructor\n        **kwargs: Additional keyword arguments passed to the session constructor.\n                Common options include:\n                    - lang (str): Programming language (\"python\", \"java\", \"javascript\", \"cpp\", \"go\")\n                    - verbose (bool): Enable verbose logging\n                    - keep_template (bool): Keep the container template\n                    - image (str): Custom container image to use\n                    - container_id (str): ID of existing container/pod to connect to\n\n    Returns:\n        Session: A sandbox session instance for the specified backend\n\n    Raises:\n        MissingDependencyError: If the required dependency for the chosen backend is not installed\n        UnsupportedBackendError: If the chosen backend is not supported\n\n    Examples:\n        Connect to existing Docker container:\n        ```python\n        # Assumes you have a running container with ID 'abc123...'\n        with SandboxSession(container_id='abc123def456', lang=\"python\") as session:\n            result = session.run(\"print('Hello from existing container!')\")\n            print(result.stdout)\n\n            # Install libraries in existing container\n            session.install([\"numpy\"])\n            result = session.run(\"import numpy as np; print(np.random.rand())\")\n\n            # Execute commands\n            result = session.execute_command(\"ls -la\")\n\n            # Copy files\n            session.copy_to_runtime(\"local_file.py\", \"/container/path/file.py\")\n        ```\n\n        Connect to existing Kubernetes pod:\n        ```python\n        # Assumes you have a running pod with name 'my-pod-abc123'\n        with SandboxSession(\n            backend=SandboxBackend.KUBERNETES,\n            container_id='my-pod-abc123',  # pod name\n            lang=\"python\"\n        ) as session:\n            result = session.run(\"print('Hello from existing pod!')\")\n        ```\n\n        Connect to existing Podman container:\n        ```python\n        from podman import PodmanClient\n\n        client = PodmanClient()\n        with SandboxSession(\n            backend=SandboxBackend.PODMAN,\n            client=client,\n            container_id='podman-container-id',\n            lang=\"python\"\n        ) as session:\n            result = session.run(\"print('Hello from existing Podman container!')\")\n        ```\n\n        Python session with package installation:\n        ```python\n        with SandboxSession(lang=\"python\", keep_template=True, verbose=True) as session:\n            # Basic code execution\n            result = session.run(\"print('Hello, World!')\")\n            print(result.stdout)  # Output: Hello, World!\n\n            # Install and use packages\n            result = session.run(\n                \"import numpy as np\\nprint(np.random.rand())\",\n                libraries=[\"numpy\"]\n            )\n\n            # Install additional packages during session\n            session.install([\"pandas\"])\n            result = session.run(\"import pandas as pd\\nprint(pd.__version__)\")\n\n            # Copy files to runtime\n            session.copy_to_runtime(\"README.md\", \"/sandbox/data.csv\")\n        ```\n\n        Java session:\n        ```python\n        with SandboxSession(lang=\"java\", keep_template=True, verbose=True) as session:\n            result = session.run(\\\"\\\"\\\"\n                public class Main {\n                    public static void main(String[] args) {\n                        System.out.println(\"Hello, World!\");\n                    }\n                }\n            \\\"\\\"\\\")\n        ```\n\n        JavaScript session with npm packages:\n        ```python\n        with SandboxSession(lang=\"javascript\", keep_template=True, verbose=True) as session:\n            # Basic code execution\n            result = session.run(\"console.log('Hello, World!')\")\n\n            # Using npm packages\n            result = session.run(\\\"\\\"\\\"\n                const axios = require('axios');\n                axios.get('https://jsonplaceholder.typicode.com/posts/1')\n                    .then(response =&gt; console.log(response.data));\n            \\\"\\\"\\\", libraries=[\"axios\"])\n        ```\n\n        C++ session:\n        ```python\n        with SandboxSession(lang=\"cpp\", keep_template=True, verbose=True) as session:\n            result = session.run(\\\"\\\"\\\"\n                #include &lt;iostream&gt;\n                #include &lt;vector&gt;\n                #include &lt;algorithm&gt;\n                int main() {\n                    std::vector&lt;int&gt; v = {1, 2, 3, 4, 5};\n                    std::reverse(v.begin(), v.end());\n                    for (int i : v) {\n                        std::cout &lt;&lt; i &lt;&lt; \" \";\n                    }\n                    std::cout &lt;&lt; std::endl;\n                    return 0;\n                }\n            \\\"\\\"\\\", libraries=[\"libstdc++\"])\n        ```\n\n        Go session with external packages:\n        ```python\n        with SandboxSession(lang=\"go\", keep_template=True, verbose=True) as session:\n            result = session.run(\\\"\\\"\\\"\n                package main\n                import (\n                    \"fmt\"\n                    \"github.com/spyzhov/ajson\"\n                )\n                func main() {\n                    json := []byte(`{\"price\": 100}`)\n                    root, _ := ajson.Unmarshal(json)\n                    nodes, _ := root.JSONPath(\"$..price\")\n                    for _, node := range nodes {\n                        node.SetNumeric(node.MustNumeric() * 1.25)\n                    }\n                    result, _ := ajson.Marshal(root)\n                    fmt.Printf(\"%s\", result)\n                }\n            \\\"\\\"\\\", libraries=[\"github.com/spyzhov/ajson\"])\n        ```\n\n    \"\"\"\n    # Check if required dependency is installed\n    _check_dependency(backend)\n\n    # Create the appropriate session based on backend\n    match backend:\n        case SandboxBackend.DOCKER:\n            from .docker import SandboxDockerSession\n\n            return SandboxDockerSession(*args, **kwargs)\n        case SandboxBackend.KUBERNETES:\n            from .kubernetes import SandboxKubernetesSession\n\n            return SandboxKubernetesSession(*args, **kwargs)\n        case SandboxBackend.PODMAN:\n            from .podman import SandboxPodmanSession\n\n            return SandboxPodmanSession(*args, **kwargs)\n        case SandboxBackend.MICROMAMBA:\n            from .micromamba import MicromambaSession\n\n            return MicromambaSession(*args, **kwargs)\n        case _:\n            raise UnsupportedBackendError(backend=backend)\n</code></pre>"},{"location":"api-reference/#exceptions","title":"Exceptions","text":"<p>The library defines a base exception <code>llm_sandbox.exceptions.SandboxError</code> and various specific exceptions that inherit from it. Please refer to the <code>llm_sandbox.exceptions</code> module for a complete list.</p>"},{"location":"api-reference/#sandboxtimeouterror","title":"SandboxTimeoutError","text":"<p>Common exceptions include: - <code>ContainerError</code> - <code>SecurityError</code> - <code>ResourceError</code> - <code>ValidationError</code> - <code>LanguageNotSupportedError</code> - <code>ImageNotFoundError</code> - <code>SandboxTimeoutError</code> - Raised when operations exceed configured timeout limits</p>"},{"location":"api-reference/#llm_sandbox.exceptions.SandboxTimeoutError","title":"SandboxTimeoutError","text":"<pre><code>SandboxTimeoutError(message: str, timeout_duration: float | None = None)\n</code></pre> <p>               Bases: <code>SandboxError</code></p> <p>Raised when an operation times out.</p> <p>Initialize the TimeoutError.</p> Source code in <code>llm_sandbox/exceptions.py</code> <pre><code>def __init__(self, message: str, timeout_duration: float | None = None) -&gt; None:\n    \"\"\"Initialize the TimeoutError.\"\"\"\n    super().__init__(message)\n    self.timeout_duration = timeout_duration\n</code></pre>"},{"location":"api-reference/#llm_sandbox.exceptions.SandboxTimeoutError-functions","title":"Functions","text":""},{"location":"api-reference/#language-handlers","title":"Language Handlers","text":""},{"location":"api-reference/#abstractlanguagehandler","title":"AbstractLanguageHandler","text":""},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler","title":"AbstractLanguageHandler","text":"<pre><code>AbstractLanguageHandler(logger: Logger | None = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for language-specific handlers.</p> <p>Initialize the language handler.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def __init__(self, logger: logging.Logger | None = None) -&gt; None:\n    \"\"\"Initialize the language handler.\"\"\"\n    self.config: LanguageConfig\n    self.logger: logging.Logger = logger or logging.getLogger(__name__)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler-attributes","title":"Attributes","text":""},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.file_extension","title":"file_extension  <code>property</code>","text":"<pre><code>file_extension: str\n</code></pre> <p>Get file extension for language.</p>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.is_support_library_installation","title":"is_support_library_installation  <code>property</code>","text":"<pre><code>is_support_library_installation: bool\n</code></pre> <p>Get if the language supports library installation.</p>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.is_support_plot_detection","title":"is_support_plot_detection  <code>property</code>","text":"<pre><code>is_support_plot_detection: bool\n</code></pre> <p>Get if the language supports plot detection.</p>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get name of the language.</p>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.supported_plot_libraries","title":"supported_plot_libraries  <code>property</code>","text":"<pre><code>supported_plot_libraries: list[PlotLibrary]\n</code></pre> <p>Get supported plotting libraries.</p>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.extract_plots","title":"extract_plots","text":"<pre><code>extract_plots(container: ContainerProtocol, output_dir: str) -&gt; list[PlotOutput]\n</code></pre> <p>Extract plots from the code.</p> <p>Base implementation that searches for plot files and extracts them. Languages can override this method to provide custom plot extraction logic.</p> PARAMETER DESCRIPTION <code>container</code> <p>The container protocol instance to run code in</p> <p> TYPE: <code>ContainerProtocol</code> </p> <code>output_dir</code> <p>Directory where plots should be saved</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[PlotOutput]</code> <p>list[PlotOutput]: List of plot outputs</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def extract_plots(self, container: \"ContainerProtocol\", output_dir: str) -&gt; list[PlotOutput]:\n    \"\"\"Extract plots from the code.\n\n    Base implementation that searches for plot files and extracts them.\n    Languages can override this method to provide custom plot extraction logic.\n\n    Args:\n        container: The container protocol instance to run code in\n        output_dir: Directory where plots should be saved\n\n    Returns:\n        list[PlotOutput]: List of plot outputs\n\n    \"\"\"\n    plots: list[PlotOutput] = []\n\n    try:\n        result = container.execute_command(f\"test -d {output_dir}\")\n        if result.exit_code:\n            return plots\n\n        result = container.execute_command(\n            f\"find {output_dir} -name '*.png' -o -name '*.svg' -o -name '*.pdf' -o -name '*.html'\"\n        )\n        if result.exit_code:\n            return plots\n\n        file_paths = result.stdout.strip().split(\"\\n\")\n        file_paths = [path.strip() for path in file_paths if path.strip()]\n\n        for file_path in sorted(file_paths):\n            try:\n                plot_output = self._extract_single_plot(container, file_path)\n                if plot_output:\n                    plots.append(plot_output)\n            except (OSError, tarfile.TarError, ValueError):\n                self.logger.exception(\"Error extracting plot %s\", file_path)\n\n    except (OSError, RuntimeError):\n        self.logger.exception(\"Error extracting %s plots\", self.config.name)\n\n    return plots\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.filter_comments","title":"filter_comments","text":"<pre><code>filter_comments(code: str) -&gt; str\n</code></pre> <p>Filter out comments from code in a language-specific way.</p> PARAMETER DESCRIPTION <code>code</code> <p>The code to filter comments from.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The code with comments removed.</p> <p> TYPE: <code>str</code> </p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def filter_comments(self, code: str) -&gt; str:\n    \"\"\"Filter out comments from code in a language-specific way.\n\n    Args:\n        code (str): The code to filter comments from.\n\n    Returns:\n        str: The code with comments removed.\n\n    \"\"\"\n    # First remove multi-line comments\n    code = re.sub(self.get_multiline_comment_patterns(), \"\", code)\n\n    # Then handle single-line comments\n    filtered_lines = []\n    for line in code.split(\"\\n\"):\n        # Remove inline comments\n        clean_line = re.sub(self.get_inline_comment_patterns(), \"\", line)\n        # Keep the line if it has non-whitespace content\n        if clean_line.strip():\n            filtered_lines.append(clean_line)\n        else:\n            # Preserve empty lines for readability\n            filtered_lines.append(\"\")\n    return \"\\n\".join(filtered_lines)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.get_execution_commands","title":"get_execution_commands","text":"<pre><code>get_execution_commands(code_file: str) -&gt; list[str]\n</code></pre> <p>Get commands to execute code file.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def get_execution_commands(self, code_file: str) -&gt; list[str]:\n    \"\"\"Get commands to execute code file.\"\"\"\n    if not self.config.execution_commands:\n        raise CommandFailedError(self.config.name, 1, \"No execution commands found\")\n    return [command.format(file=code_file) for command in self.config.execution_commands]\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.get_import_patterns","title":"get_import_patterns  <code>abstractmethod</code>","text":"<pre><code>get_import_patterns(module: str) -&gt; str\n</code></pre> <p>Get the regex patterns for import statements.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>@abstractmethod\ndef get_import_patterns(self, module: str) -&gt; str:\n    \"\"\"Get the regex patterns for import statements.\"\"\"\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.get_inline_comment_patterns","title":"get_inline_comment_patterns  <code>abstractmethod</code> <code>staticmethod</code>","text":"<pre><code>get_inline_comment_patterns() -&gt; str\n</code></pre> <p>Get the regex for inline comment patterns.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef get_inline_comment_patterns() -&gt; str:\n    \"\"\"Get the regex for inline comment patterns.\"\"\"\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.get_library_installation_command","title":"get_library_installation_command","text":"<pre><code>get_library_installation_command(library: str) -&gt; str\n</code></pre> <p>Get command to install library.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def get_library_installation_command(self, library: str) -&gt; str:\n    \"\"\"Get command to install library.\"\"\"\n    if not self.config.package_manager:\n        raise PackageManagerError(self.config.name)\n    return f\"{self.config.package_manager} {library}\"\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.get_multiline_comment_patterns","title":"get_multiline_comment_patterns  <code>abstractmethod</code> <code>staticmethod</code>","text":"<pre><code>get_multiline_comment_patterns() -&gt; str\n</code></pre> <p>Get the regex patterns for multiline comment.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef get_multiline_comment_patterns() -&gt; str:\n    \"\"\"Get the regex patterns for multiline comment.\"\"\"\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.inject_plot_detection_code","title":"inject_plot_detection_code","text":"<pre><code>inject_plot_detection_code(code: str) -&gt; str\n</code></pre> <p>Inject code to detect and capture plots.</p> <p>Subclasses should override this method to provide custom plot detection code.</p> PARAMETER DESCRIPTION <code>code</code> <p>The code to inject plot detection code into.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The code with plot detection code injected.</p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def inject_plot_detection_code(self, code: str) -&gt; str:\n    \"\"\"Inject code to detect and capture plots.\n\n    Subclasses should override this method to provide custom plot detection code.\n\n    Args:\n        code: The code to inject plot detection code into.\n\n    Returns:\n        The code with plot detection code injected.\n\n    \"\"\"\n    return code\n</code></pre>"},{"location":"api-reference/#llm_sandbox.language_handlers.base.AbstractLanguageHandler.run_with_artifacts","title":"run_with_artifacts","text":"<pre><code>run_with_artifacts(\n    container: ContainerProtocol,\n    code: str,\n    libraries: list | None = None,\n    enable_plotting: bool = True,\n    output_dir: str = \"/tmp/sandbox_plots\",\n    timeout: int = 30,\n) -&gt; tuple[Any, list[PlotOutput]]\n</code></pre> <p>Run code and extract artifacts (plots) in a language-specific manner.</p> <p>This method provides a language-specific implementation for running code with artifact extraction. Languages that support plot detection can override this method to provide custom artifact extraction logic.</p> PARAMETER DESCRIPTION <code>container</code> <p>The container protocol instance to run code in</p> <p> TYPE: <code>ContainerProtocol</code> </p> <code>code</code> <p>The code to execute</p> <p> TYPE: <code>str</code> </p> <code>libraries</code> <p>Optional list of libraries to install before running</p> <p> TYPE: <code>list | None</code> DEFAULT: <code>None</code> </p> <code>enable_plotting</code> <p>Whether to enable plot detection and extraction</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>output_dir</code> <p>Directory where plots should be saved</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/tmp/sandbox_plots'</code> </p> <code>timeout</code> <p>Timeout for the code execution</p> <p> TYPE: <code>int</code> DEFAULT: <code>30</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>(execution_result, list_of_plots)</p> <p> TYPE: <code>tuple[Any, list[PlotOutput]]</code> </p> Source code in <code>llm_sandbox/language_handlers/base.py</code> <pre><code>def run_with_artifacts(\n    self,\n    container: \"ContainerProtocol\",\n    code: str,\n    libraries: list | None = None,\n    enable_plotting: bool = True,\n    output_dir: str = \"/tmp/sandbox_plots\",\n    timeout: int = 30,\n) -&gt; tuple[Any, list[PlotOutput]]:\n    \"\"\"Run code and extract artifacts (plots) in a language-specific manner.\n\n    This method provides a language-specific implementation for running code\n    with artifact extraction. Languages that support plot detection can override\n    this method to provide custom artifact extraction logic.\n\n    Args:\n        container: The container protocol instance to run code in\n        code: The code to execute\n        libraries: Optional list of libraries to install before running\n        enable_plotting: Whether to enable plot detection and extraction\n        output_dir: Directory where plots should be saved\n        timeout: Timeout for the code execution\n\n    Returns:\n        tuple: (execution_result, list_of_plots)\n\n    \"\"\"\n    # Default implementation for languages without plot support\n    if enable_plotting and self.is_support_plot_detection:\n        # Inject plot detection code\n        injected_code = self.inject_plot_detection_code(code)\n\n        # Run the code with plot detection\n        result = container.run(injected_code, libraries, timeout)\n\n        # Extract plots\n        plots = self.extract_plots(container, output_dir)\n\n        return result, plots\n\n    # Run code without plot detection\n    result = container.run(code, libraries, timeout)\n    return result, []\n</code></pre>"},{"location":"api-reference/#languageconfig","title":"LanguageConfig","text":""},{"location":"api-reference/#llm_sandbox.language_handlers.LanguageConfig","title":"LanguageConfig  <code>dataclass</code>","text":"<pre><code>LanguageConfig(\n    name: str,\n    file_extension: str,\n    execution_commands: list[str],\n    package_manager: str | None,\n    is_support_library_installation: bool = True,\n    plot_detection: PlotDetectionConfig | None = None,\n)\n</code></pre> <p>Language-specific configuration.</p>"},{"location":"api-reference/#backend-specific-apis","title":"Backend-Specific APIs","text":""},{"location":"api-reference/#docker-backend","title":"Docker Backend","text":""},{"location":"api-reference/#llm_sandbox.docker.SandboxDockerSession","title":"SandboxDockerSession","text":"<pre><code>SandboxDockerSession(\n    client: DockerClient | None = None,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    stream: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>BaseSession</code></p> <p>Sandbox session implemented using Docker containers.</p> <p>This class provides a sandboxed environment for code execution by leveraging Docker. It handles Docker image management (pulling, building from Dockerfile), container creation and lifecycle, code execution, library installation, and file operations within the Docker container.</p> <p>Initialize Docker session.</p> PARAMETER DESCRIPTION <code>client</code> <p>The Docker client to use.</p> <p> TYPE: <code>DockerClient | None</code> DEFAULT: <code>None</code> </p> <code>image</code> <p>The image to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>dockerfile</code> <p>The Dockerfile to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>lang</code> <p>The language to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYTHON</code> </p> <code>keep_template</code> <p>Whether to keep the template image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>commit_container</code> <p>Whether to commit the container to a new image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>Whether to enable verbose output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>stream</code> <p>Whether to stream the output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>runtime_configs</code> <p>The runtime configurations to use.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>workdir</code> <p>The working directory to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/sandbox'</code> </p> <code>security_policy</code> <p>The security policy to use.</p> <p> TYPE: <code>SecurityPolicy | None</code> DEFAULT: <code>None</code> </p> <code>default_timeout</code> <p>The default timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>execution_timeout</code> <p>The execution timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>session_timeout</code> <p>The session timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>container_id</code> <p>ID of existing container to connect to.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>skip_environment_setup</code> <p>Skip language-specific environment setup.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>llm_sandbox/docker.py</code> <pre><code>def __init__(\n    self,  # NOSONAR\n    client: docker.DockerClient | None = None,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    stream: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    r\"\"\"Initialize Docker session.\n\n    Args:\n        client (docker.DockerClient | None): The Docker client to use.\n        image (str | None): The image to use.\n        dockerfile (str | None): The Dockerfile to use.\n        lang (str): The language to use.\n        keep_template (bool): Whether to keep the template image.\n        commit_container (bool): Whether to commit the container to a new image.\n        verbose (bool): Whether to enable verbose output.\n        stream (bool): Whether to stream the output.\n        runtime_configs (dict | None): The runtime configurations to use.\n        workdir (str): The working directory to use.\n        security_policy (SecurityPolicy | None): The security policy to use.\n        default_timeout (float | None): The default timeout to use.\n        execution_timeout (float | None): The execution timeout to use.\n        session_timeout (float | None): The session timeout to use.\n        container_id (str | None): ID of existing container to connect to.\n        skip_environment_setup (bool): Skip language-specific environment setup.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        None\n\n    \"\"\"\n    config = SessionConfig(\n        image=image,\n        dockerfile=dockerfile,\n        lang=SupportedLanguage(lang.upper()),\n        verbose=verbose,\n        workdir=workdir,\n        runtime_configs=runtime_configs or {},\n        security_policy=security_policy,\n        default_timeout=default_timeout,\n        execution_timeout=execution_timeout,\n        session_timeout=session_timeout,\n        container_id=container_id,\n        skip_environment_setup=skip_environment_setup,\n    )\n\n    super().__init__(config=config, **kwargs)\n\n    self.client: docker.DockerClient\n\n    if not client:\n        self._log(\"Using local Docker context since client is not provided.\")\n        self.client = docker.from_env()\n    else:\n        self.client = client\n\n    self.container_api = DockerContainerAPI(self.client, stream)\n\n    self.docker_image: Image\n    self.keep_template: bool = keep_template\n    self.commit_container: bool = commit_container\n    self.is_create_template: bool = False\n    self.stream: bool = stream\n\n    if mounts := kwargs.get(\"mounts\"):\n        warnings.warn(\n            \"The 'mounts' parameter is deprecated and will be removed in a future version. \"\n            \"Put the mounts in 'runtime_configs' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        existing_mounts = self.config.runtime_configs.setdefault(\"mounts\", [])\n        if isinstance(mounts, list):\n            existing_mounts.extend(mounts)\n        else:\n            existing_mounts.append(mounts)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.docker.SandboxDockerSession-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.docker.SandboxDockerSession.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the Docker sandbox session.</p> <p>This method cleans up Docker resources by: 1. Committing the container to a new image if <code>commit_container</code> is True. 2. Stopping and removing the running Docker container (only if we created it). 3. Removing the Docker image if <code>is_create_template</code> is True (image was built or pulled     during this session), <code>keep_template</code> is False, and the image is not in use by     other containers.</p> <p>Note: When using existing containers, we only disconnect but don't stop/remove the container.</p> RAISES DESCRIPTION <code>ImageNotFoundError</code> <p>If the image to be removed is not found (should not typically occur).</p> Source code in <code>llm_sandbox/docker.py</code> <pre><code>def close(self) -&gt; None:\n    r\"\"\"Close the Docker sandbox session.\n\n    This method cleans up Docker resources by:\n    1. Committing the container to a new image if `commit_container` is True.\n    2. Stopping and removing the running Docker container (only if we created it).\n    3. Removing the Docker image if `is_create_template` is True (image was built or pulled\n        during this session), `keep_template` is False, and the image is not in use by\n        other containers.\n\n    Note: When using existing containers, we only disconnect but don't stop/remove the container.\n\n    Raises:\n        ImageNotFoundError: If the image to be removed is not found (should not typically occur).\n\n    \"\"\"\n    super().close()\n\n    if self.container:\n        if self.commit_container and self.docker_image:\n            self._commit_container()\n\n        # Only stop/remove container if we created it (not existing container)\n        if not self.using_existing_container:\n            try:\n                self.container.stop()\n                self.container.wait()\n                self.container.remove(force=True)\n                self._log(\"Stopped and removed container\")\n            except Exception:  # noqa: BLE001\n                self._log(\"Error cleaning up container\")\n        else:\n            self._log(\"Disconnected from existing container\")\n\n        self.container = None\n\n    if self.is_create_template and not self.keep_template and self.docker_image:\n        self._cleanup_image()\n</code></pre>"},{"location":"api-reference/#llm_sandbox.docker.SandboxDockerSession.get_archive","title":"get_archive","text":"<pre><code>get_archive(path: str) -&gt; tuple[bytes, dict]\n</code></pre> <p>Get archive from container.</p> Source code in <code>llm_sandbox/docker.py</code> <pre><code>def get_archive(self, path: str) -&gt; tuple[bytes, dict]:\n    \"\"\"Get archive from container.\"\"\"\n    if not self.container:\n        raise NotOpenSessionError\n\n    data, stat = self.container.get_archive(path)\n    return b\"\".join(data), stat\n</code></pre>"},{"location":"api-reference/#llm_sandbox.docker.SandboxDockerSession.open","title":"open","text":"<pre><code>open() -&gt; None\n</code></pre> <p>Open Docker session.</p> <p>This method prepares the Docker environment for code execution by: - Building or pulling the Docker image (if not using existing container) - Creating a container or connecting to existing one - Setting up the environment (if not using existing container)</p> RAISES DESCRIPTION <code>ImagePullError</code> <p>If the image cannot be pulled.</p> <code>ImageNotFoundError</code> <p>If the image cannot be found.</p> <code>ContainerError</code> <p>If existing container cannot be found or accessed.</p> Source code in <code>llm_sandbox/docker.py</code> <pre><code>def open(self) -&gt; None:\n    r\"\"\"Open Docker session.\n\n    This method prepares the Docker environment for code execution by:\n    - Building or pulling the Docker image (if not using existing container)\n    - Creating a container or connecting to existing one\n    - Setting up the environment (if not using existing container)\n\n    Raises:\n        ImagePullError: If the image cannot be pulled.\n        ImageNotFoundError: If the image cannot be found.\n        ContainerError: If existing container cannot be found or accessed.\n\n    \"\"\"\n    super().open()\n\n    if self.using_existing_container and self.config.container_id:\n        # Connect to existing container\n        self._connect_to_existing_container(self.config.container_id)\n    else:\n        # Create new container\n        self._prepare_image()\n\n        container_config = {\"image\": self.docker_image, \"detach\": True, \"tty\": True, \"user\": \"root\"}\n        container_config.update(self.config.runtime_configs)\n\n        self.container = self.container_api.create_container(container_config)\n        self.container_api.start_container(self.container)\n\n    # Setup environment (skipped for existing containers)\n    self.environment_setup()\n</code></pre>"},{"location":"api-reference/#kubernetes-backend","title":"Kubernetes Backend","text":""},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession","title":"SandboxKubernetesSession","text":"<pre><code>SandboxKubernetesSession(\n    client: CoreV1Api | None = None,\n    image: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    verbose: bool = False,\n    kube_namespace: str = \"default\",\n    env_vars: dict[str, str] | None = None,\n    pod_manifest: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>BaseSession</code></p> <p>Sandbox session implemented using Kubernetes Pods.</p> <p>This class provides a sandboxed environment for code execution by leveraging Kubernetes. It handles Pod creation and lifecycle based on a provided or default manifest, code execution, library installation, and file operations within the Kubernetes Pod.</p> <p>Initialize Kubernetes session.</p> PARAMETER DESCRIPTION <code>client</code> <p>The Kubernetes client to use.</p> <p> TYPE: <code>CoreV1Api | None</code> DEFAULT: <code>None</code> </p> <code>image</code> <p>The image to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>lang</code> <p>The language to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYTHON</code> </p> <code>verbose</code> <p>Whether to enable verbose output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>kube_namespace</code> <p>The Kubernetes namespace to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> <code>env_vars</code> <p>The environment variables to use.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>pod_manifest</code> <p>The Kubernetes pod manifest to use.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>workdir</code> <p>The working directory to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/sandbox'</code> </p> <code>security_policy</code> <p>The security policy to use.</p> <p> TYPE: <code>SecurityPolicy | None</code> DEFAULT: <code>None</code> </p> <code>default_timeout</code> <p>The default timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>execution_timeout</code> <p>The execution timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>session_timeout</code> <p>The session timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>container_id</code> <p>ID of existing pod to connect to.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>skip_environment_setup</code> <p>Skip language-specific environment setup.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def __init__(\n    self,  # NOSONAR (too many arguments)\n    client: CoreV1Api | None = None,\n    image: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    verbose: bool = False,\n    kube_namespace: str = \"default\",\n    env_vars: dict[str, str] | None = None,\n    pod_manifest: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,  # This will be pod_id for Kubernetes\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    r\"\"\"Initialize Kubernetes session.\n\n    Args:\n        client (CoreV1Api | None): The Kubernetes client to use.\n        image (str | None): The image to use.\n        lang (str): The language to use.\n        verbose (bool): Whether to enable verbose output.\n        kube_namespace (str): The Kubernetes namespace to use.\n        env_vars (dict[str, str] | None): The environment variables to use.\n        pod_manifest (dict | None): The Kubernetes pod manifest to use.\n        workdir (str): The working directory to use.\n        security_policy (SecurityPolicy | None): The security policy to use.\n        default_timeout (float | None): The default timeout to use.\n        execution_timeout (float | None): The execution timeout to use.\n        session_timeout (float | None): The session timeout to use.\n        container_id (str | None): ID of existing pod to connect to.\n        skip_environment_setup (bool): Skip language-specific environment setup.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        None\n\n    \"\"\"\n    config = SessionConfig(\n        image=image,\n        lang=SupportedLanguage(lang.upper()),\n        verbose=verbose,\n        workdir=workdir,\n        security_policy=security_policy,\n        default_timeout=default_timeout,\n        execution_timeout=execution_timeout,\n        session_timeout=session_timeout,\n        container_id=container_id,\n        skip_environment_setup=skip_environment_setup,\n    )\n\n    super().__init__(config=config, **kwargs)\n\n    if not client:\n        self._log(\"Using local Kubernetes context since client is not provided.\")\n        from kubernetes import config as k8s_config\n\n        k8s_config.load_kube_config()\n        self.client = CoreV1Api()\n    else:\n        self.client = client\n\n    self.kube_namespace = kube_namespace\n    self.container_api = KubernetesContainerAPI(self.client, kube_namespace)\n\n    # Generate unique pod name (only if not using existing pod)\n    if not self.using_existing_container:\n        short_uuid = uuid.uuid4().hex[:8]\n        self.pod_name = f\"sandbox-{lang.lower()}-{short_uuid}\"\n        self.env_vars = env_vars\n        self.pod_manifest = pod_manifest or self._default_pod_manifest()\n        self._reconfigure_with_pod_manifest()\n\n        # Extract container name from pod manifest for command execution\n        containers = self.pod_manifest.get(\"spec\", {}).get(\"containers\", [])\n        if containers:\n            self.container_name = containers[0][\"name\"]\n        else:\n            self.container_name = \"sandbox-container\"  # fallback\n    elif container_id:\n        self.pod_name = container_id\n        # For existing containers, we'll need to query the pod to get container name\n        self.container_name = None  # Will be set when connecting\n\n    # For compatibility with base class\n    self.stream = False\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession-functions","title":"Functions","text":""},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close Kubernetes session.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close Kubernetes session.\"\"\"\n    super().close()\n\n    if self.container:\n        # Only delete pod if we created it (not existing pod)\n        if not self.using_existing_container:\n            try:\n                self.container_api.stop_container(self.container)\n                self._log(\"Deleted pod\")\n            except Exception as e:  # noqa: BLE001\n                self._log(f\"Error cleaning up pod: {e}\", \"error\")\n        else:\n            self._log(\"Disconnected from existing pod\")\n\n        self.container = None\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.copy_from_runtime","title":"copy_from_runtime","text":"<pre><code>copy_from_runtime(src: str, dest: str) -&gt; None\n</code></pre> <p>Override to pass container name for Kubernetes.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def copy_from_runtime(self, src: str, dest: str) -&gt; None:\n    \"\"\"Override to pass container name for Kubernetes.\"\"\"\n    if not self.container:\n        raise NotOpenSessionError\n\n    if self.verbose:\n        self.logger.info(\"Copying %s to %s\", src, dest)\n\n    bits, stat = self.container_api.copy_from_container(self.container, src, container_name=self.container_name)\n    if stat.get(\"size\", 0) == 0:\n        msg = f\"File {src} not found in container\"\n        raise FileNotFoundError(msg)\n\n    self._extract_archive_safely(bits, dest)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.copy_to_runtime","title":"copy_to_runtime","text":"<pre><code>copy_to_runtime(src: str, dest: str) -&gt; None\n</code></pre> <p>Override to pass container name for Kubernetes.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def copy_to_runtime(self, src: str, dest: str) -&gt; None:\n    \"\"\"Override to pass container name for Kubernetes.\"\"\"\n    if not self.container:\n        raise NotOpenSessionError\n\n    # Validate source path exists and is accessible (same as mixin)\n    src_path = Path(src)\n    if not (src_path.exists() and (src_path.is_file() or src_path.is_dir())):\n        msg = f\"Source path {src} does not exist or is not accessible\"\n        raise FileNotFoundError(msg)\n\n    if self.verbose:\n        self.logger.info(\"Copying %s to %s\", src, dest)\n\n    dest_dir = str(Path(dest).parent)\n    if dest_dir:\n        self._ensure_directory_exists(dest_dir)\n\n    self.container_api.copy_to_container(self.container, src, dest, container_name=self.container_name)\n    self._ensure_ownership([dest])\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.execute_command","title":"execute_command","text":"<pre><code>execute_command(command: str, workdir: str | None = None) -&gt; ConsoleOutput\n</code></pre> <p>Override to pass container name for Kubernetes.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def execute_command(self, command: str, workdir: str | None = None) -&gt; ConsoleOutput:\n    \"\"\"Override to pass container name for Kubernetes.\"\"\"\n    if not command:\n        raise CommandEmptyError\n\n    if not self.container:\n        raise NotOpenSessionError\n\n    if self.verbose:\n        self.logger.info(\"Executing command: %s\", command)\n\n    exit_code, output = self.container_api.execute_command(\n        self.container, command, workdir=workdir, stream=self.stream, container_name=self.container_name\n    )\n\n    stdout, stderr = self._process_output(output)\n\n    if self.verbose:\n        if stdout:\n            self.logger.info(\"STDOUT: %s\", stdout)\n        if stderr:\n            self.logger.error(\"STDERR: %s\", stderr)\n\n    return ConsoleOutput(exit_code=exit_code or 0, stdout=stdout, stderr=stderr)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.get_archive","title":"get_archive","text":"<pre><code>get_archive(path: str) -&gt; tuple[bytes, dict]\n</code></pre> <p>Get archive from Kubernetes pod.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def get_archive(self, path: str) -&gt; tuple[bytes, dict]:\n    \"\"\"Get archive from Kubernetes pod.\"\"\"\n    if not self.container:\n        raise NotOpenSessionError\n\n    return self.container_api.copy_from_container(self.container, path, container_name=self.container_name)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.kubernetes.SandboxKubernetesSession.open","title":"open","text":"<pre><code>open() -&gt; None\n</code></pre> <p>Open Kubernetes session.</p> Source code in <code>llm_sandbox/kubernetes.py</code> <pre><code>def open(self) -&gt; None:\n    \"\"\"Open Kubernetes session.\"\"\"\n    super().open()\n\n    if self.using_existing_container and self.config.container_id:\n        # Connect to existing pod\n        self._connect_to_existing_container(self.config.container_id)\n    else:\n        # Create new pod\n        container_config = {\"pod_manifest\": self.pod_manifest}\n        self.container = self.container_api.create_container(container_config)\n\n    # Setup environment only for newly-created pods\n    if not self.using_existing_container:\n        self.environment_setup()\n</code></pre>"},{"location":"api-reference/#podman-backend","title":"Podman Backend","text":""},{"location":"api-reference/#llm_sandbox.podman.SandboxPodmanSession","title":"SandboxPodmanSession","text":"<pre><code>SandboxPodmanSession(\n    client: PodmanClient | None = None,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    mounts: list | None = None,\n    stream: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str | None = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: dict[str, Any],\n)\n</code></pre> <p>               Bases: <code>SandboxDockerSession</code></p> <p>Sandbox session implemented using Podman containers.</p> <p>This class provides a sandboxed environment for code execution by leveraging Podman. It inherits from SandboxDockerSession since Podman is designed to be Docker-compatible, only overriding the differences in client initialization and API behavior.</p> <p>Initialize Podman session.</p> PARAMETER DESCRIPTION <code>client</code> <p>The Podman client to use.</p> <p> TYPE: <code>PodmanClient | None</code> DEFAULT: <code>None</code> </p> <code>image</code> <p>The image to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>dockerfile</code> <p>The Dockerfile to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>lang</code> <p>The language to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYTHON</code> </p> <code>keep_template</code> <p>Whether to keep the template image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>commit_container</code> <p>Whether to commit the container to a new image.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>Whether to enable verbose output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>mounts</code> <p>The mounts to use.</p> <p> TYPE: <code>list | None</code> DEFAULT: <code>None</code> </p> <code>stream</code> <p>Whether to stream the output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>runtime_configs</code> <p>The runtime configurations to use.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>workdir</code> <p>The working directory to use.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>'/sandbox'</code> </p> <code>security_policy</code> <p>The security policy to use.</p> <p> TYPE: <code>SecurityPolicy | None</code> DEFAULT: <code>None</code> </p> <code>default_timeout</code> <p>The default timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>execution_timeout</code> <p>The execution timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>session_timeout</code> <p>The session timeout to use.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>container_id</code> <p>ID of existing container to connect to.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>skip_environment_setup</code> <p>Skip language-specific environment setup.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>llm_sandbox/podman.py</code> <pre><code>def __init__(\n    self,  # NOSONAR\n    client: PodmanClient | None = None,\n    image: str | None = None,\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    commit_container: bool = False,\n    verbose: bool = False,\n    mounts: list | None = None,\n    stream: bool = False,\n    runtime_configs: dict | None = None,\n    workdir: str | None = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: dict[str, Any],\n) -&gt; None:\n    r\"\"\"Initialize Podman session.\n\n    Args:\n        client (PodmanClient | None): The Podman client to use.\n        image (str | None): The image to use.\n        dockerfile (str | None): The Dockerfile to use.\n        lang (str): The language to use.\n        keep_template (bool): Whether to keep the template image.\n        commit_container (bool): Whether to commit the container to a new image.\n        verbose (bool): Whether to enable verbose output.\n        mounts (list | None): The mounts to use.\n        stream (bool): Whether to stream the output.\n        runtime_configs (dict | None): The runtime configurations to use.\n        workdir (str | None): The working directory to use.\n        security_policy (SecurityPolicy | None): The security policy to use.\n        default_timeout (float | None): The default timeout to use.\n        execution_timeout (float | None): The execution timeout to use.\n        session_timeout (float | None): The session timeout to use.\n        container_id (str | None): ID of existing container to connect to.\n        skip_environment_setup (bool): Skip language-specific environment setup.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        None\n\n    \"\"\"\n    config = SessionConfig(\n        image=image,\n        dockerfile=dockerfile,\n        lang=SupportedLanguage(lang.upper()),\n        verbose=verbose,\n        workdir=workdir or \"/sandbox\",\n        runtime_configs=runtime_configs or {},\n        security_policy=security_policy,\n        default_timeout=default_timeout,\n        execution_timeout=execution_timeout,\n        session_timeout=session_timeout,\n        container_id=container_id,\n        skip_environment_setup=skip_environment_setup,\n    )\n\n    # Initialize BaseSession (skip Docker's __init__)\n    from llm_sandbox.core.session_base import BaseSession\n\n    BaseSession.__init__(self, config=config, **kwargs)\n\n    if not client:\n        self._log(\"Using local Podman context since client is not provided.\")\n        self.client = PodmanClient.from_env()\n    else:\n        self.client = client\n\n    self.container_api = PodmanContainerAPI(self.client, stream)\n\n    # Set other attributes\n    self.docker_image: Image\n    self.keep_template: bool = keep_template\n    self.commit_container: bool = commit_container\n    self.is_create_template: bool = False\n    self.stream: bool = stream\n\n    if mounts:\n        import warnings\n\n        warnings.warn(\n            \"The 'mounts' parameter is deprecated and will be removed in a future version. \"\n            \"Put the mounts in 'runtime_configs' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self.config.runtime_configs.setdefault(\"mounts\", []).append(mounts)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.podman.SandboxPodmanSession-functions","title":"Functions","text":""},{"location":"api-reference/#micromamba-backend","title":"Micromamba Backend","text":""},{"location":"api-reference/#llm_sandbox.micromamba.MicromambaSession","title":"MicromambaSession","text":"<pre><code>MicromambaSession(\n    client: DockerClient | None = None,\n    image: str = \"mambaorg/micromamba:latest\",\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    verbose: bool = False,\n    mounts: list[Mount] | None = None,\n    environment: str = \"base\",\n    commit_container: bool = False,\n    stream: bool = True,\n    runtime_configs: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>SandboxDockerSession</code></p> <p>Extends <code>BaseSession</code> to execute commands within a Micromamba environment.</p> <p>This session leverages a Docker container (typically one with Micromamba pre-installed, like \"mambaorg/micromamba:latest\") and wraps executed commands with <code>micromamba run</code> to ensure they operate within a specified Micromamba environment.</p> <p>Reference: https://github.com/vndee/llm-sandbox/pull/3</p> <p>Initialize a new Micromamba-enabled sandbox session.</p> PARAMETER DESCRIPTION <code>client</code> <p>An existing Docker client instance. If None, a new client is created from the local Docker environment. Defaults to None.</p> <p> TYPE: <code>DockerClient | None</code> DEFAULT: <code>None</code> </p> <code>image</code> <p>The Docker image to use, which should have Micromamba installed. Defaults to \"mambaorg/micromamba:latest\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'mambaorg/micromamba:latest'</code> </p> <code>dockerfile</code> <p>Path to a Dockerfile to build a custom image. The resulting image should have Micromamba. Defaults to None.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>lang</code> <p>The primary programming language. This mainly influences default file extensions for code execution. Defaults to SupportedLanguage.PYTHON.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYTHON</code> </p> <code>keep_template</code> <p>If True, the Docker image will not be removed after the session ends. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>If True, print detailed log messages. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>mounts</code> <p>A list of Docker <code>Mount</code> objects to be mounted into the container. Defaults to None.</p> <p> TYPE: <code>list[Mount] | None</code> DEFAULT: <code>None</code> </p> <code>environment</code> <p>The name of the Micromamba environment to activate and run commands within (e.g., \"base\", \"my_env\"). Defaults to \"base\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'base'</code> </p> <code>commit_container</code> <p>If True, the Docker container's state will be committed to a new image after the session ends. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>stream</code> <p>If True, the output from <code>execute_command</code> will be streamed. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>runtime_configs</code> <p>Additional configurations for the container runtime. Defaults to None.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>workdir</code> <p>The working directory inside the container. Defaults to \"/sandbox\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/sandbox'</code> </p> <code>security_policy</code> <p>The security policy to use for the session. Defaults to None.</p> <p> TYPE: <code>SecurityPolicy | None</code> DEFAULT: <code>None</code> </p> <code>default_timeout</code> <p>The default timeout for the session. Defaults to None.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>execution_timeout</code> <p>The execution timeout for the session. Defaults to None.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>session_timeout</code> <p>The session timeout for the session. Defaults to None.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>container_id</code> <p>ID of existing container to connect to. Defaults to None.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>skip_environment_setup</code> <p>Skip language-specific environment setup. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>llm_sandbox/micromamba.py</code> <pre><code>def __init__(\n    self,  # NOSONAR\n    client: docker.DockerClient | None = None,\n    image: str = \"mambaorg/micromamba:latest\",\n    dockerfile: str | None = None,\n    lang: str = SupportedLanguage.PYTHON,\n    keep_template: bool = False,\n    verbose: bool = False,\n    mounts: list[Mount] | None = None,\n    environment: str = \"base\",\n    commit_container: bool = False,\n    stream: bool = True,\n    runtime_configs: dict | None = None,\n    workdir: str = \"/sandbox\",\n    security_policy: SecurityPolicy | None = None,\n    default_timeout: float | None = None,\n    execution_timeout: float | None = None,\n    session_timeout: float | None = None,\n    container_id: str | None = None,\n    skip_environment_setup: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    r\"\"\"Initialize a new Micromamba-enabled sandbox session.\n\n    Args:\n        client (docker.DockerClient | None, optional): An existing Docker client instance.\n            If None, a new client is created from the local Docker environment. Defaults to None.\n        image (str, optional): The Docker image to use, which should have Micromamba installed.\n            Defaults to \"mambaorg/micromamba:latest\".\n        dockerfile (str | None, optional): Path to a Dockerfile to build a custom image.\n            The resulting image should have Micromamba. Defaults to None.\n        lang (str, optional): The primary programming language. This mainly influences default file\n            extensions for code execution. Defaults to SupportedLanguage.PYTHON.\n        keep_template (bool, optional): If True, the Docker image will not be removed after the\n            session ends. Defaults to False.\n        verbose (bool, optional): If True, print detailed log messages. Defaults to False.\n        mounts (list[Mount] | None, optional): A list of Docker `Mount` objects to be mounted\n            into the container. Defaults to None.\n        environment (str, optional): The name of the Micromamba environment to activate and run\n            commands within (e.g., \"base\", \"my_env\"). Defaults to \"base\".\n        commit_container (bool, optional): If True, the Docker container's state will be committed\n            to a new image after the session ends. Defaults to False.\n        stream (bool, optional): If True, the output from `execute_command` will be streamed.\n            Defaults to True.\n        runtime_configs (dict | None, optional): Additional configurations for the container runtime.\n            Defaults to None.\n        workdir (str, optional): The working directory inside the container.\n            Defaults to \"/sandbox\".\n        security_policy (SecurityPolicy | None, optional): The security policy to use for the session.\n            Defaults to None.\n        default_timeout (float | None, optional): The default timeout for the session.\n            Defaults to None.\n        execution_timeout (float | None, optional): The execution timeout for the session.\n            Defaults to None.\n        session_timeout (float | None, optional): The session timeout for the session.\n            Defaults to None.\n        container_id (str | None, optional): ID of existing container to connect to.\n            Defaults to None.\n        skip_environment_setup (bool, optional): Skip language-specific environment setup.\n            Defaults to False.\n        **kwargs: Additional keyword arguments.\n\n    \"\"\"\n    super().__init__(\n        client=client,\n        image=image,\n        dockerfile=dockerfile,\n        lang=lang,\n        keep_template=keep_template,\n        verbose=verbose,\n        mounts=mounts,\n        commit_container=commit_container,\n        stream=stream,\n        runtime_configs=runtime_configs or {},\n        workdir=workdir,\n        security_policy=security_policy,\n        default_timeout=default_timeout,\n        execution_timeout=execution_timeout,\n        session_timeout=session_timeout,\n        container_id=container_id,\n        skip_environment_setup=skip_environment_setup,\n        **kwargs,\n    )\n\n    self.environment = environment\n\n    self.container_api = MicromambaContainerAPI(self.client, environment, stream)\n</code></pre>"},{"location":"api-reference/#llm_sandbox.micromamba.MicromambaSession-functions","title":"Functions","text":""},{"location":"api-reference/#type-hints","title":"Type Hints","text":""},{"location":"api-reference/#protocol-types","title":"Protocol Types","text":"<pre><code>class ContainerProtocol(Protocol):\n    \"\"\"Protocol for container objects\"\"\"\n\n    def execute_command(self, command: str, workdir: str | None = None) -&gt; Any:\n        ...\n\n    def get_archive(self, path: str) -&gt; tuple:\n        ...\n\n    def run(self, code: str, libraries: list | None = None) -&gt; Any:\n        ...\n</code></pre>"},{"location":"api-reference/#complete-example","title":"Complete Example","text":"<pre><code>from llm_sandbox import (\n    SandboxSession,\n    SandboxBackend,\n    ArtifactSandboxSession,\n    get_security_policy,\n    SecurityPolicy,\n    SecurityPattern,\n    SecurityIssueSeverity\n)\nfrom llm_sandbox.exceptions import SandboxTimeoutError\nimport base64\n\n# Basic usage\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"print('Hello, World!')\")\n    print(result.stdout)\n\n# With timeout configuration\nwith SandboxSession(\n    lang=\"python\",\n    execution_timeout=30.0,  # 30 seconds for code execution\n    session_timeout=300.0,   # 5 minutes session lifetime\n    default_timeout=10.0     # Default timeout for operations\n) as session:\n    try:\n        # This will use the execution_timeout (30s)\n        result = session.run(\"print('Normal execution')\")\n\n        # Override timeout for specific execution\n        result = session.run(\"\"\"\nimport time\ntime.sleep(5)\nprint('Long operation completed')\n        \"\"\", timeout=15.0)  # Override with 15 seconds\n\n    except SandboxTimeoutError as e:\n        print(f\"Operation timed out: {e}\")\n\n# With security policy\npolicy = get_security_policy(\"production\")\npolicy.add_pattern(SecurityPattern(\n    pattern=r\"requests\\.get\\(.*internal\\.company\",\n    description=\"Internal network access\",\n    severity=SecurityIssueSeverity.HIGH\n))\n\nwith SandboxSession(\n    lang=\"python\",\n    security_policy=policy,\n    runtime_configs={\n        \"cpu_count\": 2,\n        \"mem_limit\": \"512m\",\n        \"timeout\": 30\n    }\n) as session:\n    # Check code safety\n    code = \"import requests; requests.get('https://api.example.com')\"\n    is_safe, violations = session.is_safe(code)\n\n    if is_safe:\n        result = session.run(code, libraries=[\"requests\"])\n        print(result.stdout)\n    else:\n        print(\"Code failed security check\")\n\n# With artifact extraction\nwith ArtifactSandboxSession(\n    lang=\"python\",\n    backend=SandboxBackend.DOCKER\n) as session:\n    result = session.run(\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.title('Sine Wave')\nplt.show()\n    \"\"\", libraries=[\"matplotlib\", \"numpy\"])\n\n    # Save plots\n    for i, plot in enumerate(result.plots):\n        with open(f\"plot_{i}.{plot.format.value}\", \"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n\n# Kubernetes backend\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    lang=\"python\",\n    kube_namespace=\"default\",\n    pod_manifest={\n        \"spec\": {\n            \"containers\": [{\n                \"resources\": {\n                    \"limits\": {\n                        \"memory\": \"512Mi\",\n                        \"cpu\": \"1\"\n                    }\n                }\n            }]\n        }\n    }\n) as session:\n    result = session.run(\"print('Running in Kubernetes!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"backends/","title":"Container Backends","text":"<p>LLM Sandbox supports multiple container backends to suit different infrastructure needs. This guide covers each backend's features, configuration, and best practices.</p>"},{"location":"backends/#overview","title":"Overview","text":"<p>Supported backends:</p> Backend Use Case Root Access Orchestration Performance Docker Development, single-host Yes Limited High Kubernetes Production, scalable Configurable Full High Podman Rootless security No (rootless) Limited High"},{"location":"backends/#docker-backend","title":"Docker Backend","text":""},{"location":"backends/#overview_1","title":"Overview","text":"<p>Docker is the default and most widely supported backend. It provides excellent performance and compatibility.</p>"},{"location":"backends/#installation","title":"Installation","text":"<pre><code># Install Docker\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n\n# Install LLM Sandbox with Docker support\npip install 'llm-sandbox[docker]'\n</code></pre>"},{"location":"backends/#basic-usage","title":"Basic Usage","text":"<pre><code>from llm_sandbox import SandboxSession, SandboxBackend\n\n# Default Docker backend\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"print('Hello from Docker!')\")\n    print(result.stdout)\n\n# Explicit Docker backend\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    lang=\"python\"\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#custom-docker-client","title":"Custom Docker Client","text":"<pre><code>import docker\n\n# Connect to remote Docker daemon\nclient = docker.DockerClient(\n    base_url='tcp://docker-host:2375',\n    version='auto',\n    timeout=30\n)\n\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    client=client,\n    lang=\"python\"\n) as session:\n    pass\n\n# Use Docker context\nclient = docker.DockerClient.from_env()\n</code></pre>"},{"location":"backends/#docker-specific-features","title":"Docker-Specific Features","text":""},{"location":"backends/#container-commit","title":"Container Commit","text":"<pre><code># Save container state after execution\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    lang=\"python\",\n    commit_container=True,\n    image=\"my-base-image:latest\"\n) as session:\n    # Install packages and setup environment\n    session.install([\"numpy\", \"pandas\", \"scikit-learn\"])\n    session.run(\"echo 'Environment configured'\")\n    # Container will be committed as my-base-image:latest\n</code></pre>"},{"location":"backends/#volume-mounts","title":"Volume Mounts","text":"<pre><code>from docker.types import Mount\n\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    lang=\"python\",\n    mounts=[\n        # Bind mount\n        Mount(\n            type=\"bind\",\n            source=\"/host/data\",\n            target=\"/container/data\",\n            read_only=True\n        ),\n        # Named volume\n        Mount(\n            type=\"volume\",\n            source=\"myvolume\",\n            target=\"/container/cache\"\n        ),\n        # Tmpfs mount\n        Mount(\n            type=\"tmpfs\",\n            target=\"/container/tmp\",\n            tmpfs_size=\"100m\"\n        )\n    ]\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#network-configuration","title":"Network Configuration","text":"<pre><code># No network access\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    runtime_configs={\"network_mode\": \"none\"}\n) as session:\n    pass\n\n# Custom network\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    runtime_configs={\"network_mode\": \"my_isolated_network\"}\n) as session:\n    pass\n\n# Host network (use with caution)\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    runtime_configs={\"network_mode\": \"host\"}\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#advanced-runtime-options","title":"Advanced Runtime Options","text":"<pre><code>with SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    lang=\"python\",\n    runtime_configs={\n        # Resource limits\n        \"cpu_count\": 2,\n        \"cpu_shares\": 1024,\n        \"cpu_period\": 100000,\n        \"cpu_quota\": 50000,\n        \"mem_limit\": \"512m\",\n        \"memswap_limit\": \"1g\",\n        \"pids_limit\": 100,\n\n        # Security options\n        \"privileged\": False,\n        \"read_only\": True,\n        \"cap_drop\": [\"ALL\"],\n        \"cap_add\": [\"DAC_OVERRIDE\"],\n        \"security_opt\": [\"no-new-privileges\"],\n\n        # User and group\n        \"user\": \"1000:1000\",\n        \"userns_mode\": \"host\",\n\n        # Environment\n        \"environment\": {\n            \"PYTHONUNBUFFERED\": \"1\",\n            \"CUSTOM_VAR\": \"value\"\n        },\n\n        # Devices\n        \"devices\": [\"/dev/sda:/dev/xvda:rwm\"],\n\n        # Logging\n        \"log_config\": {\n            \"type\": \"json-file\",\n            \"config\": {\"max-size\": \"10m\"}\n        }\n    }\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#docker-best-practices","title":"Docker Best Practices","text":"<ol> <li> <p>Use specific image tags <pre><code># Good\nimage=\"python:3.11.5-slim-bullseye\"\n\n# Avoid\nimage=\"python:latest\"\n</code></pre></p> </li> <li> <p>Clean up resources <pre><code># Remove containers and images after use\nwith SandboxSession(\n    keep_template=False,  # Remove image\n    runtime_configs={\"auto_remove\": True}  # Remove container\n) as session:\n    pass\n</code></pre></p> </li> <li> <p>Use multi-stage builds for custom images <pre><code># Dockerfile\nFROM python:3.11-slim as builder\nRUN pip install --user numpy pandas\n\nFROM python:3.11-slim\nCOPY --from=builder /root/.local /root/.local\n</code></pre></p> </li> </ol>"},{"location":"backends/#kubernetes-backend","title":"Kubernetes Backend","text":""},{"location":"backends/#overview_2","title":"Overview","text":"<p>Kubernetes backend is ideal for production deployments, offering scalability and orchestration features.</p>"},{"location":"backends/#installation_1","title":"Installation","text":"<pre><code># Install kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# Install LLM Sandbox with Kubernetes support\npip install 'llm-sandbox[k8s]'\n</code></pre>"},{"location":"backends/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from llm_sandbox import SandboxSession, SandboxBackend\n\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    lang=\"python\",\n    kube_namespace=\"default\"\n) as session:\n    result = session.run(\"print('Hello from Kubernetes!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"backends/#custom-kubernetes-configuration","title":"Custom Kubernetes Configuration","text":"<pre><code>from kubernetes import client, config\n\n# Load custom kubeconfig\nconfig.load_kube_config(config_file=\"~/.kube/custom-config\")\n\n# Or use in-cluster config\n# config.load_incluster_config()\n\nk8s_client = client.CoreV1Api()\n\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    client=k8s_client,\n    lang=\"python\",\n    kube_namespace=\"sandbox-namespace\"\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#custom-pod-manifests","title":"Custom Pod Manifests","text":"<pre><code># Basic pod customization\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    lang=\"python\",\n    pod_manifest={\n        \"apiVersion\": \"v1\",\n        \"kind\": \"Pod\",\n        \"metadata\": {\n            \"name\": \"sandbox-pod\",\n            \"namespace\": \"default\",\n            \"labels\": {\n                \"app\": \"llm-sandbox\",\n                \"environment\": \"production\"\n            },\n            \"annotations\": {\n                \"prometheus.io/scrape\": \"true\"\n            }\n        },\n        \"spec\": {\n            \"containers\": [{\n                \"name\": \"sandbox\",\n                \"image\": \"python:3.11-slim\",\n                \"resources\": {\n                    \"requests\": {\n                        \"memory\": \"256Mi\",\n                        \"cpu\": \"250m\"\n                    },\n                    \"limits\": {\n                        \"memory\": \"512Mi\",\n                        \"cpu\": \"500m\"\n                    }\n                },\n                \"securityContext\": {\n                    \"runAsNonRoot\": True,\n                    \"runAsUser\": 1000,\n                    \"readOnlyRootFilesystem\": True,\n                    \"allowPrivilegeEscalation\": False\n                }\n            }],\n            \"securityContext\": {\n                \"runAsNonRoot\": True,\n                \"fsGroup\": 2000\n            }\n        }\n    }\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#advanced-kubernetes-features","title":"Advanced Kubernetes Features","text":""},{"location":"backends/#persistent-volumes","title":"Persistent Volumes","text":"<pre><code>pod_manifest = {\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\"name\": \"sandbox-with-pv\"},\n    \"spec\": {\n        \"containers\": [{\n            \"name\": \"sandbox\",\n            \"image\": \"python:3.11\",\n            \"volumeMounts\": [{\n                \"name\": \"data-volume\",\n                \"mountPath\": \"/data\"\n            }]\n        }],\n        \"volumes\": [{\n            \"name\": \"data-volume\",\n            \"persistentVolumeClaim\": {\n                \"claimName\": \"sandbox-pvc\"\n            }\n        }]\n    }\n}\n</code></pre>"},{"location":"backends/#configmaps-and-secrets","title":"ConfigMaps and Secrets","text":"<pre><code>pod_manifest = {\n    \"spec\": {\n        \"containers\": [{\n            \"name\": \"sandbox\",\n            \"image\": \"python:3.11\",\n            \"env\": [\n                {\n                    \"name\": \"CONFIG_VALUE\",\n                    \"valueFrom\": {\n                        \"configMapKeyRef\": {\n                            \"name\": \"app-config\",\n                            \"key\": \"value\"\n                        }\n                    }\n                },\n                {\n                    \"name\": \"SECRET_VALUE\",\n                    \"valueFrom\": {\n                        \"secretKeyRef\": {\n                            \"name\": \"app-secret\",\n                            \"key\": \"password\"\n                        }\n                    }\n                }\n            ],\n            \"volumeMounts\": [\n                {\n                    \"name\": \"config\",\n                    \"mountPath\": \"/config\"\n                },\n                {\n                    \"name\": \"secret\",\n                    \"mountPath\": \"/secrets\"\n                }\n            ]\n        }],\n        \"volumes\": [\n            {\n                \"name\": \"config\",\n                \"configMap\": {\"name\": \"app-config\"}\n            },\n            {\n                \"name\": \"secret\",\n                \"secret\": {\"secretName\": \"app-secret\"}\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"backends/#node-affinity","title":"Node Affinity","text":"<pre><code>pod_manifest = {\n    \"spec\": {\n        \"affinity\": {\n            \"nodeAffinity\": {\n                \"requiredDuringSchedulingIgnoredDuringExecution\": {\n                    \"nodeSelectorTerms\": [{\n                        \"matchExpressions\": [{\n                            \"key\": \"node-type\",\n                            \"operator\": \"In\",\n                            \"values\": [\"sandbox\"]\n                        }]\n                    }]\n                }\n            }\n        },\n        \"tolerations\": [{\n            \"key\": \"sandbox\",\n            \"operator\": \"Equal\",\n            \"value\": \"true\",\n            \"effect\": \"NoSchedule\"\n        }]\n    }\n}\n</code></pre>"},{"location":"backends/#kubernetes-best-practices","title":"Kubernetes Best Practices","text":"<ol> <li> <p>Resource Limits <pre><code># Always set resource requests and limits\n\"resources\": {\n    \"requests\": {\"memory\": \"256Mi\", \"cpu\": \"250m\"},\n    \"limits\": {\"memory\": \"512Mi\", \"cpu\": \"500m\"}\n}\n</code></pre></p> </li> <li> <p>Security Context <pre><code># Run as non-root with restricted permissions\n\"securityContext\": {\n    \"runAsNonRoot\": True,\n    \"runAsUser\": 1000,\n    \"readOnlyRootFilesystem\": True\n}\n</code></pre></p> </li> <li> <p>Namespace Isolation <pre><code># Use dedicated namespaces\nkube_namespace=\"llm-sandbox-prod\"\n</code></pre></p> </li> </ol>"},{"location":"backends/#podman-backend","title":"Podman Backend","text":""},{"location":"backends/#overview_3","title":"Overview","text":"<p>Podman provides rootless containers for enhanced security, making it ideal for security-conscious environments.</p>"},{"location":"backends/#installation_2","title":"Installation","text":"<pre><code># Install Podman (Ubuntu/Debian)\nsudo apt-get update\nsudo apt-get install -y podman\n\n# Install LLM Sandbox with Podman support\npip install 'llm-sandbox[podman]'\n</code></pre>"},{"location":"backends/#basic-usage_2","title":"Basic Usage","text":"<pre><code>from podman import PodmanClient\nfrom llm_sandbox import SandboxSession, SandboxBackend\n\n# Create Podman client\nclient = PodmanClient(\n    base_url=\"unix:///run/user/1000/podman/podman.sock\"\n)\n\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Hello from Podman!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"backends/#rootless-configuration","title":"Rootless Configuration","text":"<pre><code># Rootless Podman with user namespace\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    lang=\"python\",\n    runtime_configs={\n        \"userns_mode\": \"keep-id\",  # Keep user ID\n        \"user\": \"1000:1000\",\n        \"security_opt\": [\n            \"no-new-privileges\",\n            \"seccomp=unconfined\"  # If needed\n        ]\n    },\n    workdir=\"/tmp/sandbox\"  # Writable for non-root\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#podman-specific-features","title":"Podman-Specific Features","text":""},{"location":"backends/#podman-pods","title":"Podman Pods","text":"<pre><code># Create a pod first\nclient.pods.create(\n    name=\"sandbox-pod\",\n    labels={\"app\": \"llm-sandbox\"}\n)\n\n# Run container in pod\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    runtime_configs={\n        \"pod\": \"sandbox-pod\"\n    }\n) as session:\n    pass\n</code></pre>"},{"location":"backends/#systemd-integration","title":"Systemd Integration","text":"<pre><code># Generate systemd unit\ncontainer = session.container\nunit = container.generate_systemd(\n    name=\"llm-sandbox\",\n    restart_policy=\"on-failure\",\n    time=10\n)\n</code></pre>"},{"location":"backends/#podman-best-practices","title":"Podman Best Practices","text":"<ol> <li> <p>Use rootless mode <pre><code># Run as regular user\nclient = PodmanClient(\n    base_url=f\"unix:///run/user/{os.getuid()}/podman/podman.sock\"\n)\n</code></pre></p> </li> <li> <p>User namespace mapping <pre><code>runtime_configs={\"userns_mode\": \"keep-id\"}\n</code></pre></p> </li> </ol>"},{"location":"backends/#use-case-recommendations","title":"Use Case Recommendations","text":"<ol> <li>Development: Docker or Podman for fast iteration and easy debugging</li> <li>Production: Kubernetes for scalability and enterprise features</li> <li>Security-Critical: Podman for rootless containers and SELinux integration</li> </ol>"},{"location":"backends/#multi-backend-support","title":"Multi-Backend Support","text":""},{"location":"backends/#backend-fallback","title":"Backend Fallback","text":"<pre><code>def create_session_with_fallback(**kwargs):\n    \"\"\"Try multiple backends in order\"\"\"\n    backends = [\n        (SandboxBackend.DOCKER, {}),\n        (SandboxBackend.PODMAN, {\"client\": get_podman_client()}),\n        (SandboxBackend.KUBERNETES, {\"kube_namespace\": \"default\"}),\n    ]\n\n    for backend, backend_kwargs in backends:\n        try:\n            return SandboxSession(\n                backend=backend,\n                **kwargs,\n                **backend_kwargs\n            )\n        except Exception as e:\n            print(f\"Backend {backend} failed: {e}\")\n            continue\n\n    raise RuntimeError(\"No available backends\")\n</code></pre>"},{"location":"backends/#backend-detection","title":"Backend Detection","text":"<pre><code>import subprocess\n\ndef detect_available_backends():\n    \"\"\"Detect which backends are available\"\"\"\n    available = []\n\n    # Check Docker\n    try:\n        subprocess.run([\"docker\", \"--version\"],\n                      capture_output=True, check=True)\n        available.append(SandboxBackend.DOCKER)\n    except:\n        pass\n\n    # Check Podman\n    try:\n        subprocess.run([\"podman\", \"--version\"],\n                      capture_output=True, check=True)\n        available.append(SandboxBackend.PODMAN)\n    except:\n        pass\n\n    # Check Kubernetes\n    try:\n        subprocess.run([\"kubectl\", \"version\", \"--client\"],\n                      capture_output=True, check=True)\n        available.append(SandboxBackend.KUBERNETES)\n    except:\n        pass\n\n    return available\n</code></pre>"},{"location":"backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"backends/#docker-issues","title":"Docker Issues","text":"<pre><code># Permission denied\nsudo usermod -aG docker $USER\nnewgrp docker\n\n# Cannot connect to daemon\nsudo systemctl start docker\ndocker context use default\n</code></pre>"},{"location":"backends/#kubernetes-issues","title":"Kubernetes Issues","text":"<pre><code># No access to cluster\nkubectl config view\nkubectl auth can-i create pods\n\n# Pod stuck in pending\nkubectl describe pod &lt;pod-name&gt;\nkubectl get events\n</code></pre>"},{"location":"backends/#podman-issues","title":"Podman Issues","text":"<pre><code># Rootless setup\npodman system migrate\npodman unshare cat /etc/subuid\n\n# Socket not found\nsystemctl --user start podman.socket\n</code></pre>"},{"location":"backends/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Supported Languages</li> <li>Configure Security Policies</li> <li>Explore Integration Options</li> <li>See practical Examples</li> </ul>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>This guide covers all configuration options available in LLM Sandbox.</p>"},{"location":"configuration/#session-configuration","title":"Session Configuration","text":""},{"location":"configuration/#basic-parameters","title":"Basic Parameters","text":"<pre><code>from llm_sandbox import SandboxSession\n\nsession = SandboxSession(\n    lang=\"python\",              # Programming language\n    verbose=True,               # Enable verbose logging\n    keep_template=False,        # Keep container image after session\n    workdir=\"/sandbox\",         # Working directory in container\n)\n</code></pre>"},{"location":"configuration/#environment-setup-control","title":"Environment Setup Control","text":"<p>LLM Sandbox automatically sets up language-specific environments during container initialization (e.g., creating Python virtual environments, upgrading pip, initializing Go modules). For production deployments or when using custom pre-configured images, you can skip this setup for faster startup times.</p>"},{"location":"configuration/#skip_environment_setup-parameter","title":"skip_environment_setup Parameter","text":"<p>The <code>skip_environment_setup</code> parameter allows you to bypass automatic environment setup:</p> <pre><code>from llm_sandbox import SandboxSession, SandboxBackend\n\n# Skip environment setup for faster container startup\nwith SandboxSession(\n    lang=\"python\",\n    skip_environment_setup=True,  # Skip pip upgrades and venv creation\n    verbose=True\n) as session:\n    result = session.run(\"print('Hello from pre-configured environment!')\")\n</code></pre>"},{"location":"configuration/#when-to-use-skip_environment_setuptrue","title":"When to Use skip_environment_setup=True","text":"<p>\u2705 Recommended for:</p> <ul> <li>Production deployments where container startup time is critical</li> <li>Custom images with pre-installed packages and configured environments</li> <li>CI/CD pipelines where environment setup adds unnecessary overhead</li> <li>Air-gapped environments where external package repositories aren't accessible</li> <li>Batch processing where you want predictable, pre-configured setups</li> </ul> <p>\u274c Not recommended for:</p> <ul> <li>Development and testing with dynamic package installation</li> <li>Using base images without pre-configured language environments</li> <li>Scenarios requiring on-the-fly library installation</li> </ul>"},{"location":"configuration/#production-deployment-examples","title":"Production Deployment Examples","text":"<p>Docker with custom image: <pre><code>with SandboxSession(\n    lang=\"python\",\n    backend=SandboxBackend.DOCKER,\n    skip_environment_setup=True,\n    image=\"my-registry.com/python-ml:latest\",  # Pre-installed ML packages\n) as session:\n    result = session.run(\"import numpy as np; print(f'NumPy: {np.__version__}')\")\n</code></pre></p> <p>Kubernetes: <pre><code>with SandboxSession(\n    lang=\"python\",\n    backend=SandboxBackend.KUBERNETES,\n    skip_environment_setup=True,\n    image=\"my-registry.com/python-ml:latest\",\n) as session:\n    result = session.run(\"import pandas as pd; print(f'Pandas: {pd.__version__}')\")\n</code></pre></p> <p>Podman for rootless containers: <pre><code>with SandboxSession(\n    lang=\"python\",\n    backend=SandboxBackend.PODMAN,\n    skip_environment_setup=True,\n    image=\"my-registry.com/python-secure:latest\"\n) as session:\n    result = session.run(\"print('Secure environment ready!')\")\n</code></pre></p>"},{"location":"configuration/#custom-image-requirements","title":"Custom Image Requirements","text":"<p>When using <code>skip_environment_setup=True</code>, ensure your custom image includes:</p> <p>For Python:</p> <ul> <li>Python interpreter in expected location (usually <code>/usr/bin/python</code> or <code>/usr/local/bin/python</code>)</li> <li>Required packages pre-installed (numpy, pandas, etc.)</li> <li>Proper PATH configuration</li> </ul> <p>For Other Languages:</p> <ul> <li>Language runtime properly installed and configured</li> <li>Standard libraries and common packages available</li> <li>Appropriate environment variables set</li> </ul>"},{"location":"configuration/#library-installation-behavior","title":"Library Installation Behavior","text":"<p>When <code>skip_environment_setup=True</code>:</p> <ul> <li>\u2705 Code execution works normally</li> <li>\u274c Dynamic library installation is disabled</li> <li>\ud83d\udce6 Libraries must be pre-installed in the container image</li> </ul> <pre><code># This will fail with skip_environment_setup=True\nresult = session.run(\n    \"import requests; print('OK')\",\n    libraries=[\"requests\"]  # \u274c Will raise LibraryInstallationNotSupportedError\n)\n\n# Instead, use execute_command for manual installation if needed\nsession.execute_command(\"pip install requests\")\nresult = session.run(\"import requests; print('OK')\")  # \u2705 Works\n</code></pre>"},{"location":"configuration/#timeout-configuration","title":"Timeout Configuration","text":"<p>LLM Sandbox provides comprehensive timeout controls to prevent runaway code execution and manage resource usage efficiently.</p>"},{"location":"configuration/#timeout-types","title":"Timeout Types","text":"<p>There are three types of timeouts you can configure:</p> Timeout Type Description Default <code>default_timeout</code> Default timeout for all operations 30.0 seconds <code>execution_timeout</code> Timeout for code execution (per run) Uses <code>default_timeout</code> <code>session_timeout</code> Maximum session lifetime None (unlimited)"},{"location":"configuration/#basic-timeout-configuration","title":"Basic Timeout Configuration","text":"<pre><code>from llm_sandbox import SandboxSession\n\n# Configure timeouts at session creation\nwith SandboxSession(\n    lang=\"python\",\n    default_timeout=30.0,      # Default timeout for operations\n    execution_timeout=60.0,    # Timeout for code execution\n    session_timeout=300.0,     # Session expires after 5 minutes\n    verbose=True\n) as session:\n    # Fast operation - should complete\n    result = session.run(\"\"\"\nprint(\"Hello, World!\")\nimport time\ntime.sleep(2)\nprint(\"Operation completed\")\n    \"\"\")\n</code></pre>"},{"location":"configuration/#per-execution-timeout-override","title":"Per-Execution Timeout Override","text":"<p>You can override the execution timeout for individual <code>run()</code> calls:</p> <pre><code>with SandboxSession(lang=\"python\", execution_timeout=10.0) as session:\n    # This will use the session's execution_timeout (10 seconds)\n    result1 = session.run(\"print('Normal execution')\")\n\n    # Override with a longer timeout for this specific execution\n    result2 = session.run(\"\"\"\nimport time\ntime.sleep(15)  # This needs more time\nprint(\"Long operation completed\")\n    \"\"\", timeout=20.0)  # Override with 20 seconds\n\n    # Override with a shorter timeout\n    try:\n        session.run(\"\"\"\nimport time\ntime.sleep(5)\nprint(\"This might timeout\")\n        \"\"\", timeout=2.0)  # Override with 2 seconds\n    except SandboxTimeoutError:\n        print(\"Operation timed out as expected\")\n</code></pre>"},{"location":"configuration/#timeout-error-handling","title":"Timeout Error Handling","text":"<pre><code>from llm_sandbox.exceptions import SandboxTimeoutError\n\ndef execute_with_retry(session, code, max_retries=3):\n    \"\"\"Execute code with automatic retry on timeout.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return session.run(code, timeout=10.0)\n        except SandboxTimeoutError:\n            print(f\"Attempt {attempt + 1} timed out\")\n            if attempt == max_retries - 1:\n                raise\n            print(\"Retrying...\")\n\n# Usage example\nwith SandboxSession(lang=\"python\") as session:\n    try:\n        result = execute_with_retry(session, \"\"\"\nimport time\nimport random\ntime.sleep(random.uniform(5, 15))  # Variable execution time\nprint(\"Completed!\")\n        \"\"\")\n        print(result.stdout)\n    except SandboxTimeoutError:\n        print(\"All retry attempts failed\")\n</code></pre>"},{"location":"configuration/#backend-specific-timeout-behavior","title":"Backend-Specific Timeout Behavior","text":"<p>Different backends handle timeouts differently:</p>"},{"location":"configuration/#docker-podman","title":"Docker &amp; Podman","text":"<ul> <li>Containers are forcefully killed when timeout is reached</li> <li>Container cleanup is automatic</li> <li>Resource usage monitoring during execution</li> </ul>"},{"location":"configuration/#kubernetes","title":"Kubernetes","text":"<ul> <li>Pods are monitored for timeout during command execution</li> <li>Timeout applies to individual command execution within the pod</li> <li>Pod lifecycle is managed independently</li> </ul>"},{"location":"configuration/#advanced-timeout-scenarios","title":"Advanced Timeout Scenarios","text":""},{"location":"configuration/#infinite-loop-protection","title":"Infinite Loop Protection","text":"<pre><code>with SandboxSession(lang=\"python\", execution_timeout=5.0) as session:\n    try:\n        session.run(\"\"\"\n# This infinite loop will be terminated\ni = 0\nwhile True:\n    i += 1\n    if i % 100000 == 0:\n        print(f\"Iteration: {i}\")\n        \"\"\")\n    except SandboxTimeoutError:\n        print(\"Infinite loop was terminated by timeout\")\n</code></pre>"},{"location":"configuration/#resource-intensive-operation-control","title":"Resource-Intensive Operation Control","text":"<pre><code>with SandboxSession(lang=\"python\") as session:\n    try:\n        session.run(\"\"\"\n# CPU-intensive operation\ntotal = 0\nfor i in range(10**8):  # Large computation\n    total += i * i\nprint(f\"Result: {total}\")\n        \"\"\", timeout=30.0)  # Give enough time for legitimate computation\n    except SandboxTimeoutError:\n        print(\"Computation took too long and was terminated\")\n</code></pre>"},{"location":"configuration/#session-lifetime-management","title":"Session Lifetime Management","text":"<pre><code>import time\n\n# Session that automatically expires\nwith SandboxSession(\n    lang=\"python\",\n    session_timeout=60.0  # Session expires after 1 minute\n) as session:\n\n    # This will work\n    session.run(\"print('First execution')\")\n\n    # Wait and try again\n    time.sleep(30)\n    session.run(\"print('Second execution')\")\n\n    # This might fail if session has expired\n    time.sleep(40)  # Total elapsed: 70 seconds\n    try:\n        session.run(\"print('This might fail')\")\n    except SandboxTimeoutError:\n        print(\"Session expired\")\n</code></pre>"},{"location":"configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Set Appropriate Timeouts: Balance between allowing legitimate long operations and preventing runaway code</li> <li>Use Per-Execution Overrides: Override timeouts for known long-running operations</li> <li>Implement Retry Logic: Handle timeout errors gracefully with retry mechanisms</li> <li>Monitor Resource Usage: Use timeout in combination with resource limits</li> <li>Log Timeout Events: Enable verbose logging to understand timeout patterns</li> </ol>"},{"location":"configuration/#language-options","title":"Language Options","text":"<p>Supported languages and their identifiers:</p> Language Identifier Default Image Python <code>python</code> <code>ghcr.io/vndee/sandbox-python-311-bullseye</code> JavaScript <code>javascript</code> <code>ghcr.io/vndee/sandbox-node-22-bullseye</code> Java <code>java</code> <code>ghcr.io/vndee/sandbox-java-11-bullseye</code> C++ <code>cpp</code> <code>ghcr.io/vndee/sandbox-cpp-11-bullseye</code> Go <code>go</code> <code>ghcr.io/vndee/sandbox-go-123-bullseye</code> Ruby <code>ruby</code> <code>ghcr.io/vndee/sandbox-ruby-302-bullseye</code>"},{"location":"configuration/#container-images","title":"Container Images","text":""},{"location":"configuration/#using-default-images","title":"Using Default Images","text":"<pre><code># Uses default Python image\nwith SandboxSession(lang=\"python\") as session:\n    pass\n</code></pre>"},{"location":"configuration/#using-custom-images","title":"Using Custom Images","text":"<pre><code># Use a specific image\nwith SandboxSession(\n    lang=\"python\",\n    image=\"python:3.12-slim\"\n) as session:\n    pass\n\n# Use your own custom image\nwith SandboxSession(\n    lang=\"python\",\n    image=\"myregistry.com/my-python:latest\"\n) as session:\n    pass\n</code></pre>"},{"location":"configuration/#building-from-dockerfile","title":"Building from Dockerfile","text":"<pre><code># Build image from Dockerfile\nwith SandboxSession(\n    lang=\"python\",\n    dockerfile=\"./custom/Dockerfile\"\n) as session:\n    pass\n</code></pre> <p>Example Dockerfile: <pre><code>FROM python:3.11-slim\n\n# Install additional system packages\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Pre-install Python packages\nRUN pip install numpy pandas matplotlib\n\nWORKDIR /sandbox\n</code></pre></p>"},{"location":"configuration/#runtime-configuration","title":"Runtime Configuration","text":"<p>Important: Runtime configurations work differently depending on the backend:</p>"},{"location":"configuration/#docker-and-podman-backends","title":"Docker and Podman Backends","text":"<p>For Docker and Podman backends, runtime configuration options are passed as extra arguments to the respective Python libraries (<code>docker-py</code> and <code>podman-py</code>). These are used to configure container creation and execution parameters.</p>"},{"location":"configuration/#docker-runtime-config","title":"Docker Runtime Config","text":"<pre><code># Docker-specific runtime configuration\nruntime_configs = {\n    \"privileged\": False,\n    \"memory\": \"512m\",\n    \"cpu_period\": 100000,\n    \"cpu_quota\": 50000,\n    \"network_mode\": \"bridge\",\n    \"volumes\": {\"/host/path\": {\"bind\": \"/container/path\", \"mode\": \"ro\"}},\n    \"environment\": {\"PYTHONPATH\": \"/app\"},\n    \"working_dir\": \"/workspace\"\n}\n\nsession = SandboxSession(\n    image=\"python:3.9\",\n    backend=\"docker\",\n    runtime_configs=runtime_configs\n)\n</code></pre> <p>Docker Documentation: See the Docker SDK for Python documentation for complete API reference and available parameters.</p>"},{"location":"configuration/#podman-runtime-config","title":"Podman Runtime Config","text":"<pre><code># Podman-specific runtime configuration\nruntime_config = {\n    \"privileged\": False,\n    \"memory\": \"512m\",\n    \"cpu_shares\": 512,\n    \"network_mode\": \"bridge\",\n    \"volumes\": {\"/host/path\": {\"bind\": \"/container/path\", \"mode\": \"ro\"}},\n    \"environment\": {\"PYTHONPATH\": \"/app\"},\n    \"working_dir\": \"/workspace\"\n}\n\nsession = SandboxSession(\n    image=\"python:3.9\",\n    backend=\"podman\",\n    runtime_configs=runtime_configs\n)\n</code></pre> <p>Podman Documentation: See the Podman Python SDK documentation for complete API reference and available parameters.</p>"},{"location":"configuration/#kubernetes-backend","title":"Kubernetes Backend","text":"<p>For Kubernetes, runtime configurations are not supported through the <code>runtime_configs</code> parameter. Instead, users should define their requirements as Kubernetes Pod manifests using the <code>pod_manifest</code> parameter.</p> <pre><code># Kubernetes configuration using pod_manifest parameter\nimport uuid\n\n# Generate unique pod name to avoid conflicts\nunique_suffix = str(uuid.uuid4())[:8]\npod_name = f\"sandbox-{unique_suffix}\"\n\n# Define custom pod manifest\npod_manifest = {\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"name\": pod_name,\n        \"labels\": {\"app\": \"sandbox\"},\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"name\": \"sandbox-container\",\n                \"image\": \"python:3.9\",\n                \"tty\": True,\n                \"securityContext\": {\n                    \"runAsUser\": 1000,\n                    \"runAsGroup\": 1000,\n                },\n                \"resources\": {\n                    \"limits\": {\n                        \"memory\": \"512Mi\",\n                        \"cpu\": \"500m\"\n                    },\n                    \"requests\": {\n                        \"memory\": \"256Mi\",\n                        \"cpu\": \"250m\"\n                    }\n                }\n            }\n        ],\n        \"securityContext\": {\n            \"runAsUser\": 1000,\n            \"runAsGroup\": 1000,\n        },\n    },\n}\n\nsession = SandboxSession(\n    backend=\"kubernetes\",\n    lang=\"python\",\n    image=\"python:3.9\",\n    pod_manifest=pod_manifest,\n    workdir=\"/tmp/sandbox\"  # Use writable directory for non-root\n)\n</code></pre>"},{"location":"configuration/#critical-pod-manifest-requirements","title":"\u26a0\ufe0f Critical Pod Manifest Requirements","text":"<p>When providing custom pod manifests, these configurations are mandatory for proper operation:</p> <p>Required Container Configurations: <pre><code>{\n    \"name\": \"my-container\",       # Can be any valid container name\n    \"image\": \"your-image:latest\",\n    \"tty\": True,                  # REQUIRED: Keeps container alive for command execution\n    \"securityContext\": {          # REQUIRED: For proper file permissions\n        \"runAsUser\": 0,\n        \"runAsGroup\": 0,\n    },\n    # Your other settings...\n}\n</code></pre></p> <p>Required Pod-Level Configuration: <pre><code>{\n    \"spec\": {\n        \"containers\": [...],\n        \"securityContext\": {      # REQUIRED: Pod-level security context\n            \"runAsUser\": 0,\n            \"runAsGroup\": 0,\n        },\n    }\n}\n</code></pre></p> <p>\u26a0\ufe0f Common Issues:</p> <ul> <li>Pod exits immediately: Missing <code>\"tty\": True</code> configuration</li> <li>Permission denied errors: Missing or incorrect <code>securityContext</code> configurations</li> <li>Connection timeouts: Pod may not be fully  ready - ensure proper resource limits and image availability</li> </ul>"},{"location":"configuration/#additional-kubernetes-configuration","title":"Additional Kubernetes Configuration","text":"<p>To configure resources, security context, volumes, and other Pod-level settings in Kubernetes, you should:</p> <ol> <li>Create a Pod manifest file or use the Kubernetes Python client directly</li> <li>Apply resource limits, security policies, and other configurations through Kubernetes APIs</li> <li>Use ConfigMaps and Secrets for environment configuration</li> </ol> <p>Kubernetes Documentation: See the Kubernetes Python Client documentation and Kubernetes API reference for Pod configuration options.</p>"},{"location":"configuration/#example-runtime-configurations","title":"Example Runtime Configurations","text":""},{"location":"configuration/#resource-limits-dockerpodman","title":"Resource Limits (Docker/Podman)","text":"<pre><code># Memory and CPU limits\nruntime_configs = {\n    \"memory\": \"1g\",           # 1GB memory limit\n    \"cpu_period\": 100000,     # CPU period in microseconds\n    \"cpu_quota\": 50000,       # CPU quota (50% of one CPU)\n    \"memswap_limit\": \"2g\"     # Memory + swap limit\n}\n</code></pre>"},{"location":"configuration/#network-configuration-dockerpodman","title":"Network Configuration (Docker/Podman)","text":"<pre><code># Custom network settings\nruntime_configs = {\n    \"network_mode\": \"host\",        # Use host networking\n    \"ports\": {\"8080/tcp\": 8080},   # Port mapping\n    \"dns\": [\"8.8.8.8\", \"8.8.4.4\"] # Custom DNS servers\n}\n</code></pre>"},{"location":"configuration/#volume-mounts-dockerpodman","title":"Volume Mounts (Docker/Podman)","text":"<pre><code># Volume mounting\nruntime_configs = {\n    \"volumes\": {\n        \"/host/data\": {\"bind\": \"/data\", \"mode\": \"rw\"},\n        \"/host/config\": {\"bind\": \"/config\", \"mode\": \"ro\"}\n    }\n}\n</code></pre>"},{"location":"configuration/#environment-variables-dockerpodman","title":"Environment Variables (Docker/Podman)","text":"<pre><code># Environment configuration\nruntime_configs = {\n    \"environment\": {\n        \"PYTHONPATH\": \"/app:/libs\",\n        \"DEBUG\": \"true\",\n        \"API_KEY\": \"your-api-key\"\n    }\n}\n</code></pre>"},{"location":"configuration/#security-configuration-dockerpodman","title":"Security Configuration (Docker/Podman)","text":"<pre><code># Security settings\nruntime_configs = {\n    \"privileged\": False,\n    \"user\": \"1000:1000\",           # Run as specific user/group\n    \"cap_drop\": [\"ALL\"],           # Drop all capabilities\n    \"cap_add\": [\"NET_ADMIN\"],      # Add specific capabilities\n    \"security_opt\": [\"no-new-privileges:true\"]\n}\n</code></pre>"},{"location":"configuration/#backend-specific-documentation-links","title":"Backend-Specific Documentation Links","text":"<ul> <li>Docker: Docker SDK for Python - Complete API reference for container configuration</li> <li>Podman: Podman Python SDK - Complete API reference for Podman container management</li> <li>Kubernetes: Kubernetes Python Client - Official Kubernetes API client documentation</li> </ul> <p>For detailed parameter lists and advanced configuration options, please refer to the respective documentation links above.</p>"},{"location":"configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"configuration/#security-policies","title":"Security Policies","text":"<pre><code>from llm_sandbox.security import (\n    SecurityPolicy,\n    SecurityPattern,\n    RestrictedModule,\n    SecurityIssueSeverity\n)\n\n# Create custom security policy\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[\n        SecurityPattern(\n            pattern=r\"os\\.system\",\n            description=\"System command execution\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        SecurityPattern(\n            pattern=r\"open\\s*\\([^)]*['\\\"][wa]\",\n            description=\"File write operation\",\n            severity=SecurityIssueSeverity.MEDIUM\n        )\n    ],\n    restricted_modules=[\n        RestrictedModule(\n            name=\"subprocess\",\n            description=\"Process execution\",\n            severity=SecurityIssueSeverity.HIGH\n        )\n    ]\n)\n\nwith SandboxSession(lang=\"python\", security_policy=policy) as session:\n    pass\n</code></pre> <p>For more information, see the Security Policies page.</p>"},{"location":"configuration/#custom-client-configuration","title":"Custom Client Configuration","text":"<p>By default, LLM Sandbox uses the standard client initialization for each backend:</p> <ul> <li>Docker: <code>docker.from_env()</code></li> <li>Podman: <code>PodmanClient()</code></li> <li>Kubernetes: Loads from <code>~/.kube/config</code></li> </ul> <p>However, you can provide your own client instances to connect to remote servers, custom sockets, or clusters with specific configurations.</p>"},{"location":"configuration/#docker-remote-connection","title":"Docker Remote Connection","text":"<pre><code>import docker\n\n# Connect to remote Docker daemon\nclient = docker.DockerClient(\n    base_url=\"tcp://remote-docker-host:2376\",\n    tls=True,\n    timeout=30\n)\n\nwith SandboxSession(\n    backend=\"docker\",\n    client=client,  # Use custom client instead of docker.from_env()\n    lang=\"python\"\n) as session:\n    pass\n</code></pre>"},{"location":"configuration/#podman-custom-socket","title":"Podman Custom Socket","text":"<pre><code>from podman import PodmanClient\n\n# Connect to custom Podman socket\nclient = PodmanClient(\n    base_url=\"unix:///run/user/1000/podman/podman.sock\",\n    timeout=60\n)\n\nwith SandboxSession(\n    backend=\"podman\",\n    client=client,  # Use custom client\n    lang=\"python\"\n) as session:\n    pass\n</code></pre>"},{"location":"configuration/#kubernetes-remote-cluster","title":"Kubernetes Remote Cluster","text":"<pre><code>from kubernetes import client, config\n\n# Load config from custom file or remote cluster\nconfig.load_kube_config(\n    config_file=\"/path/to/custom/kubeconfig\",\n    context=\"remote-cluster-context\"\n)\n\n# Or configure for remote cluster programmatically\nconfiguration = client.Configuration()\nconfiguration.host = \"https://k8s-cluster.example.com:6443\"\nconfiguration.api_key_prefix['authorization'] = 'Bearer'\nconfiguration.api_key['authorization'] = 'your-token-here'\n\nk8s_client = client.CoreV1Api(client.ApiClient(configuration))\n\nwith SandboxSession(\n    backend=\"kubernetes\",\n    client=k8s_client,  # Use custom configured client\n    lang=\"python\",\n    kube_namespace=\"custom-namespace\"\n) as session:\n    pass\n</code></pre>"},{"location":"configuration/#docker-with-custom-tls-configuration","title":"Docker with Custom TLS Configuration","text":"<pre><code>import docker\nimport ssl\n\n# Docker with custom TLS/SSL settings\ntls_config = docker.tls.TLSConfig(\n    client_cert=('/path/to/client-cert.pem', '/path/to/client-key.pem'),\n    ca_cert='/path/to/ca.pem',\n    verify=True\n)\n\nclient = docker.DockerClient(\n    base_url=\"tcp://secure-docker-host:2376\",\n    tls=tls_config\n)\n\nwith SandboxSession(backend=\"docker\", client=client, lang=\"python\") as session:\n    pass\n</code></pre>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#artifact-extraction","title":"Artifact Extraction","text":"<pre><code>from llm_sandbox import ArtifactSandboxSession\n\nwith ArtifactSandboxSession(\n    lang=\"python\",\n    enable_plotting=True,\n    verbose=True\n) as session:\n    result = session.run(\"\"\"\nimport matplotlib.pyplot as plt\nplt.plot([1, 2, 3], [1, 4, 9])\nplt.show()\n    \"\"\")\n\n    # Access captured plots\n    for plot in result.plots:\n        print(f\"Plot format: {plot.format}\")\n        print(f\"Plot size: {len(plot.content_base64)} bytes\")\n</code></pre>"},{"location":"configuration/#custom-language-handlers","title":"Custom Language Handlers","text":"<pre><code>from llm_sandbox.language_handlers import AbstractLanguageHandler\nfrom llm_sandbox.language_handlers.factory import LanguageHandlerFactory\n\nclass CustomLanguageHandler(AbstractLanguageHandler):\n    def __init__(self, logger=None):\n        super().__init__(logger)\n        self.config = LanguageConfig(\n            name=\"custom\",\n            file_extension=\"custom\",\n            execution_commands=[\"custom-runner {file}\"],\n            package_manager=\"custom-pm install\"\n        )\n\n    def get_import_patterns(self, module):\n        return rf\"import\\s+{module}\"\n\n    # Implement other required methods...\n\n# Register custom handler\nLanguageHandlerFactory.register_handler(\"custom\", CustomLanguageHandler)\n\n# Use custom language\nwith SandboxSession(lang=\"custom\") as session:\n    pass\n</code></pre>"},{"location":"configuration/#logging-configuration","title":"Logging Configuration","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Create logger\nlogger = logging.getLogger('llm_sandbox')\n\n# Use custom logger\nwith SandboxSession(\n    lang=\"python\",\n    logger=logger,\n    verbose=True\n) as session:\n    pass\n</code></pre>"},{"location":"configuration/#session-persistence","title":"Session Persistence","text":"<pre><code># Keep container running for reuse\nwith SandboxSession(\n    lang=\"python\",\n    keep_template=True,\n    commit_container=True\n) as session:\n    # Install packages\n    session.install([\"numpy\", \"pandas\", \"scikit-learn\"])\n\n    # Run initial setup\n    session.run(\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nprint(\"Environment ready!\")\n    \"\"\")\n\n# Container state is saved and can be reused\n</code></pre>"},{"location":"configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"configuration/#1-use-appropriate-resource-limits","title":"1. Use Appropriate Resource Limits","text":"<pre><code># Development environment\ndev_config = {\n    \"cpu_count\": 4,\n    \"mem_limit\": \"2g\",\n\\}\n\n# Production environment\nprod_config = {\n    \"cpu_count\": 1,\n    \"mem_limit\": \"256m\",\n\\    \"pids_limit\": 50\n}\n</code></pre>"},{"location":"configuration/#2-layer-security-policies","title":"2. Layer Security Policies","text":"<pre><code># Base policy\nbase_policy = get_security_policy(\"production\")\n\n# Add custom patterns\nbase_policy.add_pattern(SecurityPattern(\n    pattern=r\"requests\\.get\\s*\\(.*internal\",\n    description=\"Internal network access\",\n    severity=SecurityIssueSeverity.HIGH\n))\n</code></pre>"},{"location":"configuration/#3-use-environment-specific-images","title":"3. Use Environment-Specific Images","text":"<pre><code>import os\n\n# Environment-based configuration\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nconfigs = {\n    \"development\": {\n        \"image\": \"python:3.11\",\n        \"keep_template\": True,\n        \"verbose\": True\n    },\n    \"production\": {\n        \"image\": \"python:3.11-slim\",\n        \"keep_template\": False,\n        \"verbose\": False\n    }\n}\n\nwith SandboxSession(**configs[env]) as session:\n    pass\n</code></pre>"},{"location":"configuration/#4-handle-backend-failover","title":"4. Handle Backend Failover","text":"<pre><code>def create_session_with_fallback(**kwargs):\n    \"\"\"Create session with backend fallback\"\"\"\n    backends = [\n        SandboxBackend.DOCKER,\n        SandboxBackend.PODMAN,\n        SandboxBackend.KUBERNETES\n    ]\n\n    for backend in backends:\n        try:\n            return SandboxSession(backend=backend, **kwargs)\n        except Exception as e:\n            print(f\"Backend {backend} failed: {e}\")\n            continue\n\n    raise RuntimeError(\"No available backends\")\n</code></pre>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Security Policies</li> <li>Explore Backend Options</li> <li>Check out Examples</li> <li>Read the API Reference</li> </ul>"},{"location":"contributing/","title":"Contributing to LLM Sandbox","text":"<p>Thank you for your interest in contributing to LLM Sandbox! This guide will help you get started with contributing to the project.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to abide by our Code of Conduct:</p> <ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers and help them get started</li> <li>Focus on constructive criticism</li> <li>Respect differing viewpoints and experiences</li> <li>Show empathy towards other community members</li> </ul>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>uv for dependency management</li> <li>Docker (for testing Docker backend)</li> <li>Git</li> </ul>"},{"location":"contributing/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<ol> <li>Fork and clone the repository</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/llm-sandbox.git\ncd llm-sandbox\n</code></pre> <ol> <li>Install dependencies using uv</li> </ol> <pre><code>make install\n</code></pre> <p>This will:</p> <ul> <li>Create a virtual environment</li> <li>Install all dependencies</li> <li> <p>Install pre-commit hooks</p> </li> <li> <p>Verify installation</p> </li> </ul> <pre><code>make test\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#1-create-a-feature-branch","title":"1. Create a Feature Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/your-bug-fix\n</code></pre>"},{"location":"contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Follow these guidelines:</p> <ul> <li>Write clean, readable code</li> <li>Follow PEP 8 style guide</li> <li>Add type hints where appropriate</li> <li>Include docstrings for all public functions/classes</li> <li>Keep commits focused and atomic</li> </ul>"},{"location":"contributing/#3-run-quality-checks","title":"3. Run Quality Checks","text":"<pre><code># Run all checks\nmake check\n\n# Individual checks\nuv run pre-commit run -a  # Linting and formatting\nuv run mypy              # Type checking\nuv run deptry .          # Dependency checking\n</code></pre>"},{"location":"contributing/#4-write-tests","title":"4. Write Tests","text":"<p>All new features should include tests:</p> <pre><code># tests/test_your_feature.py\nimport pytest\nfrom llm_sandbox import YourFeature\n\ndef test_your_feature():\n    \"\"\"Test description\"\"\"\n    # Arrange\n    feature = YourFeature()\n\n    # Act\n    result = feature.do_something()\n\n    # Assert\n    assert result == expected_value\n\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"input1\", \"output1\"),\n    (\"input2\", \"output2\"),\n])\ndef test_parametrized(input, expected):\n    \"\"\"Test with multiple inputs\"\"\"\n    assert process(input) == expected\n</code></pre> <p>Run tests:</p> <pre><code>make test\n</code></pre>"},{"location":"contributing/#5-update-documentation","title":"5. Update Documentation","text":"<p>If your changes affect the public API:</p> <ol> <li>Update docstrings</li> <li>Update relevant documentation in <code>docs/</code></li> <li>Add examples if applicable</li> </ol> <p>Build and preview documentation:</p> <pre><code>make docs\n# Visit http://localhost:8000\n</code></pre>"},{"location":"contributing/#6-commit-your-changes","title":"6. Commit Your Changes","text":"<p>Write meaningful commit messages following the Conventional Commits specification:</p> <pre><code># Good\ngit commit -m \"feat: add support for Ruby language handler\"\ngit commit -m \"fix: resolve memory leak in Docker session cleanup\"\ngit commit -m \"docs: update security policy examples\"\ngit commit -m \"test: add unit tests for Kubernetes backend\"\ngit commit -m \"refactor: simplify session factory logic\"\n\n# With scope\ngit commit -m \"feat(security): add new pattern detection for SQL injection\"\ngit commit -m \"fix(docker): handle container cleanup on session timeout\"\n\n# Breaking changes\ngit commit -m \"feat!: remove deprecated session.execute() method\"\ngit commit -m \"feat(api)!: change SecurityPolicy constructor signature\"\n\n# Bad\ngit commit -m \"fixed stuff\"\ngit commit -m \"updates\"\n</code></pre> <p>Conventional Commit Format: <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre></p> <p>Types:</p> <ul> <li><code>feat</code>: A new feature</li> <li><code>fix</code>: A bug fix</li> <li><code>docs</code>: Documentation only changes</li> <li><code>style</code>: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)</li> <li><code>refactor</code>: A code change that neither fixes a bug nor adds a feature</li> <li><code>perf</code>: A code change that improves performance</li> <li><code>test</code>: Adding missing tests or correcting existing tests</li> <li><code>build</code>: Changes that affect the build system or external dependencies</li> <li><code>ci</code>: Changes to our CI configuration files and scripts</li> <li><code>chore</code>: Other changes that don't modify src or test files</li> <li><code>revert</code>: Reverts a previous commit</li> </ul> <p>Breaking Changes: - Add <code>!</code> after the type/scope to indicate breaking changes - Or include <code>BREAKING CHANGE:</code> in the footer</p> <p>Examples with body and footer: <pre><code>git commit -m \"feat(lang): add Rust language support\n\nAdd comprehensive Rust language handler with cargo support.\nIncludes compilation and execution pipeline for .rs files.\n\nCloses #123\"\n\ngit commit -m \"fix(security): prevent code injection in eval patterns\n\nThe previous regex pattern allowed certain escape sequences\nthat could bypass security restrictions.\n\nBREAKING CHANGE: SecurityPattern.pattern property is now read-only\"\n</code></pre></p>"},{"location":"contributing/#7-push-and-create-pull-request","title":"7. Push and Create Pull Request","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request on GitHub with:</p> <ul> <li>Clear description of changes</li> <li>Link to related issues</li> <li>Screenshots/examples if applicable</li> </ul>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<pre><code>llm-sandbox/\n\u251c\u2500\u2500 llm_sandbox/           # Main package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py           # Base classes\n\u2502   \u251c\u2500\u2500 session.py        # Session management\n\u2502   \u251c\u2500\u2500 docker.py         # Docker backend\n\u2502   \u251c\u2500\u2500 kubernetes.py     # Kubernetes backend\n\u2502   \u251c\u2500\u2500 podman.py         # Podman backend\n\u2502   \u251c\u2500\u2500 security.py       # Security policies\n\u2502   \u251c\u2500\u2500 data.py           # Data classes\n\u2502   \u251c\u2500\u2500 const.py          # Constants\n\u2502   \u251c\u2500\u2500 exceptions.py     # Custom exceptions\n\u2502   \u2514\u2500\u2500 language_handlers/ # Language support\n\u2502       \u251c\u2500\u2500 base.py\n\u2502       \u251c\u2500\u2500 python_handler.py\n\u2502       \u251c\u2500\u2500 javascript_handler.py\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 tests/                # Test files\n\u251c\u2500\u2500 examples/             # Example scripts\n\u251c\u2500\u2500 docs/                 # Documentation\n\u2514\u2500\u2500 pyproject.toml        # Project configuration\n</code></pre>"},{"location":"contributing/#adding-new-features","title":"Adding New Features","text":""},{"location":"contributing/#adding-a-new-language","title":"Adding a New Language","text":"<ol> <li>Create handler in <code>llm_sandbox/language_handlers/</code>:</li> </ol> <pre><code># llm_sandbox/language_handlers/rust_handler.py\nfrom .base import AbstractLanguageHandler, LanguageConfig\n\nclass RustHandler(AbstractLanguageHandler):\n    def __init__(self, logger=None):\n        super().__init__(logger)\n        self.config = LanguageConfig(\n            name=\"rust\",\n            file_extension=\"rs\",\n            execution_commands=[\"rustc {file} -o /tmp/program &amp;&amp; /tmp/program\"],\n            package_manager=\"cargo add\",\n        )\n\n    def get_import_patterns(self, module: str) -&gt; str:\n        return rf\"use\\s+{module}\"\n\n    # Implement other required methods...\n</code></pre> <ol> <li>Register in factory:</li> </ol> <pre><code># llm_sandbox/language_handlers/factory.py\nfrom .rust_handler import RustHandler\n\nclass LanguageHandlerFactory:\n    _handlers = {\n        # ...\n        \"rust\": RustHandler,\n    }\n</code></pre> <ol> <li>Update constants:</li> </ol> <pre><code># llm_sandbox/const.py\nclass SupportedLanguage(StrEnum):\n    # ...\n    RUST = \"rust\"\n\nclass DefaultImage:\n    # ...\n    RUST = \"rust:latest\"\n</code></pre> <ol> <li>Add tests:</li> </ol> <pre><code># tests/test_rust_handler.py\ndef test_rust_execution():\n    with SandboxSession(lang=\"rust\") as session:\n        result = session.run('fn main() { println!(\"Hello\"); }')\n        assert result.stdout.strip() == \"Hello\"\n</code></pre>"},{"location":"contributing/#adding-a-new-backend","title":"Adding a New Backend","text":"<ol> <li>Create backend implementation:</li> </ol> <pre><code># llm_sandbox/new_backend.py\nfrom .base import Session\n\nclass SandboxNewBackendSession(Session):\n    def open(self):\n        # Implementation\n        pass\n\n    def close(self):\n        # Implementation\n        pass\n\n    # Implement all abstract methods...\n</code></pre> <ol> <li>Update session factory:</li> </ol> <pre><code># llm_sandbox/session.py\ndef create_session(backend, **kwargs):\n    match backend:\n        # ...\n        case SandboxBackend.NEW_BACKEND:\n            from .new_backend import SandboxNewBackendSession\n            return SandboxNewBackendSession(**kwargs)\n</code></pre> <ol> <li>Add to constants:</li> </ol> <pre><code># llm_sandbox/const.py\nclass SandboxBackend(StrEnum):\n    # ...\n    NEW_BACKEND = \"new_backend\"\n</code></pre>"},{"location":"contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/#test-structure","title":"Test Structure","text":"<pre><code># Use pytest fixtures for reusable components\n@pytest.fixture\ndef sandbox_session():\n    with SandboxSession(lang=\"python\") as session:\n        yield session\n\n# Group related tests\nclass TestSecurityPolicies:\n    def test_pattern_detection(self):\n        # Test implementation\n        pass\n\n    def test_module_restriction(self):\n        # Test implementation\n        pass\n\n# Use parametrize for multiple test cases\n@pytest.mark.parametrize(\"backend\", [\n    SandboxBackend.DOCKER,\n    SandboxBackend.PODMAN,\n])\ndef test_cross_backend(backend):\n    # Test implementation\n    pass\n</code></pre>"},{"location":"contributing/#mocking-external-dependencies","title":"Mocking External Dependencies","text":"<pre><code>from unittest.mock import Mock, patch\n\n@patch('docker.from_env')\ndef test_docker_connection(mock_docker):\n    mock_client = Mock()\n    mock_docker.return_value = mock_client\n\n    session = SandboxSession(backend=SandboxBackend.DOCKER)\n    # Test implementation\n</code></pre>"},{"location":"contributing/#documentation-standards","title":"Documentation Standards","text":""},{"location":"contributing/#docstring-format","title":"Docstring Format","text":"<p>Use Google-style docstrings:</p> <pre><code>def execute_code(code: str, language: str = \"python\") -&gt; ConsoleOutput:\n    \"\"\"Execute code in a sandboxed environment.\n\n    This function creates an isolated container environment and\n    executes the provided code safely.\n\n    Args:\n        code: The source code to execute\n        language: Programming language identifier\n\n    Returns:\n        ConsoleOutput containing stdout, stderr, and exit code\n\n    Raises:\n        SecurityError: If code violates security policy\n        NotOpenSessionError: If session is not initialized\n\n    Example:\n        &gt;&gt;&gt; result = execute_code(\"print('Hello')\")\n        &gt;&gt;&gt; print(result.stdout)\n        Hello\n    \"\"\"\n</code></pre>"},{"location":"contributing/#type-hints","title":"Type Hints","text":"<p>Always include type hints:</p> <pre><code>from typing import Optional, List, Dict, Union, Any\nfrom typing import Protocol  # for protocols\n\ndef process_data(\n    data: List[Dict[str, Any]],\n    options: Optional[Dict[str, Union[str, int]]] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"Process data with options.\"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#performance-guidelines","title":"Performance Guidelines","text":""},{"location":"contributing/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Lazy Imports: Import heavy dependencies only when needed</li> </ol> <pre><code>def use_special_feature():\n    # Import only when function is called\n    import heavy_library\n    return heavy_library.process()\n</code></pre> <ol> <li>Resource Management: Always use context managers</li> </ol> <pre><code># Good\nwith SandboxSession() as session:\n    result = session.run(code)\n\n# Avoid\nsession = SandboxSession()\nsession.open()\nresult = session.run(code)\nsession.close()  # May not be called if error occurs\n</code></pre> <ol> <li>Caching: Cache expensive operations</li> </ol> <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef get_language_handler(language: str):\n    return LanguageHandlerFactory.create_handler(language)\n</code></pre>"},{"location":"contributing/#security-considerations","title":"Security Considerations","text":"<p>When contributing security-related features:</p> <ol> <li>Never Trust User Input: Always validate and sanitize</li> <li>Principle of Least Privilege: Request minimum permissions</li> <li>Defense in Depth: Layer security measures</li> <li>Fail Secure: Default to denying access</li> <li>Log Security Events: But don't log sensitive data</li> </ol>"},{"location":"contributing/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update CHANGELOG.md</li> <li>Create git tag: <code>git tag v0.x.x</code></li> <li>Push tag: <code>git push origin v0.x.x</code></li> <li>GitHub Actions will handle PyPI release</li> </ol>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues: For bugs and feature requests</li> <li>GitHub Discussions: For questions and ideas</li> <li>Email: vndee.huynh@gmail.com</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in:</p> <ul> <li>CONTRIBUTORS.md file</li> <li>GitHub contributors page</li> <li>Release notes</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p> <p>Thank you for contributing to LLM Sandbox! Your efforts help make code execution safer for everyone using LLMs.</p>"},{"location":"custom-images/","title":"Custom Docker Images and Pre-installed Libraries","text":"<p>This guide explains how to use custom Docker images and Dockerfiles with pre-installed libraries in LLM Sandbox.</p>"},{"location":"custom-images/#overview","title":"Overview","text":"<p>LLM Sandbox supports using custom Docker images and Dockerfiles that have libraries pre-installed. This is particularly useful for Python environments, where virtual environment isolation can sometimes prevent access to system-wide packages.</p> <p>Note: This guide primarily applies to Python. Other languages (Go, R, Java, etc.) typically don't have the same isolation issues since they don't use virtual environments.</p> <p>Benefits include: - Faster execution times (no need to install libraries at runtime) - Complex dependency setups - Specific library versions or configurations - Reproducible environments</p>"},{"location":"custom-images/#using-custom-images","title":"Using Custom Images","text":""},{"location":"custom-images/#pre-built-custom-images","title":"Pre-built Custom Images","text":"<p>You can use any custom Docker image with pre-installed libraries:</p> <pre><code>from llm_sandbox import SandboxSession\n\n# Using a custom image with pre-installed data science libraries\nwith SandboxSession(\n    lang=\"python\",\n    image=\"your-registry/python-datascience:latest\"\n) as session:\n    # Libraries like pandas, numpy are already available\n    result = session.run(\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\nprint(df.to_json())\n    \"\"\")\n    # No need to specify libraries=[\"pandas\", \"numpy\"]\n    print(result.stdout)\n</code></pre>"},{"location":"custom-images/#building-from-dockerfile","title":"Building from Dockerfile","text":"<p>You can also build images from Dockerfiles with pre-installed libraries:</p> <pre><code>from llm_sandbox import SandboxSession\n\nwith SandboxSession(\n    lang=\"python\",\n    dockerfile=\"./custom/Dockerfile\"\n) as session:\n    result = session.run(\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create sample data\ndata = np.random.randn(100)\nprint(f\"Generated {len(data)} data points\")\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"custom-images/#example-dockerfile","title":"Example Dockerfile","text":"<p>Here's an example Dockerfile with pre-installed Python libraries:</p> <pre><code>FROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Pre-install Python packages\nRUN pip install \\\n    numpy \\\n    pandas \\\n    matplotlib \\\n    scikit-learn \\\n    requests \\\n    fastapi\n\n# Create working directory\nWORKDIR /sandbox\n\n# Optional: Create directories for output\nRUN mkdir -p /tmp/sandbox_output /tmp/sandbox_plots\n</code></pre>"},{"location":"custom-images/#how-it-works-python-specific","title":"How It Works (Python-Specific)","text":""},{"location":"custom-images/#virtual-environment-with-system-packages","title":"Virtual Environment with System Packages","text":"<p>For Python only, LLM Sandbox creates a virtual environment using the <code>--system-site-packages</code> flag:</p> <pre><code>python -m venv --system-site-packages /tmp/venv\n</code></pre> <p>This allows the virtual environment to access packages installed in the system Python (including those in your custom image).</p> <p>Other Languages: Languages like Go, R, Java, C++, etc. don't use virtual environments, so pre-installed libraries in custom images are automatically accessible without any special configuration.</p>"},{"location":"custom-images/#library-installation-behavior","title":"Library Installation Behavior","text":"<ol> <li>Pre-installed libraries: Available immediately without specifying in <code>libraries</code> parameter</li> <li>Additional libraries: Can still be installed using the <code>libraries</code> parameter</li> <li>Hybrid approach: Mix pre-installed and runtime-installed libraries</li> </ol> <pre><code># Pre-installed: pandas, numpy\n# Runtime-installed: requests\nresult = session.run(\"\"\"\nimport pandas as pd  # Pre-installed\nimport numpy as np   # Pre-installed\nimport requests      # Will be installed at runtime\n\ndata = pd.DataFrame({'x': np.random.randn(10)})\nresponse = requests.get('https://api.github.com')\nprint(f\"Data shape: {data.shape}, API status: {response.status_code}\")\n\"\"\", libraries=[\"requests\"])  # Only need to specify requests\n</code></pre>"},{"location":"custom-images/#best-practices","title":"Best Practices","text":""},{"location":"custom-images/#1-layer-optimization","title":"1. Layer Optimization","text":"<p>Organize your Dockerfile for optimal layer caching:</p> <pre><code>FROM python:3.11-slim\n\n# Install system dependencies first (rarely change)\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install stable/core libraries next\nRUN pip install \\\n    numpy \\\n    pandas \\\n    matplotlib\n\n# Install more volatile libraries last\nRUN pip install \\\n    scikit-learn \\\n    requests\n\nWORKDIR /sandbox\n</code></pre>"},{"location":"custom-images/#2-pin-library-versions","title":"2. Pin Library Versions","text":"<p>For reproducible environments, pin library versions:</p> <pre><code>RUN pip install \\\n    numpy==1.24.3 \\\n    pandas==2.0.3 \\\n    matplotlib==3.7.2 \\\n    scikit-learn==1.3.0\n</code></pre>"},{"location":"custom-images/#3-use-multi-stage-builds","title":"3. Use Multi-stage Builds","text":"<p>For smaller images, consider multi-stage builds:</p> <pre><code># Build stage\nFROM python:3.11 as builder\nCOPY requirements.txt .\nRUN pip install --user -r requirements.txt\n\n# Runtime stage\nFROM python:3.11-slim\nCOPY --from=builder /root/.local /root/.local\nENV PATH=/root/.local/bin:$PATH\nWORKDIR /sandbox\n</code></pre>"},{"location":"custom-images/#4-cache-dependencies","title":"4. Cache Dependencies","text":"<p>Set up pip cache for faster builds:</p> <pre><code>ENV PIP_CACHE_DIR=/tmp/pip_cache\nRUN mkdir -p /tmp/pip_cache\nRUN pip install --cache-dir /tmp/pip_cache numpy pandas\n</code></pre>"},{"location":"custom-images/#language-specific-examples","title":"Language-Specific Examples","text":""},{"location":"custom-images/#python-data-science-image-requires-system-site-packages-fix","title":"Python Data Science Image (Requires --system-site-packages Fix)","text":"<p>Python requires the virtual environment fix to access pre-installed packages:</p> <pre><code>FROM python:3.11-bullseye\n\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    libpq-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Data science stack - accessible via --system-site-packages\nRUN pip install \\\n    numpy \\\n    pandas \\\n    matplotlib \\\n    seaborn \\\n    scikit-learn \\\n    scipy \\\n    jupyter \\\n    plotly\n\nWORKDIR /sandbox\n</code></pre>"},{"location":"custom-images/#python-web-development-image","title":"Python Web Development Image","text":"<pre><code>FROM python:3.11-slim\n\n# Pre-installed packages accessible via --system-site-packages\nRUN pip install \\\n    fastapi \\\n    uvicorn \\\n    requests \\\n    pydantic \\\n    sqlalchemy \\\n    pytest\n\nWORKDIR /sandbox\n</code></pre>"},{"location":"custom-images/#r-with-bioconductor-no-virtual-environment-issues","title":"R with Bioconductor (No Virtual Environment Issues)","text":"<p>R doesn't use virtual environments, so pre-installed packages work automatically:</p> <pre><code>FROM rocker/r-ver:4.3.0\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    libxml2-dev \\\n    libssl-dev \\\n    libcurl4-openssl-dev\n\n# These packages are immediately accessible - no virtual environment isolation\nRUN R -e \"install.packages(c('tidyverse', 'data.table', 'plotly'))\"\nRUN R -e \"BiocManager::install(c('DESeq2', 'edgeR'))\"\n\nWORKDIR /sandbox\n</code></pre>"},{"location":"custom-images/#troubleshooting","title":"Troubleshooting","text":""},{"location":"custom-images/#python-library-not-found","title":"Python Library Not Found","text":"<p>If a pre-installed Python library is not found:</p> <ol> <li>Check virtual environment creation: Ensure <code>--system-site-packages</code> is used</li> <li>Verify installation path: Libraries should be in system Python, not user-local</li> <li>Test directly: Run <code>python -c \"import library_name\"</code> in your image</li> </ol>"},{"location":"custom-images/#other-languages","title":"Other Languages","text":"<p>For non-Python languages, pre-installed libraries should work automatically. If they don't:</p> <ol> <li>Verify installation: Check that packages are properly installed in the image</li> <li>Check paths: Ensure library paths are correctly configured</li> <li>Language-specific issues: Check language-specific package manager configurations</li> </ol>"},{"location":"custom-images/#conflicting-libraries","title":"Conflicting Libraries","text":"<p>If you get version conflicts:</p> <pre><code># Check what's installed\nresult = session.run(\"\"\"\nimport pkg_resources\ninstalled = [str(d) for d in pkg_resources.working_set]\nfor package in sorted(installed):\n    print(package)\n\"\"\")\n</code></pre>"},{"location":"custom-images/#performance-issues","title":"Performance Issues","text":"<p>For faster startup: - Use smaller base images (e.g., <code>python:3.11-slim</code> vs <code>python:3.11</code>) - Pre-compile Python files: <code>RUN python -m compileall /usr/local/lib/python3.11</code> - Use package wheels: <code>RUN pip install --only-binary=all numpy pandas</code></p>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples of using LLM Sandbox for executing LLM-generated code in real-world AI agent scenarios. These examples focus on the most common use cases where LLMs generate code that needs to be executed safely.</p>"},{"location":"examples/#llm-framework-integrations","title":"LLM Framework Integrations","text":""},{"location":"examples/#langchain-integration","title":"LangChain Integration","text":"<pre><code># ruff: noqa: E501\n\n# Reference: https://python.langchain.com/docs/how_to/custom_tools/\n\nimport logging\n\nfrom langchain import hub\nfrom langchain.agents import AgentExecutor, create_tool_calling_agent\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\nfrom llm_sandbox import SandboxSession\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\n@tool\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n    tools = [run_code]\n\n    agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore[arg-type]\n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  # type: ignore[arg-type]\n    output = agent_executor.invoke({\n        \"input\": \"Write python code to calculate Pi number by Monte Carlo method then run it.\"\n    })\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Write python code to calculate the factorial of a number then run it.\"})\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Write python code to calculate the Fibonacci sequence then run it.\"})\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Calculate the sum of the first 10000 numbers.\"})\n    logger.info(\"Agent: %s\", output)\n</code></pre>"},{"location":"examples/#langgraph-integration","title":"LangGraph Integration","text":"<pre><code>import logging\n\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import create_react_agent\n\nfrom llm_sandbox import SandboxSession\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\n@tool\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    agent = create_react_agent(model=\"openai:gpt-4.1-nano\", tools=[run_code])\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Write python code to calculate Pi number by Monte Carlo method then run it.\",\n                }\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Write python code to calculate the factorial of a number then run it.\"}\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Write python code to calculate the Fibonacci sequence then run it.\"}\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Calculate the sum of the first 10000 numbers.\"}]}),\n    )\n</code></pre>"},{"location":"examples/#llamaindex-integration","title":"LlamaIndex Integration","text":"<pre><code># ruff: noqa: E501\n\n# Reference: https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/\n\nimport logging\n\nimport nest_asyncio\nfrom llama_index.core.agent import FunctionCallingAgentWorker\nfrom llama_index.core.tools import FunctionTool\nfrom llama_index.llms.openai import OpenAI\n\nfrom llm_sandbox import SandboxSession\n\nnest_asyncio.apply()\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    llm = OpenAI(model=\"gpt-4.1-nano\", temperature=0)\n    code_execution_tool = FunctionTool.from_defaults(fn=run_code)\n\n    agent_worker = FunctionCallingAgentWorker.from_tools(\n        [code_execution_tool],\n        llm=llm,\n        verbose=True,\n        allow_parallel_tool_calls=False,\n    )\n    agent = agent_worker.as_agent()\n\n    response = agent.chat(\"Write python code to calculate Pi number by Monte Carlo method then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Write python code to calculate the factorial of a number then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Write python code to calculate the Fibonacci sequence then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Calculate the sum of the first 10000 numbers.\")\n    logger.info(response)\n</code></pre>"},{"location":"examples/#code-generation-patterns","title":"Code Generation Patterns","text":""},{"location":"examples/#1-self-correcting-code-generator","title":"1. Self-Correcting Code Generator","text":"<pre><code>from llm_sandbox import SandboxSession\nimport openai\n\nclass SelfCorrectingCodeGenerator:\n    \"\"\"Generate and iteratively improve code using LLM feedback\"\"\"\n\n    def __init__(self, api_key: str):\n        self.client = openai.OpenAI(api_key=api_key)\n        self.max_iterations = 3\n\n    def generate_and_test_code(self, task: str, test_cases: list) -&gt; dict:\n        \"\"\"Generate code and iteratively improve it based on test results\"\"\"\n\n        iteration = 0\n        current_code = None\n\n        while iteration &lt; self.max_iterations:\n            iteration += 1\n\n            # Generate or improve code\n            if current_code is None:\n                prompt = f\"Write Python code to: {task}\\n\\nInclude proper error handling and documentation.\"\n            else:\n                prompt = f\"\"\"\n                The previous code failed. Here's what happened:\n\n                Code: {current_code}\n                Error: {last_error}\n\n                Fix the issues and improve the code to: {task}\n                \"\"\"\n\n            response = self.client.chat.completions.create(\n                model=\"gpt-4\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are an expert Python developer. Write clean, efficient, well-tested code.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n            )\n\n            current_code = response.choices[0].message.content\n\n            # Test the generated code\n            with SandboxSession(lang=\"python\") as session:\n                # Setup test environment\n                test_result = session.run(current_code)\n\n                if test_result.exit_code == 0:\n                    # Run test cases\n                    all_passed = True\n                    test_outputs = []\n\n                    for test_case in test_cases:\n                        test_code = f\"\"\"\n# Test case: {test_case['description']}\ntry:\n    result = {test_case['code']}\n    expected = {test_case['expected']}\n    passed = result == expected\n    print(f\"Test '{test_case['description']}': {'PASS' if passed else 'FAIL'}\")\n    if not passed:\n        print(f\"  Expected: {expected}, Got: {result}\")\nexcept Exception as e:\n    print(f\"Test '{test_case['description']}': ERROR - {e}\")\n    passed = False\n\"\"\"\n                        test_output = session.run(test_code)\n                        test_outputs.append(test_output.stdout)\n\n                        if \"FAIL\" in test_output.stdout or \"ERROR\" in test_output.stdout:\n                            all_passed = False\n\n                    if all_passed:\n                        return {\n                            \"success\": True,\n                            \"code\": current_code,\n                            \"iterations\": iteration,\n                            \"test_results\": test_outputs\n                        }\n                    else:\n                        last_error = \"Some test cases failed: \" + \"\\n\".join(test_outputs)\n                else:\n                    last_error = test_result.stderr\n\n        return {\n            \"success\": False,\n            \"code\": current_code,\n            \"iterations\": iteration,\n            \"final_error\": last_error\n        }\n\n# Example usage\ngenerator = SelfCorrectingCodeGenerator(\"your-api-key\")\n\ntest_cases = [\n    {\n        \"description\": \"Basic sorting\",\n        \"code\": \"sort_list([3, 1, 4, 1, 5])\",\n        \"expected\": [1, 1, 3, 4, 5]\n    },\n    {\n        \"description\": \"Empty list\",\n        \"code\": \"sort_list([])\",\n        \"expected\": []\n    },\n    {\n        \"description\": \"Single element\",\n        \"code\": \"sort_list([42])\",\n        \"expected\": [42]\n    }\n]\n\nresult = generator.generate_and_test_code(\n    \"Create a function called 'sort_list' that sorts a list of numbers in ascending order\",\n    test_cases\n)\n\nprint(f\"Success: {result['success']}\")\nprint(f\"Iterations: {result['iterations']}\")\nif result['success']:\n    print(\"Generated code:\", result['code'])\n</code></pre>"},{"location":"examples/#2-multi-language-code-translator","title":"2. Multi-Language Code Translator","text":"<pre><code>from llm_sandbox import SandboxSession\nimport openai\n\nclass CodeTranslator:\n    \"\"\"Translate code between different programming languages\"\"\"\n\n    def __init__(self, api_key: str):\n        self.client = openai.OpenAI(api_key=api_key)\n        self.supported_languages = [\"python\", \"javascript\", \"java\", \"cpp\", \"go\"]\n\n    def translate_code(self, source_code: str, source_lang: str, target_lang: str) -&gt; dict:\n        \"\"\"Translate code from one language to another and test it\"\"\"\n\n        translation_prompt = f\"\"\"\n        Translate this {source_lang} code to {target_lang}:\n\n        {source_code}\n\n        Requirements:\n        1. Maintain the same functionality\n        2. Use idiomatic {target_lang} patterns\n        3. Include proper error handling\n        4. Add comments explaining the translation choices\n        5. Ensure the code is runnable and follows best practices\n        \"\"\"\n\n        response = self.client.chat.completions.create(\n            model=\"gpt-4\",\n            messages=[\n                {\"role\": \"system\", \"content\": f\"You are an expert in both {source_lang} and {target_lang}. Provide accurate, idiomatic translations.\"},\n                {\"role\": \"user\", \"content\": translation_prompt}\n            ]\n        )\n\n        translated_code = response.choices[0].message.content\n\n        # Test both original and translated code\n        original_result = self._test_code(source_code, source_lang)\n        translated_result = self._test_code(translated_code, target_lang)\n\n        return {\n            \"source_language\": source_lang,\n            \"target_language\": target_lang,\n            \"original_code\": source_code,\n            \"translated_code\": translated_code,\n            \"original_output\": original_result,\n            \"translated_output\": translated_result,\n            \"translation_successful\": translated_result[\"success\"],\n            \"outputs_match\": self._compare_outputs(original_result, translated_result)\n        }\n\n    def _test_code(self, code: str, language: str) -&gt; dict:\n        \"\"\"Test code execution in specified language\"\"\"\n        try:\n            with SandboxSession(lang=language) as session:\n                result = session.run(code)\n                return {\n                    \"success\": result.exit_code == 0,\n                    \"output\": result.stdout,\n                    \"error\": result.stderr\n                }\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"output\": \"\",\n                \"error\": str(e)\n            }\n\n    def _compare_outputs(self, original: dict, translated: dict) -&gt; bool:\n        \"\"\"Compare outputs to verify translation accuracy\"\"\"\n        if not (original[\"success\"] and translated[\"success\"]):\n            return False\n\n        # Simple output comparison (can be enhanced for specific needs)\n        return original[\"output\"].strip() == translated[\"output\"].strip()\n\n# Example usage\ntranslator = CodeTranslator(\"your-api-key\")\n\npython_code = \"\"\"\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# Test the function\nfor i in range(10):\n    print(f\"fib({i}) = {fibonacci(i)}\")\n\"\"\"\n\ntranslation = translator.translate_code(python_code, \"python\", \"javascript\")\n\nprint(f\"Translation successful: {translation['translation_successful']}\")\nprint(f\"Outputs match: {translation['outputs_match']}\")\nprint(\"Translated code:\", translation['translated_code'])\n</code></pre>"},{"location":"examples/#security-and-monitoring","title":"Security and Monitoring","text":""},{"location":"examples/#secure-code-execution-service","title":"Secure Code Execution Service","text":"<pre><code>from llm_sandbox import SandboxSession\nfrom llm_sandbox.security import SecurityPolicy, RestrictedModule, SecurityIssueSeverity\nimport hashlib\nimport time\nimport logging\n\nclass SecureAICodeExecutor:\n    \"\"\"Production-ready secure execution service for AI-generated code\"\"\"\n\n    def __init__(self):\n        self.execution_log = []\n        self.security_policy = self._create_security_policy()\n        self.logger = logging.getLogger(__name__)\n\n    def _create_security_policy(self) -&gt; SecurityPolicy:\n        \"\"\"Create comprehensive security policy for AI-generated code\"\"\"\n        return SecurityPolicy(\n            severity_threshold=SecurityIssueSeverity.MEDIUM,\n            restricted_modules=[\n                RestrictedModule(\"os\", \"Operating system access\", SecurityIssueSeverity.HIGH),\n                RestrictedModule(\"subprocess\", \"Process execution\", SecurityIssueSeverity.HIGH),\n                RestrictedModule(\"socket\", \"Network operations\", SecurityIssueSeverity.MEDIUM),\n                RestrictedModule(\"ctypes\", \"Foreign function library\", SecurityIssueSeverity.HIGH)\n            ]\n        )\n\n    def execute_ai_code(\n        self,\n        code: str,\n        user_id: str,\n        ai_model: str,\n        language: str = \"python\",\n        timeout: int = 30\n    ) -&gt; dict:\n        \"\"\"Execute AI-generated code with comprehensive security and monitoring\"\"\"\n\n        execution_id = hashlib.sha256(f\"{user_id}{time.time()}{code}\".encode()).hexdigest()[:16]\n\n        # Log execution attempt\n        log_entry = {\n            \"execution_id\": execution_id,\n            \"user_id\": user_id,\n            \"ai_model\": ai_model,\n            \"language\": language,\n            \"timestamp\": time.time(),\n            \"code_length\": len(code),\n            \"code_hash\": hashlib.sha256(code.encode()).hexdigest()\n        }\n\n        try:\n            with SandboxSession(\n                lang=language,\n                security_policy=self.security_policy,\n                runtime_configs={\n                    \"timeout\": timeout,\n                    \"mem_limit\": \"256m\",\n                    \"cpu_count\": 1,\n                    \"network_mode\": \"none\",\n                    \"read_only\": True\n                }\n            ) as session:\n                # Security check\n                is_safe, violations = session.is_safe(code)\n\n                if not is_safe:\n                    log_entry[\"security_violations\"] = [v.description for v in violations]\n                    self.execution_log.append(log_entry)\n\n                    return {\n                        \"success\": False,\n                        \"execution_id\": execution_id,\n                        \"error\": \"Security policy violations detected\",\n                        \"violations\": [\n                            {\"description\": v.description, \"severity\": v.severity.name}\n                            for v in violations\n                        ]\n                    }\n\n                # Execute code\n                result = session.run(code)\n\n                log_entry[\"success\"] = result.exit_code == 0\n                log_entry[\"execution_time\"] = time.time() - log_entry[\"timestamp\"]\n                self.execution_log.append(log_entry)\n\n                return {\n                    \"success\": result.exit_code == 0,\n                    \"execution_id\": execution_id,\n                    \"output\": result.stdout[:5000],  # Limit output size\n                    \"error\": result.stderr[:1000] if result.stderr else None,\n                    \"execution_time\": log_entry[\"execution_time\"]\n                }\n\n        except Exception as e:\n            log_entry[\"error\"] = str(e)\n            self.execution_log.append(log_entry)\n\n            return {\n                \"success\": False,\n                \"execution_id\": execution_id,\n                \"error\": f\"Execution failed: {str(e)}\"\n            }\n\n    def get_execution_stats(self, user_id: str = None) -&gt; dict:\n        \"\"\"Get execution statistics\"\"\"\n        logs = self.execution_log\n        if user_id:\n            logs = [log for log in logs if log[\"user_id\"] == user_id]\n\n        if not logs:\n            return {\"total\": 0}\n\n        total = len(logs)\n        successful = sum(1 for log in logs if log.get(\"success\", False))\n        violations = sum(1 for log in logs if \"security_violations\" in log)\n\n        return {\n            \"total_executions\": total,\n            \"successful_executions\": successful,\n            \"security_violations\": violations,\n            \"success_rate\": successful / total if total &gt; 0 else 0,\n            \"violation_rate\": violations / total if total &gt; 0 else 0\n        }\n\n# Example usage\nexecutor = SecureAICodeExecutor()\n\n# Example AI-generated code execution\nai_code = \"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate data\nx = np.linspace(0, 2*np.pi, 100)\ny = np.sin(x)\n\n# Create plot\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2, label='sin(x)')\nplt.xlabel('x')\nplt.ylabel('sin(x)')\nplt.title('Sine Wave Generated by AI')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(\"Successfully generated sine wave plot!\")\n\"\"\"\n\nresult = executor.execute_ai_code(\n    code=ai_code,\n    user_id=\"ai_agent_001\",\n    ai_model=\"gpt-4\",\n    language=\"python\"\n)\n\nprint(f\"Execution successful: {result['success']}\")\nif result['success']:\n    print(\"Output:\", result['output'])\nelse:\n    print(\"Error:\", result['error'])\n\n# Get statistics\nstats = executor.get_execution_stats()\nprint(f\"Success rate: {stats['success_rate']:.2%}\")\n</code></pre>"},{"location":"examples/#performance-optimization","title":"Performance Optimization","text":""},{"location":"examples/#parallel-ai-code-processing","title":"Parallel AI Code Processing","text":"<pre><code>from llm_sandbox import SandboxSession\nimport concurrent.futures\nimport time\n\nclass ParallelAICodeProcessor:\n    \"\"\"Process multiple AI-generated code snippets in parallel\"\"\"\n\n    def __init__(self, max_workers: int = 4):\n        self.max_workers = max_workers\n\n    def process_code_batch(self, code_tasks: list) -&gt; list:\n        \"\"\"Process multiple code tasks in parallel\"\"\"\n\n        def execute_single_task(task):\n            task_id, code, language = task[\"id\"], task[\"code\"], task.get(\"language\", \"python\")\n\n            start_time = time.time()\n\n            try:\n                with SandboxSession(\n                    lang=language,\n                    runtime_configs={\"timeout\": 30, \"mem_limit\": \"128m\"}\n                ) as session:\n                    result = session.run(code)\n\n                    return {\n                        \"task_id\": task_id,\n                        \"success\": result.exit_code == 0,\n                        \"output\": result.stdout,\n                        \"error\": result.stderr,\n                        \"execution_time\": time.time() - start_time\n                    }\n            except Exception as e:\n                return {\n                    \"task_id\": task_id,\n                    \"success\": False,\n                    \"output\": \"\",\n                    \"error\": str(e),\n                    \"execution_time\": time.time() - start_time\n                }\n\n        # Execute tasks in parallel\n        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            future_to_task = {\n                executor.submit(execute_single_task, task): task\n                for task in code_tasks\n            }\n\n            results = []\n            for future in concurrent.futures.as_completed(future_to_task):\n                results.append(future.result())\n\n        return sorted(results, key=lambda x: x[\"task_id\"])\n\n# Example usage\nprocessor = ParallelAICodeProcessor(max_workers=3)\n\n# Batch of AI-generated code tasks\ncode_tasks = [\n    {\n        \"id\": 1,\n        \"code\": \"print('Task 1: Hello from AI!')\\nprint(sum(range(100)))\",\n        \"language\": \"python\"\n    },\n    {\n        \"id\": 2,\n        \"code\": \"import math\\nprint(f'Task 2: Pi = {math.pi:.6f}')\",\n        \"language\": \"python\"\n    },\n    {\n        \"id\": 3,\n        \"code\": \"console.log('Task 3: JavaScript execution')\\nconsole.log(Array.from({length: 10}, (_, i) =&gt; i * 2))\",\n        \"language\": \"javascript\"\n    }\n]\n\nresults = processor.process_code_batch(code_tasks)\n\nfor result in results:\n    print(f\"Task {result['task_id']}: {'\u2713' if result['success'] else '\u2717'}\")\n    print(f\"  Execution time: {result['execution_time']:.3f}s\")\n    if result['success']:\n        print(f\"  Output: {result['output'][:100]}...\")\n    else:\n        print(f\"  Error: {result['error']}\")\n</code></pre>"},{"location":"examples/#best-practices","title":"Best Practices","text":""},{"location":"examples/#1-code-validation-pipeline","title":"1. Code Validation Pipeline","text":"<pre><code>from llm_sandbox import SandboxSession\nimport openai\n\nclass AICodeValidator:\n    \"\"\"Validate AI-generated code before execution\"\"\"\n\n    def __init__(self, api_key: str):\n        self.client = openai.OpenAI(api_key=api_key)\n\n    def validate_and_improve_code(self, code: str, requirements: str) -&gt; dict:\n        \"\"\"Validate code and suggest improvements\"\"\"\n\n        validation_prompt = f\"\"\"\n        Review this code for:\n        1. Syntax errors\n        2. Logic issues\n        3. Security concerns\n        4. Performance problems\n        5. Best practices compliance\n\n        Requirements: {requirements}\n        Code: {code}\n\n        Provide:\n        - Issues found (if any)\n        - Improved version of the code\n        - Explanation of changes\n        \"\"\"\n\n        response = self.client.chat.completions.create(\n            model=\"gpt-4\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a senior code reviewer. Identify issues and provide improved code.\"},\n                {\"role\": \"user\", \"content\": validation_prompt}\n            ]\n        )\n\n        review_result = response.choices[0].message.content\n\n        # Test both original and improved code\n        original_test = self._test_code(code)\n\n        # Extract improved code from review (simplified extraction)\n        improved_code = self._extract_improved_code(review_result)\n        improved_test = self._test_code(improved_code) if improved_code else None\n\n        return {\n            \"original_code\": code,\n            \"review_feedback\": review_result,\n            \"improved_code\": improved_code,\n            \"original_test_result\": original_test,\n            \"improved_test_result\": improved_test,\n            \"improvement_successful\": improved_test and improved_test[\"success\"]\n        }\n\n    def _test_code(self, code: str) -&gt; dict:\n        \"\"\"Test code execution\"\"\"\n        try:\n            with SandboxSession(lang=\"python\") as session:\n                result = session.run(code)\n                return {\n                    \"success\": result.exit_code == 0,\n                    \"output\": result.stdout,\n                    \"error\": result.stderr\n                }\n        except Exception as e:\n            return {\"success\": False, \"output\": \"\", \"error\": str(e)}\n\n    def _extract_improved_code(self, review_text: str) -&gt; str:\n        \"\"\"Extract improved code from review text\"\"\"\n        # Simple extraction - look for code blocks\n        import re\n        code_blocks = re.findall(r'```python\\n(.*?)\\n```', review_text, re.DOTALL)\n        return code_blocks[-1] if code_blocks else None\n\n# Example usage\nvalidator = AICodeValidator(\"your-api-key\")\n\nai_generated_code = \"\"\"\ndef calculate_average(numbers):\n    return sum(numbers) / len(numbers)\n\nnumbers = [1, 2, 3, 4, 5]\nprint(calculate_average(numbers))\n\"\"\"\n\nvalidation = validator.validate_and_improve_code(\n    code=ai_generated_code,\n    requirements=\"Function should handle edge cases like empty lists and non-numeric inputs\"\n)\n\nprint(\"Validation Results:\")\nprint(\"Original successful:\", validation[\"original_test_result\"][\"success\"])\nprint(\"Improvement successful:\", validation[\"improvement_successful\"])\nprint(\"Review feedback:\", validation[\"review_feedback\"])\n</code></pre>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Security Best Practices for AI-generated code</li> <li>Explore Configuration Options for production deployments</li> <li>Check API Reference for advanced features</li> <li>Read about Contributing to extend functionality</li> </ul> <p>For more examples and use cases, visit our GitHub repository.</p>"},{"location":"existing-container-support/","title":"Existing Container Support","text":"<p>This document describes the new feature for connecting to existing containers/pods instead of creating new ones.</p>"},{"location":"existing-container-support/#overview","title":"Overview","text":"<p>LLM Sandbox now supports connecting to existing containers/pods across all backends (Docker, Kubernetes, Podman, Micromamba). This is useful for:</p> <ul> <li>Reusing containers with complex setups: Connect to containers that already have your specific environment configured</li> <li>Working with long-running services: Integrate with containers managed by external systems</li> <li>Debugging and troubleshooting: Connect to running containers to debug issues</li> <li>Performance optimization: Skip container creation and environment setup time</li> </ul>"},{"location":"existing-container-support/#usage","title":"Usage","text":""},{"location":"existing-container-support/#basic-usage","title":"Basic Usage","text":"<pre><code>from llm_sandbox import SandboxSession\n\n# Connect to existing Docker container\nwith SandboxSession(container_id='abc123def456', lang=\"python\") as session:\n    result = session.run(\"print('Hello from existing container!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"existing-container-support/#docker-backend","title":"Docker Backend","text":"<pre><code>from llm_sandbox import SandboxSession\n\n# Connect to existing Docker container\nwith SandboxSession(\n    container_id='your-container-id',\n    lang=\"python\",\n    verbose=True\n) as session:\n    # Run code in existing container\n    result = session.run(\"import sys; print(sys.version)\")\n\n    # Install additional libraries\n    session.install([\"numpy\"])\n\n    # Execute commands\n    result = session.execute_command(\"ls -la\")\n\n    # Copy files\n    session.copy_to_runtime(\"local_file.py\", \"/container/path/file.py\")\n</code></pre>"},{"location":"existing-container-support/#kubernetes-backend","title":"Kubernetes Backend","text":"<pre><code>from llm_sandbox import SandboxSession, SandboxBackend\n\n# Connect to existing Kubernetes pod\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    container_id='my-pod-name',  # Pod name\n    lang=\"python\",\n    verbose=True\n) as session:\n    result = session.run(\"print('Hello from existing pod!')\")\n</code></pre>"},{"location":"existing-container-support/#podman-backend","title":"Podman Backend","text":"<pre><code>from llm_sandbox import SandboxSession, SandboxBackend\nfrom podman import PodmanClient\n\nclient = PodmanClient()\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    container_id='podman-container-id',\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Hello from existing Podman container!')\")\n</code></pre>"},{"location":"existing-container-support/#important-notes","title":"Important Notes","text":""},{"location":"existing-container-support/#environment-setup-skipped","title":"Environment Setup Skipped","text":"<p>When using <code>container_id</code>, the sandbox skips environment setup. This means:</p> <ul> <li>No virtual environment creation (for Python)</li> <li>No package manager initialization</li> <li>No working directory setup</li> <li>You must ensure the container has the proper environment and tools for your language</li> </ul>"},{"location":"existing-container-support/#container-management","title":"Container Management","text":"<ul> <li>Existing containers are not stopped/removed when the session ends</li> <li>Only the connection is closed</li> <li>The container continues running after session closure</li> <li>Timeout cleanup will kill the container process but won't remove existing containers</li> </ul>"},{"location":"existing-container-support/#error-handling","title":"Error Handling","text":"<pre><code>from llm_sandbox import SandboxSession, ContainerError\n\ntry:\n    with SandboxSession(container_id='non-existent', lang=\"python\") as session:\n        session.run(\"print('test')\")\nexcept ContainerError as e:\n    print(f\"Failed to connect: {e}\")\n</code></pre>"},{"location":"existing-container-support/#configuration-constraints","title":"Configuration Constraints","text":"<p>When using <code>container_id</code>:</p> <ul> <li>Cannot use <code>dockerfile</code> parameter (validation error)</li> <li><code>image</code> parameter is ignored</li> <li>Environment setup is skipped</li> <li>Container lifecycle management is limited</li> </ul>"},{"location":"existing-container-support/#complete-example","title":"Complete Example","text":"<pre><code>\"\"\"Example demonstrating connecting to existing containers/pods.\n\nThis example shows how to use LLM Sandbox with existing containers instead of creating new ones.\nThis is useful for:\n- Reusing containers with complex setups\n- Working with long-running services\n- Debugging and troubleshooting\n- Connecting to containers managed by external systems\n\"\"\"\n\nimport logging\nimport time\n\nfrom docker import DockerClient\n\nfrom llm_sandbox import SandboxBackend, SandboxSession\nfrom llm_sandbox.exceptions import ContainerError\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\nlogger = logging.getLogger(__name__)\n\n\ndef create_and_setup_container() -&gt; str:\n    \"\"\"Create a container with custom setup and return its ID.\n\n    This simulates having an existing container with custom environment.\n\n    Returns:\n        str: Container ID\n\n    \"\"\"\n    client = DockerClient(base_url=\"unix:///Users/vndee/.docker/run/docker.sock\")\n    logger.info(\"\ud83d\ude80 Creating a container with custom setup...\")\n\n    # Create a new container with custom environment\n    # Use commit_container=True to save the container state\n    sandbox = SandboxSession(\n        client=client,\n        lang=\"python\",\n        verbose=True,\n        image=\"ghcr.io/vndee/sandbox-python-311-bullseye\",\n    )\n\n    sandbox.open()\n\n    # Install some packages and setup environment\n    logger.info(\"\ud83d\udce6 Installing packages...\")\n    sandbox.install([\"numpy\", \"pandas\", \"matplotlib\"])\n\n    # Create some files\n    logger.info(\"\ud83d\udcc1 Setting up files...\")\n    # Use Python code to create files instead of shell commands\n    sandbox.run(\"\"\"\n# Create hello.py file\nwith open('/sandbox/hello.py', 'w') as f:\n    f.write('print(\"Hello from existing container!\")')\n\n# Create data.txt file\nwith open('/sandbox/data.txt', 'w') as f:\n    f.write('Custom environment data')\n\nprint(\"Files created successfully!\")\n\"\"\")\n\n    # Verify files were created\n    result = sandbox.execute_command(\"ls -la /sandbox/\")\n    logger.info(\"\ud83d\udccb Created files:\")\n    logger.info(result.stdout)\n\n    # Get container ID before closing\n    container_id = sandbox.container.id\n    logger.info(\"\u2705 Container created with ID: %s...\", container_id[:12])\n    return str(container_id)\n\n\ndef demo_connect_to_existing_docker_container() -&gt; None:\n    \"\"\"Demo connecting to an existing Docker container.\"\"\"\n    # Demo 1: Create a container for demonstration\n    try:\n        container_id = create_and_setup_container()\n    except Exception:\n        logger.exception(\"\u274c Failed to create demo container\")\n        return\n\n    logger.info(\"\\n%s\", \"=\" * 60)\n    logger.info(\"\ud83d\udc33 Demo: Connecting to Existing Docker Container\")\n    logger.info(\"%s\", \"=\" * 60)\n\n    try:\n        client = DockerClient(base_url=\"unix:///Users/vndee/.docker/run/docker.sock\")\n        # Connect to existing container - no environment setup needed\n        with SandboxSession(client=client, container_id=container_id, lang=\"python\", verbose=True) as sandbox:\n            logger.info(\"\u2705 Connected to existing container successfully!\")\n\n            # Run code that uses pre-installed packages\n            result = sandbox.run(\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"Running in existing container!\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")\n\n# Use the pre-existing data\nwith open('/sandbox/data.txt', 'r') as f:\n    data = f.read().strip()\n    print(f\"Found existing data: {data}\")\n\n# Generate some data and create a simple plot\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.figure(figsize=(8, 6))\nplt.plot(x, y)\nplt.title('Plot from Existing Container')\nplt.xlabel('X')\nplt.ylabel('sin(X)')\nplt.grid(True)\nplt.savefig('/sandbox/plot.png')\nprint(\"Plot saved as /sandbox/plot.png\")\n\"\"\")\n\n            logger.info(\"\ud83d\udcca Code execution output:\")\n            logger.info(result.stdout)\n\n            # Execute the pre-existing script\n            result = sandbox.execute_command(\"python /sandbox/hello.py\")\n            logger.info(\"\ud83d\udcdd Pre-existing script output:\")\n            logger.info(result.stdout)\n\n            # List files to show existing content\n            result = sandbox.execute_command(\"ls -la /sandbox/\")\n            logger.info(\"\ud83d\udcc1 Container contents:\")\n            logger.info(result.stdout)\n\n    except ContainerError:\n        logger.exception(\"\u274c Failed to connect to container\")\n    except Exception:\n        logger.exception(\"\u274c Unexpected error\")\n\n\ndef demo_connect_to_existing_kubernetes_pod() -&gt; None:\n    \"\"\"Demo connecting to an existing Kubernetes pod.\"\"\"\n    logger.info(\"\\n%s\", \"=\" * 60)\n    logger.info(\"\u2638\ufe0f  Demo: Connecting to Existing Kubernetes Pod\")\n    logger.info(\"%s\", \"=\" * 60)\n\n    # For demo purposes, we'll create a pod first\n    # In practice, you would have a pod already running\n    try:\n        # First create a pod (simulating existing pod)\n        logger.info(\"\ud83d\udce6 Creating a demo pod (simulating existing pod)...\")\n        sandbox = SandboxSession(backend=SandboxBackend.KUBERNETES, lang=\"python\", verbose=True)\n        sandbox.open()\n        pod_id = sandbox.container  # Get pod name\n\n        # Setup some environment\n        sandbox.execute_command(\"echo 'Pod environment ready' &gt; /sandbox/pod_info.txt\")\n        logger.info(\"\u2705 Demo pod created: %s\", pod_id)\n\n        # Now connect to the \"existing\" pod\n        logger.info(\"\ud83d\udd17 Connecting to existing pod: %s\", pod_id)\n\n        # Connect to the existing pod\n        with SandboxSession(\n            backend=SandboxBackend.KUBERNETES,\n            container_id=pod_id,  # Connect to existing pod\n            lang=\"python\",\n            verbose=True,\n        ) as sandbox:\n            logger.info(\"\u2705 Connected to existing pod successfully!\")\n\n            # Run code in the existing pod\n            result = sandbox.run(\"\"\"\nimport sys\nprint(f\"Python version: {sys.version}\")\nprint(\"Running in existing Kubernetes pod!\")\n\n# Read the existing file\ntry:\n    with open('/sandbox/pod_info.txt', 'r') as f:\n        info = f.read().strip()\n        print(f\"Pod info: {info}\")\nexcept FileNotFoundError:\n    print(\"Pod info file not found\")\n\n# Show current working directory\nimport os\nprint(f\"Current directory: {os.getcwd()}\")\nprint(f\"Directory contents: {os.listdir('/sandbox')}\")\n\"\"\")\n\n            logger.info(\"\ud83d\udcca Pod execution output:\")\n            logger.info(result.stdout)\n\n    except ContainerError:\n        logger.exception(\"\u274c Failed to connect to pod\")\n    except Exception:\n        logger.exception(\"\u274c Error in Kubernetes demo (cluster may not be available)\")\n\n\ndef demo_connect_to_existing_podman_container() -&gt; None:\n    \"\"\"Demo connecting to an existing Podman container.\"\"\"\n    logger.info(\"\\n%s\", \"=\" * 60)\n    logger.info(\"\ud83e\uddad Demo: Connecting to Existing Podman Container\")\n    logger.info(\"%s\", \"=\" * 60)\n\n    try:\n        from podman import PodmanClient\n\n        client = PodmanClient(\n            base_url=\"unix:///var/folders/lh/rjbzw60n1fv7xr9kffn7gr840000gn/T/podman/podman-machine-default-api.sock\"\n        )\n\n        # First create a container (simulating existing container)\n        logger.info(\"\ud83d\udce6 Creating a demo Podman container...\")\n        sandbox = SandboxSession(\n            backend=SandboxBackend.PODMAN, client=client, lang=\"python\", verbose=True, keep_template=True\n        )\n        sandbox.open()\n        container_id = sandbox.container.id\n\n        # Setup some environment\n        sandbox.run(\"\"\"\nwith open('/sandbox/podman_info.txt', 'w') as f:\n    f.write('Podman environment ready')\n\"\"\")\n        logger.info(\"\u2705 Demo Podman container created: %s...\", container_id[:12])\n\n        # Connect to the existing container\n        logger.info(\"\ud83d\udd17 Connecting to existing Podman container...\")\n        with SandboxSession(\n            backend=SandboxBackend.PODMAN, client=client, container_id=container_id, lang=\"python\", verbose=True\n        ) as sandbox:\n            logger.info(\"\u2705 Connected to existing Podman container successfully!\")\n\n            # Run code in the existing container\n            result = sandbox.run(\"\"\"\nimport platform\nprint(f\"Platform: {platform.platform()}\")\nprint(\"Running in existing Podman container!\")\n\n# Read the existing file\ntry:\n    with open('/sandbox/podman_info.txt', 'r') as f:\n        info = f.read().strip()\n        print(f\"Container info: {info}\")\nexcept FileNotFoundError:\n    print(\"Container info file not found\")\n\"\"\")\n\n            logger.info(\"\ud83d\udcca Podman execution output:\")\n            logger.info(result.stdout)\n\n    except ImportError:\n        logger.warning(\"\u26a0\ufe0f  Podman not available, skipping Podman demo\")\n    except ContainerError:\n        logger.exception(\"\u274c Failed to connect to Podman container\")\n    except Exception:\n        logger.exception(\"\u274c Error in Podman demo\")\n\n\ndef demo_error_handling() -&gt; None:\n    \"\"\"Demo error handling when connecting to non-existent containers.\"\"\"\n    logger.info(\"\\n%s\", \"=\" * 60)\n    logger.info(\"\ud83d\udee1\ufe0f  Demo: Error Handling\")\n    logger.info(\"%s\", \"=\" * 60)\n\n    # Try connecting to non-existent container\n    logger.info(\"\ud83e\uddea Testing connection to non-existent container...\")\n    try:\n        with SandboxSession(container_id=\"non-existent-container-id\", lang=\"python\", verbose=True) as sandbox:\n            sandbox.run(\"print('This should not work')\")\n\n    except ContainerError:\n        logger.info(\"\u2705 Correctly caught ContainerError\")\n    except Exception:\n        logger.exception(\"\u274c Unexpected error type\")\n\n    # Try with invalid pod name\n    logger.info(\"\ud83e\uddea Testing connection to non-existent pod...\")\n    try:\n        with SandboxSession(\n            backend=SandboxBackend.KUBERNETES, container_id=\"non-existent-pod\", lang=\"python\", verbose=True\n        ) as sandbox:\n            sandbox.run(\"print('This should not work')\")\n\n    except ContainerError:\n        logger.info(\"\u2705 Correctly caught ContainerError for K8s\")\n    except Exception:\n        logger.exception(\"\u26a0\ufe0f  K8s error (cluster may not be available)\")\n\n\ndef main() -&gt; None:\n    \"\"\"Run all demos.\"\"\"\n    logger.info(\"\ud83c\udfaf LLM Sandbox - Existing Container Support Demo\")\n    logger.info(\"=\" * 80)\n    logger.info(\"This demo shows how to connect to existing containers/pods\")\n    logger.info(\"instead of creating new ones from scratch.\")\n    logger.info(\"=\" * 80)\n\n    # Give container a moment to settle\n    time.sleep(2)\n\n    # Demo 1: Connect to existing Docker container\n    demo_connect_to_existing_docker_container()\n\n    # Demo 2: Connect to existing Kubernetes pod\n    demo_connect_to_existing_kubernetes_pod()\n\n    # # Demo 3: Connect to existing Podman container\n    demo_connect_to_existing_podman_container()\n\n    # Demo 4: Error handling\n    demo_error_handling()\n\n    logger.info(\"\\n%s\", \"=\" * 80)\n    logger.info(\"\ud83c\udf89 Demo completed!\")\n    logger.info(\"Key benefits of existing container support:\")\n    logger.info(\"\u2022 \ud83d\ude80 Faster startup (no environment setup)\")\n    logger.info(\"\u2022 \ud83d\udd27 Work with pre-configured environments\")\n    logger.info(\"\u2022 \ud83d\udd04 Reuse containers across multiple sandboxs\")\n    logger.info(\"\u2022 \ud83d\udc1b Connect to running containers for debugging\")\n    logger.info(\"\u2022 \ud83d\udce6 Integrate with external container management\")\n    logger.info(\"=\" * 80)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"existing-container-support/#backend-specific-notes","title":"Backend-Specific Notes","text":""},{"location":"existing-container-support/#docker","title":"Docker","text":"<ul> <li>Uses container ID or name</li> <li>Supports both running and stopped containers (will start if stopped)</li> <li>Full Docker API compatibility</li> </ul>"},{"location":"existing-container-support/#kubernetes","title":"Kubernetes","text":"<ul> <li>Uses pod name as <code>container_id</code></li> <li>Must specify correct namespace via <code>kube_namespace</code> parameter</li> <li>Pod must be in \"Running\" state</li> <li>Will wait briefly for \"Pending\" pods to start</li> </ul>"},{"location":"existing-container-support/#podman","title":"Podman","text":"<ul> <li>Uses container ID or name</li> <li>Compatible with Docker API</li> <li>Supports both running and stopped containers</li> </ul>"},{"location":"existing-container-support/#best-practices","title":"Best Practices","text":"<ol> <li>Ensure Environment Readiness: Make sure containers have required interpreters/compilers</li> <li>Handle Connection Errors: Always wrap in try/catch for <code>ContainerError</code></li> <li>Document Dependencies: Clearly document what your existing containers need</li> <li>Test Connectivity: Verify container is accessible before production use</li> <li>Monitor Resources: Existing containers may have different resource constraints</li> </ol>"},{"location":"getting-started/","title":"Getting Started with LLM Sandbox","text":"<p>This guide will help you get up and running with LLM Sandbox in just a few minutes.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Python 3.10 or higher installed</li> <li>Container runtime (at least one of the following):<ul> <li>Docker Desktop or Docker Engine</li> <li>Kubernetes cluster (local or remote)</li> <li>Podman</li> </ul> </li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#basic-installation","title":"Basic Installation","text":"<p>Install the core package:</p> <pre><code>pip install llm-sandbox\n</code></pre>"},{"location":"getting-started/#backend-specific-installation","title":"Backend-Specific Installation","text":"<p>Install with support for specific backends:</p> <pre><code># Docker backend (most common)\npip install 'llm-sandbox[docker]'\n\n# Kubernetes backend\npip install 'llm-sandbox[k8s]'\n\n# Podman backend\npip install 'llm-sandbox[podman]'\n\n# All backends\npip install 'llm-sandbox[docker,k8s,podman]'\n</code></pre>"},{"location":"getting-started/#development-installation","title":"Development Installation","text":"<p>For contributing or development:</p> <pre><code>git clone https://github.com/vndee/llm-sandbox.git\ncd llm-sandbox\npip install -e '.[dev]'\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":""},{"location":"getting-started/#your-first-sandbox-session","title":"Your First Sandbox Session","text":"<p>Let's run a simple Python code in a sandbox:</p> <pre><code>from llm_sandbox import SandboxSession\n\n# Create and use a sandbox session\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nprint(\"Hello from LLM Sandbox!\")\nprint(\"I'm running in a secure container.\")\n    \"\"\")\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Hello from LLM Sandbox!\nI'm running in a secure container.\n</code></pre></p>"},{"location":"getting-started/#installing-libraries","title":"Installing Libraries","text":"<p>Install and use Python packages dynamically:</p> <pre><code>from llm_sandbox import SandboxSession\n\nwith SandboxSession(lang=\"python\") as session:\n    # Run code with numpy\n    result = session.run(\"\"\"\nimport numpy as np\n\n# Create an array\narr = np.array([1, 2, 3, 4, 5])\nprint(f\"Array: {arr}\")\nprint(f\"Mean: {np.mean(arr)}\")\nprint(f\"Sum: {np.sum(arr)}\")\n    \"\"\", libraries=[\"numpy\"])\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Array: [1 2 3 4 5]\nMean: 3.0\nSum: 15\n</code></pre></p>"},{"location":"getting-started/#working-with-different-languages","title":"Working with Different Languages","text":"<p>LLM Sandbox supports multiple programming languages:</p>"},{"location":"getting-started/#javascript-example","title":"JavaScript Example","text":"<pre><code>with SandboxSession(lang=\"javascript\") as session:\n    result = session.run(\"\"\"\nconst greeting = \"Hello from Node.js!\";\nconsole.log(greeting);\n\n// Using a library\nconst axios = require('axios');\nconsole.log(\"Axios loaded successfully!\");\n    \"\"\", libraries=[\"axios\"])\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Hello from Node.js!\nAxios loaded successfully!\n</code></pre></p>"},{"location":"getting-started/#java-example","title":"Java Example","text":"<pre><code>with SandboxSession(lang=\"java\") as session:\n    result = session.run(\"\"\"\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println(\"Hello from Java!\");\n\n        // Print Java version\n        String version = System.getProperty(\"java.version\");\n        System.out.println(\"Java version: \" + version);\n    }\n}\n    \"\"\")\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Hello from Java!\nJava version: 17.0.1\n</code></pre></p>"},{"location":"getting-started/#c-example","title":"C++ Example","text":"<pre><code>with SandboxSession(lang=\"cpp\") as session:\n    result = session.run(\"\"\"\n#include &lt;iostream&gt;\n\nint main() {\n    std::cout &lt;&lt; \"Hello from C++!\" &lt;&lt; std::endl;\n    return 0;\n}\n    \"\"\")\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Hello from C++!\n</code></pre></p>"},{"location":"getting-started/#go-example","title":"Go Example","text":"<pre><code>with SandboxSession(lang=\"go\") as session:\n    result = session.run(\"\"\"\npackage main\nimport \"fmt\"\nfunc main() {\n    fmt.Println(\"Hello from Go!\")\n}\n    \"\"\")\n\n    print(result.stdout)\n</code></pre> <p>Output: <pre><code>Hello from Go!\n</code></pre></p>"},{"location":"getting-started/#capturing-plots-and-visualizations","title":"Capturing Plots and Visualizations","text":"<p>LLM Sandbox can automatically capture plots generated by your code by using the <code>ArtifactSandboxSession</code> class. It is currently only supported for Python code, but will be supported for other languages in the future.</p> <pre><code># ruff: noqa: T201\n\nimport base64\nfrom pathlib import Path\n\nfrom llm_sandbox import ArtifactSandboxSession\n\ncode = \"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.style.use('default')\n\n# Generate data\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x) + np.random.normal(0, 0.1, 100)\ny2 = np.cos(x) + np.random.normal(0, 0.1, 100)\n\n# Create plot\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes[0, 0].plot(x, y1, 'b-', alpha=0.7)\naxes[0, 0].set_title('Sine Wave')\naxes[0, 1].scatter(x[::5], y2[::5], c='red', alpha=0.6)\naxes[0, 1].set_title('Cosine Scatter')\naxes[1, 0].hist(y1, bins=20, alpha=0.7, color='green')\naxes[1, 0].set_title('Sine Distribution')\naxes[1, 1].bar(range(10), np.random.rand(10), alpha=0.7)\naxes[1, 1].set_title('Random Bar Chart')\nplt.tight_layout()\nplt.show()\n\nprint('Plot generated successfully!')\n\"\"\"\n\n# Create a sandbox session\nwith ArtifactSandboxSession(lang=\"python\", verbose=True) as session:\n    # Run Python code safely\n    result = session.run(code)\n\n    print(result.stdout)  # Output: Plot generated successfully!\n\n    for plot in result.plots:\n        with Path(\"docs/assets/example.png\").open(\"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre> <p>Output: <pre><code>Plot generated successfully!\n</code></pre></p> <p></p>"},{"location":"getting-started/#using-different-backends","title":"Using Different Backends","text":""},{"location":"getting-started/#docker-backend-default","title":"Docker Backend (Default)","text":"<pre><code>from llm_sandbox import SandboxSession, SandboxBackend\n\nwith SandboxSession(\n    backend=SandboxBackend.DOCKER,\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Running on Docker!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"getting-started/#kubernetes-backend","title":"Kubernetes Backend","text":"<pre><code>with SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    lang=\"python\",\n    kube_namespace=\"default\"\n) as session:\n    result = session.run(\"print('Running on Kubernetes!')\")\n    print(result.stdout)\n</code></pre> <p>Important: Custom Pod Manifests</p> <p>When using custom pod manifests with Kubernetes, ensure your manifest includes these required configurations:</p> <pre><code># Required pod manifest structure\npod_manifest = {\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"name\": \"your-pod-name\",  # Will be overridden with unique name\n        \"namespace\": \"default\",\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"name\": \"my-container\",  # Can be any valid container name\n                \"image\": \"your-image:latest\",\n                \"tty\": True,  # REQUIRED: Keeps container alive\n                \"securityContext\": {  # REQUIRED: For proper permissions\n                    \"runAsUser\": 0,\n                    \"runAsGroup\": 0,\n                },\n                # Your other container settings...\n            }\n        ],\n        \"securityContext\": {  # REQUIRED: Pod-level security context\n            \"runAsUser\": 0,\n            \"runAsGroup\": 0,\n        },\n    },\n}\n\nwith SandboxSession(\n    backend=SandboxBackend.KUBERNETES,\n    lang=\"python\",\n    pod_manifest=pod_manifest\n) as session:\n    result = session.run(\"print('Custom manifest working!')\")\n</code></pre> <p>\u26a0\ufe0f Critical Requirements: - <code>\"tty\": True</code> is essential for keeping the container alive - Both pod-level and container-level <code>securityContext</code> are required for proper permissions - Container name can be any valid name (no longer restricted to \"sandbox-container\") - Missing any of these will cause connection or permission errors</p>"},{"location":"getting-started/#podman-backend","title":"Podman Backend","text":"<pre><code>from podman import PodmanClient\n\nclient = PodmanClient(base_url=\"unix:///run/podman/podman.sock\")\n\nwith SandboxSession(\n    backend=SandboxBackend.PODMAN,\n    client=client,\n    lang=\"python\"\n) as session:\n    result = session.run(\"print('Running on Podman!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"getting-started/#working-with-files","title":"Working with Files","text":"<p>Copy files to and from the sandbox:</p> <pre><code>with SandboxSession(lang=\"python\") as session:\n    # Copy file to sandbox\n    session.copy_to_runtime(\"local_data.csv\", \"/sandbox/data.csv\")\n\n    # Process the file\n    result = session.run(\"\"\"\nimport pandas as pd\n\n# Read the CSV file\ndf = pd.read_csv('/sandbox/data.csv')\nprint(f\"Shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(f\"First 5 rows:\\n{df.head()}\")\n\n# Save processed data\ndf.to_csv('/sandbox/processed.csv', index=False)\n    \"\"\", libraries=[\"pandas\"])\n\n    # Copy file back from sandbox\n    session.copy_from_runtime(\"/sandbox/processed.csv\", \"processed_data.csv\")\n</code></pre>"},{"location":"getting-started/#setting-resource-limits","title":"Setting Resource Limits","text":"<p>Control resource usage with runtime configurations:</p> <pre><code>with SandboxSession(\n    lang=\"python\",\n    runtime_configs={\n        \"cpu_count\": 2,           # Limit to 2 CPU cores\n        \"mem_limit\": \"512m\",      # Limit memory to 512MB\n        \"timeout\": 30,            # 30 second timeout\n    }\n) as session:\n    result = session.run(\"\"\"\n# This will run with limited resources\nimport multiprocessing\nprint(f\"Available CPUs: {multiprocessing.cpu_count()}\")\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"getting-started/#basic-security-policies","title":"Basic Security Policies","text":"<p>Implement basic security checks:</p> <pre><code>from llm_sandbox import SandboxSession\nfrom llm_sandbox.security import SecurityPolicy, SecurityPattern, SecurityIssueSeverity\n\n# Create a security policy\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[\n        SecurityPattern(\n            pattern=r\"os\\.system\",\n            description=\"System command execution\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        SecurityPattern(\n            pattern=r\"eval\\s*\\(\",\n            description=\"Dynamic code evaluation\",\n            severity=SecurityIssueSeverity.MEDIUM\n        )\n    ]\n)\n\nwith SandboxSession(lang=\"python\", security_policy=policy) as session:\n    # Check if code is safe before running\n    code = \"print('This is safe code')\"\n    is_safe, violations = session.is_safe(code)\n\n    if is_safe:\n        result = session.run(code)\n        print(result.stdout)\n    else:\n        print(\"Code failed security check:\")\n        for v in violations:\n            print(f\"  - {v.description}\")\n</code></pre>"},{"location":"getting-started/#common-use-cases","title":"Common Use Cases","text":""},{"location":"getting-started/#1-llm-code-execution","title":"1. LLM Code Execution","text":"<p>Execute code generated by an LLM safely:</p> <p>Example with Langchain: <pre><code># ruff: noqa: E501\n\n# Reference: https://python.langchain.com/docs/how_to/custom_tools/\n\nimport logging\n\nfrom langchain import hub\nfrom langchain.agents import AgentExecutor, create_tool_calling_agent\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\nfrom llm_sandbox import SandboxSession\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\n@tool\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n    tools = [run_code]\n\n    agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore[arg-type]\n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  # type: ignore[arg-type]\n    output = agent_executor.invoke({\n        \"input\": \"Write python code to calculate Pi number by Monte Carlo method then run it.\"\n    })\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Write python code to calculate the factorial of a number then run it.\"})\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Write python code to calculate the Fibonacci sequence then run it.\"})\n    logger.info(\"Agent: %s\", output)\n\n    output = agent_executor.invoke({\"input\": \"Calculate the sum of the first 10000 numbers.\"})\n    logger.info(\"Agent: %s\", output)\n</code></pre></p> <p>Example with Langgraph: <pre><code>import logging\n\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import create_react_agent\n\nfrom llm_sandbox import SandboxSession\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\n@tool\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    agent = create_react_agent(model=\"openai:gpt-4.1-nano\", tools=[run_code])\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Write python code to calculate Pi number by Monte Carlo method then run it.\",\n                }\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Write python code to calculate the factorial of a number then run it.\"}\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Write python code to calculate the Fibonacci sequence then run it.\"}\n            ]\n        }),\n    )\n    logger.info(\n        \"Agent: %s\",\n        agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Calculate the sum of the first 10000 numbers.\"}]}),\n    )\n</code></pre></p> <p>Example with LlamaIndex: <pre><code># ruff: noqa: E501\n\n# Reference: https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/\n\nimport logging\n\nimport nest_asyncio\nfrom llama_index.core.agent import FunctionCallingAgentWorker\nfrom llama_index.core.tools import FunctionTool\nfrom llama_index.llms.openai import OpenAI\n\nfrom llm_sandbox import SandboxSession\n\nnest_asyncio.apply()\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\n\ndef run_code(lang: str, code: str, libraries: list | None = None) -&gt; str:\n    \"\"\"Run code in a sandboxed environment.\n\n    :param lang: The language of the code, must be one of ['python', 'java', 'javascript', 'cpp', 'go', 'ruby'].\n    :param code: The code to run.\n    :param libraries: The libraries to use, it is optional.\n    :return: The output of the code.\n    \"\"\"\n    with SandboxSession(lang=lang, verbose=False) as session:\n        return session.run(code, libraries).stdout\n\n\nif __name__ == \"__main__\":\n    llm = OpenAI(model=\"gpt-4.1-nano\", temperature=0)\n    code_execution_tool = FunctionTool.from_defaults(fn=run_code)\n\n    agent_worker = FunctionCallingAgentWorker.from_tools(\n        [code_execution_tool],\n        llm=llm,\n        verbose=True,\n        allow_parallel_tool_calls=False,\n    )\n    agent = agent_worker.as_agent()\n\n    response = agent.chat(\"Write python code to calculate Pi number by Monte Carlo method then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Write python code to calculate the factorial of a number then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Write python code to calculate the Fibonacci sequence then run it.\")\n    logger.info(response)\n\n    response = agent.chat(\"Calculate the sum of the first 10000 numbers.\")\n    logger.info(response)\n</code></pre></p>"},{"location":"getting-started/#2-data-analysis-pipeline","title":"2. Data Analysis Pipeline","text":"<p>Run data analysis safely:</p> <pre><code>with SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate sample data\nnp.random.seed(42)\ndata = {\n    'sales': np.random.randint(100, 1000, 50),\n    'customers': np.random.randint(10, 100, 50),\n    'profit_margin': np.random.uniform(0.1, 0.5, 50)\n}\n\ndf = pd.DataFrame(data)\n\n# Analysis\nprint(\"Data Summary:\")\nprint(df.describe())\nprint(f\"\\nTotal Sales: ${df['sales'].sum():,}\")\nprint(f\"Average Profit Margin: {df['profit_margin'].mean():.2%}\")\n\n# Visualization\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.hist(df['sales'], bins=15, edgecolor='black')\nplt.title('Sales Distribution')\n\nplt.subplot(1, 3, 2)\nplt.scatter(df['customers'], df['sales'])\nplt.xlabel('Customers')\nplt.ylabel('Sales')\nplt.title('Sales vs Customers')\n\nplt.subplot(1, 3, 3)\nplt.boxplot(df['profit_margin'])\nplt.title('Profit Margin Distribution')\n\nplt.tight_layout()\nplt.show()\n    \"\"\", libraries=[\"pandas\", \"numpy\", \"matplotlib\"])\n\n    print(result.stdout)\n</code></pre>"},{"location":"getting-started/#3-testing-user-submitted-code","title":"3. Testing User-Submitted Code","text":"<p>Safely test code submitted by users:</p> <pre><code>def test_user_code(code: str, test_cases: list):\n    \"\"\"Test user code against test cases\"\"\"\n    with SandboxSession(lang=\"python\") as session:\n        # Inject test framework\n        full_code = f\"\"\"\n{code}\n\n# Run test cases\ntest_results = []\n\"\"\"\n\n        for i, test in enumerate(test_cases):\n            full_code += f\"\"\"\ntry:\n    result = {test['call']}\n    expected = {test['expected']}\n    passed = result == expected\n    test_results.append({{\n        'test': {i},\n        'passed': passed,\n        'expected': expected,\n        'actual': result\n    }})\nexcept Exception as e:\n    test_results.append({{\n        'test': {i},\n        'passed': False,\n        'error': str(e)\n    }})\n\"\"\"\n\n        full_code += \"\"\"\n# Print results\nfor result in test_results:\n    print(result)\n\"\"\"\n\n        result = session.run(full_code)\n        return result.stdout\n\n# Example usage\nuser_code = \"\"\"\ndef add(a, b):\n    return a + b\n\ndef multiply(a, b):\n    return a * b\n\"\"\"\n\ntest_cases = [\n    {\"call\": \"add(2, 3)\", \"expected\": 5},\n    {\"call\": \"add(-1, 1)\", \"expected\": 0},\n    {\"call\": \"multiply(3, 4)\", \"expected\": 12},\n    {\"call\": \"multiply(0, 5)\", \"expected\": 0},\n]\n\nprint(test_user_code(user_code, test_cases))\n</code></pre>"},{"location":"getting-started/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/#1-always-use-context-managers","title":"1. Always Use Context Managers","text":"<p>Always use the <code>with</code> statement to ensure proper cleanup:</p> <pre><code># Good \u2713\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"print('Hello')\")\n\n# Avoid \u2717\nsession = SandboxSession(lang=\"python\")\nsession.open()\nresult = session.run(\"print('Hello')\")\nsession.close()  # Easy to forget!\n</code></pre>"},{"location":"getting-started/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code>with SandboxSession(lang=\"python\") as session:\n    try:\n        result = session.run(code)\n        if result.exit_code != 0:\n            print(f\"Error: {result.stderr}\")\n        else:\n            print(f\"Output: {result.stdout}\")\n    except Exception as e:\n        print(f\"Sandbox error: {e}\")\n</code></pre>"},{"location":"getting-started/#3-use-security-policies","title":"3. Use Security Policies","text":"<p>Always use security policies and check if the code is safe before running it:</p> <pre><code>from llm_sandbox import SandboxSession\nfrom llm_sandbox.security import SecurityPolicy, SecurityPattern, SecurityIssueSeverity\n\n# Create a security policy\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[\n        SecurityPattern(\n            pattern=r\"os\\.system\",\n            description=\"System command execution\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        SecurityPattern(\n            pattern=r\"eval\\s*\\(\",\n            description=\"Dynamic code evaluation\",\n            severity=SecurityIssueSeverity.MEDIUM\n        )\n    ]\n)\n\nwith SandboxSession(lang=\"python\", security_policy=policy) as session:\n    # Check if code is safe before running\n    code = \"print('This is safe code')\"\n    is_safe, violations = session.is_safe(code)\n\n    if is_safe:\n        result = session.run(code)\n        print(result.stdout)\n    else:\n        print(\"Code failed security check:\")\n        for v in violations:\n            print(f\"  - {v.description}\")\n</code></pre>"},{"location":"getting-started/#4-use-your-own-pre-built-images","title":"4. Use Your Own Pre-built Images","text":"<p>You can use your own pre-built images with appropriate dependencies and environment set up by specifying the <code>image</code> parameter when creating a sandbox session. It can be useful for running code that requires specific dependencies or environment variables. Since the image is pre-built, it will be faster to run the code without the need to build the image or install dependencies.</p> <pre><code>from llm_sandbox import SandboxSession\n\nwith SandboxSession(\n    lang=\"python\",\n    image=\"ghcr.io/vndee/sandbox-python-311-bullseye\"\n) as session:\n    result = session.run(\"print('Hello from my custom image!')\")\n    print(result.stdout)\n</code></pre>"},{"location":"getting-started/#5-skip-environment-setup-for-production","title":"5. Skip Environment Setup for Production","text":"<p>For production deployments or when using pre-configured images, skip automatic environment setup for faster container startup:</p> <pre><code>from llm_sandbox import SandboxSession\n\n# Skip environment setup when using custom images\nwith SandboxSession(\n    lang=\"python\",\n    image=\"my-registry.com/python-ml:latest\",  # Pre-configured image\n    skip_environment_setup=True  # Skip pip upgrades and venv creation\n) as session:\n    result = session.run(\"import numpy; print('Ready!')\")\n</code></pre> <p>When to use <code>skip_environment_setup=True</code>:</p> <ul> <li>Production deployments where startup time is critical</li> <li>Custom images with pre-installed packages</li> <li>CI/CD pipelines and batch processing</li> <li>Air-gapped environments without external package access</li> </ul> <p>See the Configuration Guide for detailed information.</p>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#container-runtime-not-found","title":"Container Runtime Not Found","text":"<pre><code># Check Docker\ndocker --version\n\n# Check Podman\npodman --version\n\n# Check Kubernetes\nkubectl version\n</code></pre>"},{"location":"getting-started/#permission-errors","title":"Permission Errors","text":"<pre><code># Run as non-root user\nwith SandboxSession(\n    lang=\"python\",\n    runtime_configs={\"user\": \"1000:1000\"},\n    workdir=\"/tmp/sandbox\"\n) as session:\n    pass\n</code></pre>"},{"location":"getting-started/#import-errors","title":"Import Errors","text":"<pre><code># Install backend-specific dependencies\npip install 'llm-sandbox[docker]'\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Configuration Options</li> <li>Explore Security Policies</li> <li>Understand Container Backends</li> <li>Check out more Examples</li> <li>Read the API Reference</li> </ul>"},{"location":"integrations/","title":"LLM Framework Integrations","text":"<p>LLM Sandbox seamlessly integrates with popular LLM frameworks to provide secure code execution capabilities. This guide covers integration patterns and examples.</p>"},{"location":"integrations/#langchain-integration","title":"LangChain Integration","text":""},{"location":"integrations/#basic-tool-integration","title":"Basic Tool Integration","text":"<pre><code>from langchain.tools import tool\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.llms import OpenAI\nfrom llm_sandbox import SandboxSession\n\n@tool\ndef execute_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Execute code in a secure sandbox environment.\n\n    Args:\n        code: The code to execute\n        language: Programming language (python, javascript, java, cpp, go, ruby)\n\n    Returns:\n        The execution output\n    \"\"\"\n    with SandboxSession(lang=language, verbose=False) as session:\n        result = session.run(code)\n        if result.exit_code != 0:\n            return f\"Error: {result.stderr}\"\n        return result.stdout\n\n# Create agent with code execution tool\nllm = OpenAI(temperature=0)\ntools = [execute_code]\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True\n)\n\n# Use the agent\nresponse = agent.run(\n    \"Write and execute Python code to calculate the factorial of 10\"\n)\nprint(response)\n</code></pre>"},{"location":"integrations/#advanced-tool-with-libraries","title":"Advanced Tool with Libraries","text":"<pre><code>from langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass CodeExecutionInput(BaseModel):\n    \"\"\"Input for code execution tool\"\"\"\n    code: str = Field(description=\"The code to execute\")\n    language: str = Field(default=\"python\", description=\"Programming language\")\n    libraries: Optional[List[str]] = Field(\n        default=None,\n        description=\"Libraries to install before execution\"\n    )\n\ndef execute_code_with_libs(\n    code: str,\n    language: str = \"python\",\n    libraries: Optional[List[str]] = None\n) -&gt; str:\n    \"\"\"Execute code with optional library installation\"\"\"\n    try:\n        with SandboxSession(lang=language) as session:\n            result = session.run(code, libraries=libraries)\n            return f\"Exit code: {result.exit_code}\\n{result.stdout}\"\n    except Exception as e:\n        return f\"Execution error: {str(e)}\"\n\n# Create structured tool\ncode_tool = StructuredTool.from_function(\n    func=execute_code_with_libs,\n    name=\"CodeExecutor\",\n    description=\"Execute code with optional library installation\",\n    args_schema=CodeExecutionInput\n)\n\n# Use in agent\nagent = initialize_agent(\n    [code_tool],\n    llm,\n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True\n)\n\nresponse = agent.run(\n    \"Use numpy to create a 5x5 matrix of random numbers and calculate its determinant\"\n)\n</code></pre>"},{"location":"integrations/#chain-with-code-execution","title":"Chain with Code Execution","text":"<pre><code>from langchain.chains import LLMChain, SequentialChain\nfrom langchain.prompts import PromptTemplate\n\n# Chain 1: Generate code\ncode_prompt = PromptTemplate(\n    input_variables=[\"task\"],\n    template=\"\"\"Write Python code to accomplish this task: {task}\n\nProvide only the code, no explanations.\"\"\"\n)\ncode_chain = LLMChain(llm=llm, prompt=code_prompt, output_key=\"code\")\n\n# Chain 2: Execute code\ndef execute_code_chain(inputs: dict) -&gt; dict:\n    code = inputs[\"code\"]\n    with SandboxSession(lang=\"python\") as session:\n        result = session.run(code)\n        return {\"output\": result.stdout, \"error\": result.stderr}\n\n# Combine chains\nfrom langchain.chains import TransformChain\n\nexecute_chain = TransformChain(\n    input_variables=[\"code\"],\n    output_variables=[\"output\", \"error\"],\n    transform=execute_code_chain\n)\n\noverall_chain = SequentialChain(\n    chains=[code_chain, execute_chain],\n    input_variables=[\"task\"],\n    output_variables=[\"code\", \"output\", \"error\"],\n    verbose=True\n)\n\n# Run the chain\nresult = overall_chain({\"task\": \"Generate the first 20 Fibonacci numbers\"})\nprint(f\"Generated code:\\n{result['code']}\")\nprint(f\"\\nOutput:\\n{result['output']}\")\n</code></pre>"},{"location":"integrations/#memory-and-state-management","title":"Memory and State Management","text":"<pre><code>from langchain.memory import ConversationSummaryMemory\nfrom langchain.chains import ConversationChain\n\nclass CodeExecutionMemory:\n    \"\"\"Custom memory for code execution history\"\"\"\n\n    def __init__(self):\n        self.executions = []\n        self.session = None\n\n    def start_session(self, **kwargs):\n        self.session = SandboxSession(**kwargs)\n        self.session.open()\n\n    def execute(self, code: str, libraries: List[str] = None):\n        if not self.session:\n            self.start_session(lang=\"python\")\n\n        result = self.session.run(code, libraries)\n        self.executions.append({\n            \"code\": code,\n            \"output\": result.stdout,\n            \"error\": result.stderr,\n            \"exit_code\": result.exit_code\n        })\n        return result\n\n    def close_session(self):\n        if self.session:\n            self.session.close()\n            self.session = None\n\n# Use with conversation chain\nmemory = ConversationSummaryMemory(llm=llm)\ncode_memory = CodeExecutionMemory()\n\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=True\n)\n\n# Interactive code development\ncode_memory.start_session(lang=\"python\")\n\n# First execution\nresult1 = code_memory.execute(\"data = [1, 2, 3, 4, 5]\")\nresult2 = code_memory.execute(\"print(f'Sum: {sum(data)}')\")\n\ncode_memory.close_session()\n</code></pre>"},{"location":"integrations/#langgraph-integration","title":"LangGraph Integration","text":""},{"location":"integrations/#stateful-code-execution-workflow","title":"Stateful Code Execution Workflow","text":"<pre><code>from typing import TypedDict, Annotated, Sequence\nfrom langgraph.graph import Graph, END\nfrom langgraph.prebuilt import ToolExecutor, ToolInvocation\nimport operator\n\nclass CodeState(TypedDict):\n    \"\"\"State for code execution workflow\"\"\"\n    task: str\n    code: str\n    output: str\n    error: str\n    iterations: int\n    messages: Annotated[Sequence[str], operator.add]\n\n# Define nodes\ndef generate_code(state: CodeState) -&gt; CodeState:\n    \"\"\"Generate code based on task\"\"\"\n    # Use LLM to generate code\n    prompt = f\"Write Python code for: {state['task']}\"\n    code = llm.predict(prompt)\n\n    return {\n        \"code\": code,\n        \"messages\": [f\"Generated code for task: {state['task']}\"]\n    }\n\ndef execute_code(state: CodeState) -&gt; CodeState:\n    \"\"\"Execute the generated code\"\"\"\n    with SandboxSession(lang=\"python\") as session:\n        result = session.run(state[\"code\"])\n\n        return {\n            \"output\": result.stdout,\n            \"error\": result.stderr,\n            \"messages\": [f\"Executed code with exit code: {result.exit_code}\"]\n        }\n\ndef check_output(state: CodeState) -&gt; str:\n    \"\"\"Check if output is satisfactory\"\"\"\n    if state[\"error\"]:\n        return \"fix_code\"\n    elif state[\"iterations\"] &gt;= 3:\n        return \"end\"\n    else:\n        return \"end\"\n\ndef fix_code(state: CodeState) -&gt; CodeState:\n    \"\"\"Fix code based on error\"\"\"\n    prompt = f\"\"\"Fix this Python code that has an error:\n\nCode:\n{state['code']}\n\nError:\n{state['error']}\n\"\"\"\n    fixed_code = llm.predict(prompt)\n\n    return {\n        \"code\": fixed_code,\n        \"iterations\": state[\"iterations\"] + 1,\n        \"messages\": [f\"Attempted to fix code, iteration {state['iterations'] + 1}\"]\n    }\n\n# Build graph\nworkflow = Graph()\n\n# Add nodes\nworkflow.add_node(\"generate\", generate_code)\nworkflow.add_node(\"execute\", execute_code)\nworkflow.add_node(\"fix\", fix_code)\n\n# Add edges\nworkflow.add_edge(\"generate\", \"execute\")\nworkflow.add_conditional_edges(\n    \"execute\",\n    check_output,\n    {\n        \"fix_code\": \"fix\",\n        \"end\": END\n    }\n)\nworkflow.add_edge(\"fix\", \"execute\")\n\n# Set entry point\nworkflow.set_entry_point(\"generate\")\n\n# Compile\napp = workflow.compile()\n\n# Run workflow\ninitial_state = {\n    \"task\": \"Calculate the prime numbers between 1 and 50\",\n    \"code\": \"\",\n    \"output\": \"\",\n    \"error\": \"\",\n    \"iterations\": 0,\n    \"messages\": []\n}\n\nresult = app.invoke(initial_state)\nprint(f\"Final output: {result['output']}\")\n</code></pre>"},{"location":"integrations/#tool-based-graph","title":"Tool-Based Graph","text":"<pre><code>from langgraph.prebuilt import create_react_agent\n\n# Create code execution tool\n@tool\ndef run_python_code(code: str, libraries: List[str] = None) -&gt; str:\n    \"\"\"Run Python code with optional libraries\"\"\"\n    with SandboxSession(lang=\"python\") as session:\n        result = session.run(code, libraries=libraries)\n        return result.stdout if result.exit_code == 0 else f\"Error: {result.stderr}\"\n\n@tool\ndef run_data_analysis(\n    csv_data: str,\n    analysis_type: str = \"summary\"\n) -&gt; str:\n    \"\"\"Run data analysis on CSV data\"\"\"\n    code = f\"\"\"\nimport pandas as pd\nimport io\n\ndata = '''{csv_data}'''\ndf = pd.read_csv(io.StringIO(data))\n\nif \"{analysis_type}\" == \"summary\":\n    print(df.describe())\nelif \"{analysis_type}\" == \"correlation\":\n    print(df.corr())\nelse:\n    print(df.head())\n\"\"\"\n\n    with SandboxSession(lang=\"python\") as session:\n        result = session.run(code, libraries=[\"pandas\"])\n        return result.stdout\n\n# Create agent\ntools = [run_python_code, run_data_analysis]\nagent = create_react_agent(llm, tools)\n\n# Use agent\nresponse = agent.invoke({\n    \"messages\": [\n        (\"user\", \"Generate sample sales data and analyze it\")\n    ]\n})\n</code></pre>"},{"location":"integrations/#llamaindex-integration","title":"LlamaIndex Integration","text":""},{"location":"integrations/#function-tool-integration","title":"Function Tool Integration","text":"<pre><code>from llama_index.core.tools import FunctionTool\nfrom llama_index.core.agent import ReActAgent\nfrom llama_index.llms.openai import OpenAI\n\ndef execute_code_with_context(\n    code: str,\n    language: str = \"python\",\n    context: dict = None\n) -&gt; str:\n    \"\"\"\n    Execute code with optional context variables.\n\n    Args:\n        code: Code to execute\n        language: Programming language\n        context: Dictionary of variables to inject\n\n    Returns:\n        Execution output\n    \"\"\"\n    with SandboxSession(lang=language) as session:\n        # Inject context if provided\n        if context and language == \"python\":\n            context_code = \"\\n\".join([\n                f\"{key} = {repr(value)}\"\n                for key, value in context.items()\n            ])\n            full_code = f\"{context_code}\\n\\n{code}\"\n        else:\n            full_code = code\n\n        result = session.run(full_code)\n        return result.stdout\n\n# Create LlamaIndex tool\ncode_tool = FunctionTool.from_defaults(\n    fn=execute_code_with_context,\n    name=\"code_executor\",\n    description=\"Execute code in a sandboxed environment with optional context\"\n)\n\n# Create agent\nllm = OpenAI(model=\"gpt-4\", temperature=0)\nagent = ReActAgent.from_tools(\n    [code_tool],\n    llm=llm,\n    verbose=True\n)\n\n# Use agent\nresponse = agent.chat(\n    \"Calculate the compound interest for $10,000 at 5% annual rate over 10 years\"\n)\nprint(response)\n</code></pre>"},{"location":"integrations/#query-engine-integration","title":"Query Engine Integration","text":"<pre><code>from llama_index.core import VectorStoreIndex, Document\nfrom llama_index.core.query_engine import CustomQueryEngine\nfrom llama_index.core.response_synthesizers import BaseSynthesizer\n\nclass CodeExecutionQueryEngine(CustomQueryEngine):\n    \"\"\"Query engine that executes code to answer questions\"\"\"\n\n    def __init__(self, llm, security_policy=None):\n        self.llm = llm\n        self.security_policy = security_policy\n\n    def custom_query(self, query_str: str) -&gt; str:\n        # Generate code to answer the query\n        code_prompt = f\"\"\"\nWrite Python code to answer this question: {query_str}\n\nThe code should print the answer clearly.\n\"\"\"\n        code = self.llm.complete(code_prompt).text\n\n        # Execute code safely\n        with SandboxSession(\n            lang=\"python\",\n            security_policy=self.security_policy\n        ) as session:\n            # Check if code is safe\n            if self.security_policy:\n                is_safe, violations = session.is_safe(code)\n                if not is_safe:\n                    return f\"Code failed security check: {violations}\"\n\n            result = session.run(code)\n\n            if result.exit_code != 0:\n                return f\"Execution error: {result.stderr}\"\n\n            return result.stdout\n\n# Use the query engine\nfrom llm_sandbox.security import get_security_policy\n\nquery_engine = CodeExecutionQueryEngine(\n    llm=llm,\n    security_policy=get_security_policy(\"data_science\")\n)\n\nresponse = query_engine.query(\n    \"What is the correlation between height and weight in a generated dataset of 100 people?\"\n)\nprint(response)\n</code></pre>"},{"location":"integrations/#openai-function-calling","title":"OpenAI Function Calling","text":""},{"location":"integrations/#direct-integration","title":"Direct Integration","text":"<pre><code>import openai\nimport json\nfrom typing import List, Dict\n\ndef create_code_execution_function() -&gt; Dict:\n    \"\"\"Create OpenAI function specification for code execution\"\"\"\n    return {\n        \"name\": \"execute_code\",\n        \"description\": \"Execute code in a secure sandbox environment\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"code\": {\n                    \"type\": \"string\",\n                    \"description\": \"The code to execute\"\n                },\n                \"language\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"python\", \"javascript\", \"java\", \"cpp\", \"go\", \"ruby\"],\n                    \"description\": \"Programming language\"\n                },\n                \"libraries\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Libraries to install\"\n                }\n            },\n            \"required\": [\"code\", \"language\"]\n        }\n    }\n\ndef handle_function_call(function_call) -&gt; str:\n    \"\"\"Handle the function call from OpenAI\"\"\"\n    args = json.loads(function_call.arguments)\n\n    with SandboxSession(\n        lang=args[\"language\"],\n        verbose=False\n    ) as session:\n        result = session.run(\n            args[\"code\"],\n            libraries=args.get(\"libraries\")\n        )\n\n        return json.dumps({\n            \"stdout\": result.stdout,\n            \"stderr\": result.stderr,\n            \"exit_code\": result.exit_code\n        })\n\n# Use with OpenAI\nclient = openai.OpenAI()\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Calculate the first 10 prime numbers\"}\n]\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=messages,\n    functions=[create_code_execution_function()],\n    function_call=\"auto\"\n)\n\n# Handle function call if present\nif response.choices[0].message.function_call:\n    function_result = handle_function_call(\n        response.choices[0].message.function_call\n    )\n\n    # Add function result to conversation\n    messages.append(response.choices[0].message)\n    messages.append({\n        \"role\": \"function\",\n        \"name\": \"execute_code\",\n        \"content\": function_result\n    })\n\n    # Get final response\n    final_response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages\n    )\n\n    print(final_response.choices[0].message.content)\n</code></pre>"},{"location":"integrations/#custom-framework-integration","title":"Custom Framework Integration","text":""},{"location":"integrations/#generic-integration-pattern","title":"Generic Integration Pattern","text":"<pre><code>\"\"\"Async execution example for LLM Sandbox.\"\"\"\n\nimport asyncio\nfrom typing import Any, Protocol\n\nfrom llm_sandbox import SandboxSession\n\n\nclass CodeExecutor(Protocol):\n    \"\"\"Protocol for code execution integration.\"\"\"\n\n    def execute(\n        self, code: str, language: str = \"python\", libraries: list[str] | None = None, **kwargs: Any\n    ) -&gt; dict[str, Any]:\n        \"\"\"Execute code and return results.\"\"\"\n        ...\n\n\nclass SandboxCodeExecutor:\n    \"\"\"Sandbox implementation of CodeExecutor.\"\"\"\n\n    def __init__(self, default_security_policy: Any = None) -&gt; None:\n        \"\"\"Initialize the executor with optional security policy.\"\"\"\n        self.default_security_policy = default_security_policy\n\n    def execute(\n        self,\n        code: str,\n        language: str = \"python\",\n        libraries: list[str] | None = None,\n        security_policy: Any = None,\n        **kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Execute code in sandbox.\n\n        Returns:\n            Dictionary with stdout, stderr, exit_code, and plots\n\n        \"\"\"\n        policy = security_policy or self.default_security_policy\n\n        try:\n            with SandboxSession(lang=language, security_policy=policy, **kwargs) as session:\n                result = session.run(code, libraries)\n\n                return {\n                    \"success\": result.exit_code == 0,\n                    \"stdout\": result.stdout,\n                    \"stderr\": result.stderr,\n                    \"exit_code\": result.exit_code,\n                    \"plots\": getattr(result, \"plots\", []),\n                }\n        except Exception as e:  # noqa: BLE001\n            return {\"success\": False, \"error\": str(e), \"exit_code\": -1}\n\n    async def execute_async(self, code: str, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"Async wrapper for execution.\"\"\"\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, lambda: self.execute(code, **kwargs))\n\n\nasync def main() -&gt; None:\n    \"\"\"Demonstrate both sync and async execution.\"\"\"\n    # Use in any framework\n    executor = SandboxCodeExecutor(default_security_policy=None)\n\n    # Sync execution\n    result = executor.execute(\"print('Hello, World!')\", language=\"python\")\n    print(f\"Sync result: {result['stdout']}\")  # noqa: T201\n\n    # Async execution\n    result = await executor.execute_async(\"print('Hello, Async!')\", language=\"python\")\n    print(f\"Async result: {result['stdout']}\")  # noqa: T201\n\n\n# Run async\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"integrations/#middleware-pattern","title":"Middleware Pattern","text":"<pre><code>from typing import Callable\nimport functools\nimport time\n\nclass CodeExecutionMiddleware:\n    \"\"\"Middleware for code execution with logging, caching, etc.\"\"\"\n\n    def __init__(self):\n        self.cache = {}\n        self.execution_log = []\n\n    def with_logging(self, func: Callable) -&gt; Callable:\n        \"\"\"Log all executions\"\"\"\n        @functools.wraps(func)\n        def wrapper(code: str, **kwargs):\n            start_time = time.time()\n            result = func(code, **kwargs)\n\n            self.execution_log.append({\n                \"timestamp\": time.time(),\n                \"code\": code,\n                \"language\": kwargs.get(\"language\", \"python\"),\n                \"duration\": time.time() - start_time,\n                \"success\": result.get(\"success\", False)\n            })\n\n            return result\n        return wrapper\n\n    def with_caching(self, func: Callable) -&gt; Callable:\n        \"\"\"Cache execution results\"\"\"\n        @functools.wraps(func)\n        def wrapper(code: str, **kwargs):\n            cache_key = f\"{code}:{kwargs}\"\n\n            if cache_key in self.cache:\n                return self.cache[cache_key]\n\n            result = func(code, **kwargs)\n            self.cache[cache_key] = result\n\n            return result\n        return wrapper\n\n    def with_retry(self, max_attempts: int = 3) -&gt; Callable:\n        \"\"\"Retry on failure\"\"\"\n        def decorator(func: Callable) -&gt; Callable:\n            @functools.wraps(func)\n            def wrapper(code: str, **kwargs):\n                for attempt in range(max_attempts):\n                    result = func(code, **kwargs)\n                    if result.get(\"success\"):\n                        return result\n\n                    if attempt &lt; max_attempts - 1:\n                        time.sleep(1)  # Wait before retry\n\n                return result\n            return wrapper\n        return decorator\n\n# Apply middleware\nmiddleware = CodeExecutionMiddleware()\nexecutor = SandboxCodeExecutor()\n\n# Wrap with middleware\nexecute_with_features = middleware.with_logging(\n    middleware.with_caching(\n        middleware.with_retry(max_attempts=2)(\n            executor.execute\n        )\n    )\n)\n\n# Use enhanced executor\nresult = execute_with_features(\n    \"print('Hello with middleware!')\",\n    language=\"python\"\n)\n</code></pre>"},{"location":"integrations/#integration-best-practices","title":"Integration Best Practices","text":""},{"location":"integrations/#1-error-handling","title":"1. Error Handling","text":"<pre><code>class RobustCodeExecutor:\n    \"\"\"Robust code executor with comprehensive error handling\"\"\"\n\n    def execute_safely(self, code: str, **kwargs):\n        try:\n            # Pre-execution validation\n            if not code or not code.strip():\n                return {\"error\": \"Empty code provided\"}\n\n            # Security check\n            with SandboxSession(**kwargs) as session:\n                is_safe, violations = session.is_safe(code)\n                if not is_safe:\n                    return {\n                        \"error\": \"Security violation\",\n                        \"violations\": [\n                            v.description for v in violations\n                        ]\n                    }\n\n                # Execute\n                result = session.run(code)\n\n                # Post-execution validation\n                if result.exit_code != 0:\n                    return {\n                        \"error\": \"Execution failed\",\n                        \"stderr\": result.stderr,\n                        \"exit_code\": result.exit_code\n                    }\n\n                return {\n                    \"success\": True,\n                    \"output\": result.stdout\n                }\n\n        except TimeoutError:\n            return {\"error\": \"Execution timeout\"}\n        except MemoryError:\n            return {\"error\": \"Memory limit exceeded\"}\n        except Exception as e:\n            return {\"error\": f\"Unexpected error: {str(e)}\"}\n</code></pre>"},{"location":"integrations/#2-resource-management","title":"2. Resource Management","text":"<pre><code>from contextlib import contextmanager\nimport threading\nimport queue\n\nclass ResourceManagedExecutor:\n    \"\"\"Executor with resource management\"\"\"\n\n    def __init__(self, max_concurrent=5):\n        self.semaphore = threading.Semaphore(max_concurrent)\n        self.execution_queue = queue.Queue()\n\n    @contextmanager\n    def acquire_resources(self):\n        \"\"\"Acquire execution resources\"\"\"\n        self.semaphore.acquire()\n        try:\n            yield\n        finally:\n            self.semaphore.release()\n\n    def execute(self, code: str, **kwargs):\n        \"\"\"Execute with resource management\"\"\"\n        with self.acquire_resources():\n            # Configure resource limits\n            runtime_configs = kwargs.get(\"runtime_configs\", {})\n            runtime_configs.update({\n                \"cpu_count\": 1,\n                \"mem_limit\": \"256m\",\n            })\n            kwargs[\"runtime_configs\"] = runtime_configs\n\n            with SandboxSession(**kwargs) as session:\n                return session.run(code)\n</code></pre>"},{"location":"integrations/#3-monitoring-and-metrics","title":"3. Monitoring and Metrics","text":"<pre><code>import time\nfrom dataclasses import dataclass\nfrom typing import List\n\n@dataclass\nclass ExecutionMetrics:\n    \"\"\"Metrics for code execution\"\"\"\n    timestamp: float\n    duration: float\n    language: str\n    success: bool\n    code_length: int\n    memory_used: int = 0\n    cpu_time: float = 0.0\n\nclass MonitoredExecutor:\n    \"\"\"Executor with monitoring capabilities\"\"\"\n\n    def __init__(self):\n        self.metrics: List[ExecutionMetrics] = []\n\n    def execute_with_monitoring(self, code: str, **kwargs):\n        \"\"\"Execute code with monitoring\"\"\"\n        start_time = time.time()\n\n        try:\n            with SandboxSession(**kwargs) as session:\n                result = session.run(code)\n\n                # Collect metrics\n                metric = ExecutionMetrics(\n                    timestamp=start_time,\n                    duration=time.time() - start_time,\n                    language=kwargs.get(\"lang\", \"python\"),\n                    success=result.exit_code == 0,\n                    code_length=len(code)\n                )\n\n                self.metrics.append(metric)\n\n                return result\n\n        except Exception as e:\n            # Record failure\n            metric = ExecutionMetrics(\n                timestamp=start_time,\n                duration=time.time() - start_time,\n                language=kwargs.get(\"lang\", \"python\"),\n                success=False,\n                code_length=len(code)\n            )\n            self.metrics.append(metric)\n            raise\n\n    def get_statistics(self):\n        \"\"\"Get execution statistics\"\"\"\n        if not self.metrics:\n            return {}\n\n        success_rate = sum(\n            1 for m in self.metrics if m.success\n        ) / len(self.metrics)\n\n        avg_duration = sum(\n            m.duration for m in self.metrics\n        ) / len(self.metrics)\n\n        return {\n            \"total_executions\": len(self.metrics),\n            \"success_rate\": success_rate,\n            \"average_duration\": avg_duration,\n            \"languages\": list(set(m.language for m in self.metrics))\n        }\n</code></pre>"},{"location":"integrations/#next-steps","title":"Next Steps","text":"<ul> <li>See practical Examples</li> <li>Learn about Security Policies</li> <li>Explore Backend Options</li> <li>Read the API Reference</li> </ul>"},{"location":"languages/","title":"Supported Languages","text":"<p>LLM Sandbox supports multiple programming languages, each with specific features and configurations. This guide covers language-specific details, features, and best practices.</p>"},{"location":"languages/#overview","title":"Overview","text":"Language Version Package Manager Plot Support Default Image Python 3.11 pip \u2705 Full <code>ghcr.io/vndee/sandbox-python-311-bullseye</code> R 4.5.1 CRAN \u2705 Full <code>ghcr.io/vndee/sandbox-r-451-bullseye</code> JavaScript Node 22 npm \u274c <code>ghcr.io/vndee/sandbox-node-22-bullseye</code> Java 11 Maven \u274c <code>ghcr.io/vndee/sandbox-java-11-bullseye</code> C++ GCC 11.2 apt \u274c <code>ghcr.io/vndee/sandbox-cpp-11-bullseye</code> Go 1.23.4 go get \u274c <code>ghcr.io/vndee/sandbox-go-123-bullseye</code>"},{"location":"languages/#python","title":"Python","text":""},{"location":"languages/#overview_1","title":"Overview","text":"<p>Python is the most feature-rich language in LLM Sandbox, with full support for package management, plot extraction, and data science workflows.</p>"},{"location":"languages/#basic-usage","title":"Basic Usage","text":"<pre><code>from llm_sandbox import SandboxSession\n\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport sys\nprint(f\"Python {sys.version}\")\nprint(\"Hello from Python!\")\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#package-management","title":"Package Management","text":"<pre><code># Install packages during code execution\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")\n    \"\"\", libraries=[\"numpy\", \"pandas\", \"matplotlib\"])\n\n# Install packages separately\nwith SandboxSession(lang=\"python\") as session:\n    session.install([\"scikit-learn\", \"seaborn\"])\n    result = session.run(\"\"\"\nfrom sklearn import __version__\nprint(f\"Scikit-learn version: {__version__}\")\n    \"\"\")\n</code></pre>"},{"location":"languages/#plot-extraction","title":"Plot Extraction","text":"<p>Python supports automatic extraction of plots from matplotlib, seaborn, and plotly:</p> <pre><code>from llm_sandbox import ArtifactSandboxSession\nimport base64\n\nwith ArtifactSandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create multiple plots\nfig, axes = plt.subplots(2, 2, figsize=(10, 10))\n\n# Plot 1: Line plot\nx = np.linspace(0, 10, 100)\naxes[0, 0].plot(x, np.sin(x))\naxes[0, 0].set_title('Sine Wave')\n\n# Plot 2: Scatter plot\naxes[0, 1].scatter(np.random.rand(50), np.random.rand(50))\naxes[0, 1].set_title('Random Scatter')\n\n# Plot 3: Histogram\naxes[1, 0].hist(np.random.normal(0, 1, 1000), bins=30)\naxes[1, 0].set_title('Normal Distribution')\n\n# Plot 4: Bar plot\ncategories = ['A', 'B', 'C', 'D']\nvalues = [23, 45, 56, 78]\naxes[1, 1].bar(categories, values)\naxes[1, 1].set_title('Bar Chart')\n\nplt.tight_layout()\nplt.show()\n    \"\"\")\n\n    # Save extracted plots\n    for i, plot in enumerate(result.plots):\n        with open(f\"plot_{i}.png\", \"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre>"},{"location":"languages/#data-science-workflows","title":"Data Science Workflows","text":"<pre><code>with SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample data\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10\ny = 2.5 * X + np.random.randn(100, 1) * 2\n\n# Create DataFrame\ndf = pd.DataFrame({'X': X.flatten(), 'y': y.flatten()})\nprint(\"Data shape:\", df.shape)\nprint(\"\\nData summary:\")\nprint(df.describe())\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"\\nModel coefficients: {model.coef_[0][0]:.4f}\")\nprint(f\"Model intercept: {model.intercept_[0]:.4f}\")\nprint(f\"Mean squared error: {mse:.4f}\")\nprint(f\"R\u00b2 score: {r2:.4f}\")\n    \"\"\", libraries=[\"pandas\", \"numpy\", \"scikit-learn\"])\n\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#python-specific-features","title":"Python-Specific Features","text":""},{"location":"languages/#virtual-environment","title":"Virtual Environment","text":"<p>LLM Sandbox automatically creates a virtual environment for Python:</p> <pre><code># Virtual environment is at /tmp/venv\nwith SandboxSession(lang=\"python\") as session:\n    result = session.run(\"\"\"\nimport sys\nprint(f\"Python executable: {sys.executable}\")\nprint(f\"Python path: {sys.path[0]}\")\n    \"\"\")\n</code></pre>"},{"location":"languages/#custom-python-images","title":"Custom Python Images","text":"<pre><code># Use specific Python version\nwith SandboxSession(\n    lang=\"python\",\n    image=\"python:3.12-slim\"\n) as session:\n    pass\n\n# Use data science image\nwith SandboxSession(\n    lang=\"python\",\n    image=\"jupyter/scipy-notebook:latest\"\n) as session:\n    pass\n\n# Use custom image with pre-installed packages\nwith SandboxSession(\n    lang=\"python\",\n    dockerfile=\"./python-ds/Dockerfile\"\n) as session:\n    pass\n</code></pre>"},{"location":"languages/#r","title":"R","text":""},{"location":"languages/#overview_2","title":"Overview","text":"<p>R support includes CRAN package management and plot extraction. Comprehensive documentation is available here.</p>"},{"location":"languages/#basic-usage_1","title":"Basic Usage","text":"<pre><code>with SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nprint(\"Hello from R!\")\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#package-management_1","title":"Package Management","text":"<pre><code># Install CRAN packages\nwith SandboxSession(lang=\"r\") as session:\n    session.install([\"dplyr\", \"ggplot2\"])\n    result = session.run(\"\"\"\nlibrary(dplyr)\nlibrary(ggplot2)\n    \"\"\")\n</code></pre>"},{"location":"languages/#plot-extraction_1","title":"Plot Extraction","text":"<p>R supports automatic extraction of plots from ggplot2:</p> <pre><code>from llm_sandbox import ArtifactSandboxSession\nimport base64\n\nwith ArtifactSandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nlibrary(ggplot2)\n\n# Create a plot\np &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) +\n    geom_point() +\n    labs(title = \"Miles per Gallon vs Horsepower\", x = \"Horsepower\", y = \"Miles per Gallon\")\n\n# Save the plot as a PNG\npng(file = \"plot.png\")\nprint(p)\ndev.off()\n    \"\"\")\n\n    # Save extracted plots\n    for i, plot in enumerate(result.plots):\n        with open(f\"plot_{i}.png\", \"wb\") as f:\n            f.write(base64.b64decode(plot.content_base64))\n</code></pre>"},{"location":"languages/#data-science-workflows_1","title":"Data Science Workflows","text":""},{"location":"languages/#data-manipulation-with-tidyverse","title":"Data Manipulation with Tidyverse","text":"<pre><code>with SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nlibrary(tidyverse)\nlibrary(data.table)\n\n# Generate comprehensive dataset\nset.seed(42)\nn &lt;- 1000\n\ndata &lt;- tibble(\n    id = 1:n,\n    age = rnorm(n, mean = 35, sd = 10),\n    income = exp(rnorm(n, mean = 10.5, sd = 0.5)),\n    education = sample(c(\"High School\", \"Bachelor\", \"Master\", \"PhD\"), n, replace = TRUE),\n    performance_score = 70 + 0.3 * rnorm(n, mean = 5, sd = 2) + rnorm(n, mean = 0, sd = 5)\n)\n\nprint(\"Data Summary:\")\nprint(glimpse(data))\n\n# Advanced data manipulation\nsummary_stats &lt;- data %&gt;%\n    group_by(education) %&gt;%\n    summarise(\n        count = n(),\n        avg_age = mean(age, na.rm = TRUE),\n        avg_income = mean(income, na.rm = TRUE),\n        avg_performance = mean(performance_score, na.rm = TRUE),\n        .groups = 'drop'\n    ) %&gt;%\n    arrange(desc(avg_performance))\n\nprint(\"Performance Analysis:\")\nprint(summary_stats)\n    \"\"\", libraries=[\"tidyverse\", \"data.table\"])\n</code></pre>"},{"location":"languages/#machine-learning","title":"Machine Learning","text":"<pre><code>with SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nlibrary(caret)\nlibrary(randomForest)\nlibrary(broom)\n\n# Create dataset for modeling\nset.seed(123)\nn &lt;- 500\ndata &lt;- data.frame(\n    x1 = rnorm(n),\n    x2 = rnorm(n),\n    x3 = rnorm(n),\n    x4 = runif(n, -2, 2)\n)\ndata$y &lt;- 2 * data$x1 - 1.5 * data$x2 + 0.5 * data$x3 + rnorm(n, 0, 0.5)\n\n# Split data\ntrain_index &lt;- createDataPartition(data$y, p = 0.8, list = FALSE)\ntrain_data &lt;- data[train_index, ]\ntest_data &lt;- data[-train_index, ]\n\n# Linear Regression\nlm_model &lt;- lm(y ~ ., data = train_data)\nprint(\"Linear Regression Coefficients:\")\nprint(tidy(lm_model))\n\n# Random Forest\nrf_model &lt;- randomForest(y ~ ., data = train_data, ntree = 100)\nprint(\"Random Forest Variable Importance:\")\nprint(importance(rf_model))\n\n# Model evaluation\nlm_pred &lt;- predict(lm_model, test_data)\nrf_pred &lt;- predict(rf_model, test_data)\n\nlm_rmse &lt;- sqrt(mean((test_data$y - lm_pred)^2))\nrf_rmse &lt;- sqrt(mean((test_data$y - rf_pred)^2))\n\nprint(paste(\"Linear Regression RMSE:\", round(lm_rmse, 4)))\nprint(paste(\"Random Forest RMSE:\", round(rf_rmse, 4)))\n    \"\"\", libraries=[\"caret\", \"randomForest\", \"broom\"])\n</code></pre>"},{"location":"languages/#time-series-analysis","title":"Time Series Analysis","text":"<pre><code>with SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nlibrary(forecast)\nlibrary(zoo)\n\n# Create synthetic time series\nset.seed(42)\nn &lt;- 200\ntrend &lt;- seq(100, 150, length.out = n)\nseasonal &lt;- 10 * sin(2 * pi * (1:n) / 12)\nnoise &lt;- rnorm(n, 0, 3)\nvalues &lt;- trend + seasonal + noise\n\n# Convert to time series object\nts_data &lt;- ts(values, frequency = 12, start = c(2020, 1))\n\nprint(\"Time Series Summary:\")\nprint(summary(ts_data))\n\n# Fit ARIMA model\narima_model &lt;- auto.arima(ts_data)\nprint(\"ARIMA Model:\")\nprint(arima_model)\n\n# Generate forecasts\nforecast_result &lt;- forecast(arima_model, h = 12)\nprint(\"12-Period Forecast:\")\nprint(as.data.frame(forecast_result))\n    \"\"\", libraries=[\"forecast\", \"zoo\"])\n</code></pre>"},{"location":"languages/#advanced-plotting","title":"Advanced Plotting","text":""},{"location":"languages/#ggplot2-visualizations","title":"ggplot2 Visualizations","text":"<pre><code>with ArtifactSandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Generate sample data\nset.seed(42)\ndata &lt;- data.frame(\n    x = rnorm(1000, 50, 15),\n    y = rnorm(1000, 30, 10),\n    category = sample(c(\"A\", \"B\", \"C\", \"D\"), 1000, replace = TRUE),\n    size_var = runif(1000, 1, 5)\n)\n\n# Advanced scatter plot\np1 &lt;- ggplot(data, aes(x = x, y = y, color = category, size = size_var)) +\n    geom_point(alpha = 0.7) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n    scale_color_brewer(type = \"qual\", palette = \"Set2\") +\n    scale_size_continuous(range = c(1, 4)) +\n    labs(title = \"Advanced Scatter Plot with Multiple Aesthetics\",\n         subtitle = \"Color by category, size by continuous variable\") +\n    theme_minimal()\n\nprint(p1)\n\n# Violin plot with statistics\np2 &lt;- data %&gt;%\n    ggplot(aes(x = category, y = x)) +\n    geom_violin(aes(fill = category), alpha = 0.7) +\n    geom_boxplot(width = 0.2, fill = \"white\", outlier.shape = NA) +\n    geom_jitter(width = 0.1, alpha = 0.3, size = 0.8) +\n    stat_summary(fun = mean, geom = \"point\", shape = 23,\n                 size = 3, fill = \"red\", color = \"darkred\") +\n    labs(title = \"Distribution Analysis: Violin + Box + Jitter\") +\n    theme_minimal()\n\nprint(p2)\n\n# Base R plots for comparison\nplot(data$x, data$y,\n     col = rainbow(4)[as.factor(data$category)],\n     pch = 19, cex = 0.8,\n     main = \"Base R: Scatter Plot with Colors\",\n     xlab = \"X Variable\", ylab = \"Y Variable\")\nlegend(\"topright\", legend = levels(as.factor(data$category)),\n       col = rainbow(4), pch = 19, title = \"Category\")\n    \"\"\", libraries=[\"ggplot2\", \"dplyr\", \"gridExtra\"])\n</code></pre>"},{"location":"languages/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>with SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\n# Generate sample data\nset.seed(42)\ngroup1 &lt;- rnorm(50, mean = 100, sd = 15)\ngroup2 &lt;- rnorm(50, mean = 110, sd = 12)\n\n# Descriptive statistics\nprint(\"Group 1 Statistics:\")\nprint(summary(group1))\nprint(\"Group 2 Statistics:\")\nprint(summary(group2))\n\n# Statistical tests\nt_test_result &lt;- t.test(group1, group2)\nprint(\"T-test Results:\")\nprint(t_test_result)\n\n# Correlation analysis\ndata &lt;- data.frame(x = group1, y = group1 + rnorm(50, 0, 5))\ncorrelation &lt;- cor.test(data$x, data$y)\nprint(\"Correlation Test:\")\nprint(correlation)\n\n# ANOVA\ndata$group &lt;- rep(c(\"A\", \"B\"), each = 25)\nanova_result &lt;- aov(x ~ group, data = data)\nprint(\"ANOVA Results:\")\nprint(summary(anova_result))\n    \"\"\")\n</code></pre>"},{"location":"languages/#r-specific-features","title":"R-Specific Features","text":""},{"location":"languages/#cran-package-management","title":"CRAN Package Management","text":"<pre><code># Install from specific CRAN mirror\nwith SandboxSession(lang=\"r\") as session:\n    result = session.run(\"\"\"\n# Install from CRAN\ninstall.packages(\"lubridate\", repos = \"https://cran.rstudio.com/\")\nlibrary(lubridate)\n\n# Work with dates\ntoday_date &lt;- today()\nprint(paste(\"Today is:\", today_date))\nprint(paste(\"Year:\", year(today_date)))\nprint(paste(\"Month:\", month(today_date, label = TRUE)))\n    \"\"\")\n</code></pre>"},{"location":"languages/#javascript-nodejs","title":"JavaScript (Node.js)","text":""},{"location":"languages/#overview_3","title":"Overview","text":"<p>JavaScript support includes Node.js runtime with npm package management.</p>"},{"location":"languages/#basic-usage_2","title":"Basic Usage","text":"<pre><code>with SandboxSession(lang=\"javascript\") as session:\n    result = session.run(\"\"\"\nconsole.log(`Node.js ${process.version}`);\nconsole.log('Hello from JavaScript!');\n\n// Modern JavaScript features\nconst greeting = (name) =&gt; `Hello, ${name}!`;\nconsole.log(greeting('World'));\n\n// Async/await support\nconst delay = (ms) =&gt; new Promise(resolve =&gt; setTimeout(resolve, ms));\n\n(async () =&gt; {\n    console.log('Starting...');\n    await delay(100);\n    console.log('Finished!');\n})();\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#package-management_2","title":"Package Management","text":"<pre><code># Install npm packages\nwith SandboxSession(lang=\"javascript\") as session:\n    result = session.run(\"\"\"\nconst axios = require('axios');\nconst lodash = require('lodash');\n\nconsole.log('Packages loaded successfully!');\n\n// Use lodash\nconst numbers = [1, 2, 3, 4, 5];\nconsole.log('Sum:', lodash.sum(numbers));\nconsole.log('Mean:', lodash.mean(numbers));\n    \"\"\", libraries=[\"axios\", \"lodash\"])\n</code></pre>"},{"location":"languages/#working-with-apis","title":"Working with APIs","text":"<pre><code>with SandboxSession(lang=\"javascript\") as session:\n    result = session.run(\"\"\"\nconst https = require('https');\n\n// Make API request\nhttps.get('https://api.github.com/users/github', (res) =&gt; {\n    let data = '';\n\n    res.on('data', (chunk) =&gt; {\n        data += chunk;\n    });\n\n    res.on('end', () =&gt; {\n        const user = JSON.parse(data);\n        console.log('GitHub user:', user.name);\n        console.log('Public repos:', user.public_repos);\n    });\n}).on('error', (err) =&gt; {\n    console.error('Error:', err.message);\n});\n    \"\"\")\n</code></pre>"},{"location":"languages/#expressjs-server","title":"Express.js Server","text":"<pre><code>with SandboxSession(lang=\"javascript\") as session:\n    result = session.run(\"\"\"\nconst express = require('express');\nconst app = express();\n\napp.get('/', (req, res) =&gt; {\n    res.json({ message: 'Hello from Express!' });\n});\n\n// Note: Server won't actually be accessible from outside the container\nconst PORT = 3000;\napp.listen(PORT, () =&gt; {\n    console.log(`Server would run on port ${PORT}`);\n    console.log('(Not accessible from outside the sandbox)');\n\n    // Gracefully exit after setup\n    process.exit(0);\n});\n    \"\"\", libraries=[\"express\"])\n</code></pre>"},{"location":"languages/#java","title":"Java","text":""},{"location":"languages/#overview_4","title":"Overview","text":"<p>Java support includes JDK 11 with automatic compilation and execution.</p>"},{"location":"languages/#basic-usage_3","title":"Basic Usage","text":"<pre><code>with SandboxSession(lang=\"java\") as session:\n    result = session.run(\"\"\"\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println(\"Java version: \" + System.getProperty(\"java.version\"));\n        System.out.println(\"Hello from Java!\");\n\n        // Modern Java features\n        var message = \"Using var keyword!\";\n        System.out.println(message);\n    }\n}\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#object-oriented-programming","title":"Object-Oriented Programming","text":"<pre><code>with SandboxSession(lang=\"java\") as session:\n    result = session.run(\"\"\"\nimport java.util.*;\n\nclass Person {\n    private String name;\n    private int age;\n\n    public Person(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String toString() {\n        return String.format(\"Person{name='%s', age=%d}\", name, age);\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        List&lt;Person&gt; people = Arrays.asList(\n            new Person(\"Alice\", 30),\n            new Person(\"Bob\", 25),\n            new Person(\"Charlie\", 35)\n        );\n\n        System.out.println(\"People list:\");\n        people.forEach(System.out::println);\n\n        // Stream API\n        double avgAge = people.stream()\n            .mapToInt(p -&gt; p.age)\n            .average()\n            .orElse(0);\n\n        System.out.printf(\"Average age: %.1f%n\", avgAge);\n    }\n}\n    \"\"\")\n</code></pre>"},{"location":"languages/#working-with-collections","title":"Working with Collections","text":"<pre><code>with SandboxSession(lang=\"java\") as session:\n    result = session.run(\"\"\"\nimport java.util.*;\nimport java.util.stream.Collectors;\n\npublic class CollectionsDemo {\n    public static void main(String[] args) {\n        // List operations\n        List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;(Arrays.asList(5, 2, 8, 1, 9, 3));\n        System.out.println(\"Original: \" + numbers);\n\n        Collections.sort(numbers);\n        System.out.println(\"Sorted: \" + numbers);\n\n        // Map operations\n        Map&lt;String, Integer&gt; scores = new HashMap&lt;&gt;();\n        scores.put(\"Alice\", 95);\n        scores.put(\"Bob\", 87);\n        scores.put(\"Charlie\", 92);\n\n        System.out.println(\"\\nScores:\");\n        scores.forEach((name, score) -&gt;\n            System.out.printf(\"%s: %d%n\", name, score)\n        );\n\n        // Stream operations\n        List&lt;Integer&gt; filtered = numbers.stream()\n            .filter(n -&gt; n &gt; 5)\n            .map(n -&gt; n * 2)\n            .collect(Collectors.toList());\n\n        System.out.println(\"\\nFiltered and doubled: \" + filtered);\n    }\n}\n    \"\"\")\n</code></pre>"},{"location":"languages/#c","title":"C++","text":""},{"location":"languages/#overview_5","title":"Overview","text":"<p>C++ support includes GCC compiler with C++17 standard.</p>"},{"location":"languages/#basic-usage_4","title":"Basic Usage","text":"<pre><code>with SandboxSession(lang=\"cpp\") as session:\n    result = session.run(\"\"\"\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::cout &lt;&lt; \"C++ Standard: \" &lt;&lt; __cplusplus &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Hello from C++!\" &lt;&lt; std::endl;\n\n    // Modern C++ features\n    auto message = std::string(\"Using auto keyword!\");\n    std::cout &lt;&lt; message &lt;&lt; std::endl;\n\n    // Range-based for loop\n    std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};\n    std::cout &lt;&lt; \"Numbers: \";\n    for (const auto&amp; n : numbers) {\n        std::cout &lt;&lt; n &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#stl-and-algorithms","title":"STL and Algorithms","text":"<pre><code>with SandboxSession(lang=\"cpp\") as session:\n    result = session.run(\"\"\"\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;numeric&gt;\n#include &lt;map&gt;\n\nint main() {\n    // Vector operations\n    std::vector&lt;int&gt; vec = {5, 2, 8, 1, 9, 3};\n    std::cout &lt;&lt; \"Original: \";\n    for (int n : vec) std::cout &lt;&lt; n &lt;&lt; \" \";\n    std::cout &lt;&lt; std::endl;\n\n    // Sort\n    std::sort(vec.begin(), vec.end());\n    std::cout &lt;&lt; \"Sorted: \";\n    for (int n : vec) std::cout &lt;&lt; n &lt;&lt; \" \";\n    std::cout &lt;&lt; std::endl;\n\n    // Algorithms\n    int sum = std::accumulate(vec.begin(), vec.end(), 0);\n    std::cout &lt;&lt; \"Sum: \" &lt;&lt; sum &lt;&lt; std::endl;\n\n    // Map\n    std::map&lt;std::string, int&gt; scores = {\n        {\"Alice\", 95},\n        {\"Bob\", 87},\n        {\"Charlie\", 92}\n    };\n\n    std::cout &lt;&lt; \"\\nScores:\\n\";\n    for (const auto&amp; [name, score] : scores) {\n        std::cout &lt;&lt; name &lt;&lt; \": \" &lt;&lt; score &lt;&lt; std::endl;\n    }\n\n    return 0;\n}\n    \"\"\")\n</code></pre>"},{"location":"languages/#installing-libraries","title":"Installing Libraries","text":"<pre><code># Install system libraries\nwith SandboxSession(lang=\"cpp\") as session:\n    # Install Boost\n    session.run(\"\"\"\n#include &lt;iostream&gt;\n#include &lt;boost/algorithm/string.hpp&gt;\n\nint main() {\n    std::string text = \"Hello, World!\";\n    boost::to_upper(text);\n    std::cout &lt;&lt; text &lt;&lt; std::endl;\n    return 0;\n}\n    \"\"\", libraries=[\"libboost-all-dev\"])\n</code></pre>"},{"location":"languages/#go","title":"Go","text":""},{"location":"languages/#overview_6","title":"Overview","text":"<p>Go support includes the Go compiler and module management.</p>"},{"location":"languages/#basic-usage_5","title":"Basic Usage","text":"<pre><code>with SandboxSession(lang=\"go\") as session:\n    result = session.run(\"\"\"\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n)\n\nfunc main() {\n    fmt.Printf(\"Go version: %s\\n\", runtime.Version())\n    fmt.Println(\"Hello from Go!\")\n\n    // Go features\n    numbers := []int{1, 2, 3, 4, 5}\n    sum := 0\n    for _, n := range numbers {\n        sum += n\n    }\n    fmt.Printf(\"Sum: %d\\n\", sum)\n}\n    \"\"\")\n    print(result.stdout)\n</code></pre>"},{"location":"languages/#concurrency","title":"Concurrency","text":"<pre><code>with SandboxSession(lang=\"go\") as session:\n    result = session.run(\"\"\"\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc worker(id int, wg *sync.WaitGroup) {\n    defer wg.Done()\n    fmt.Printf(\"Worker %d starting\\n\", id)\n    time.Sleep(time.Millisecond * 100)\n    fmt.Printf(\"Worker %d done\\n\", id)\n}\n\nfunc main() {\n    var wg sync.WaitGroup\n\n    for i := 1; i &lt;= 5; i++ {\n        wg.Add(1)\n        go worker(i, &amp;wg)\n    }\n\n    wg.Wait()\n    fmt.Println(\"All workers completed\")\n}\n    \"\"\")\n</code></pre>"},{"location":"languages/#using-external-packages","title":"Using External Packages","text":"<pre><code>with SandboxSession(lang=\"go\") as session:\n    result = session.run(\"\"\"\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/spyzhov/ajson\"\n)\n\nfunc main() {\n    json := []byte(`{\n        \"name\": \"John\",\n        \"age\": 30,\n        \"city\": \"New York\"\n    }`)\n\n    root, _ := ajson.Unmarshal(json)\n\n    name, _ := root.GetString(\"name\")\n    age, _ := root.GetInt(\"age\")\n\n    fmt.Printf(\"Name: %s\\n\", name)\n    fmt.Printf(\"Age: %d\\n\", age)\n}\n    \"\"\", libraries=[\"github.com/spyzhov/ajson\"])\n</code></pre>"},{"location":"languages/#language-handler-architecture","title":"Language Handler Architecture","text":""},{"location":"languages/#custom-language-support","title":"Custom Language Support","text":"<p>You can add support for additional languages:</p> <pre><code>from llm_sandbox.language_handlers import AbstractLanguageHandler\nfrom llm_sandbox.language_handlers.factory import LanguageHandlerFactory\n\nclass RustHandler(AbstractLanguageHandler):\n    def __init__(self, logger=None):\n        super().__init__(logger)\n        self.config = LanguageConfig(\n            name=\"rust\",\n            file_extension=\"rs\",\n            execution_commands=[\"rustc {file} -o /tmp/program &amp;&amp; /tmp/program\"],\n            package_manager=\"cargo add\",\n            is_support_library_installation=True\n        )\n\n    def get_import_patterns(self, module):\n        return rf\"use\\s+{module}\"\n\n    @staticmethod\n    def get_multiline_comment_patterns():\n        return r\"/\\*[\\s\\S]*?\\*/\"\n\n    @staticmethod\n    def get_inline_comment_patterns():\n        return r\"//.*$\"\n\n# Register the handler\nLanguageHandlerFactory.register_handler(\"rust\", RustHandler)\n\n# Use it\nwith SandboxSession(lang=\"rust\", image=\"rust:latest\") as session:\n    result = session.run(\"\"\"\nfn main() {\n    println!(\"Hello from Rust!\");\n}\n    \"\"\")\n</code></pre>"},{"location":"languages/#language-detection","title":"Language Detection","text":"<pre><code>def detect_language(code: str) -&gt; str:\n    \"\"\"Simple language detection based on syntax\"\"\"\n    patterns = {\n        'python': [r'def\\s+\\w+\\s*\\(', r'import\\s+\\w+', r'print\\s*\\('],\n        'javascript': [r'function\\s+\\w+\\s*\\(', r'const\\s+\\w+\\s*=', r'console\\.log'],\n        'java': [r'public\\s+class', r'public\\s+static\\s+void\\s+main'],\n        'cpp': [r'#include\\s*&lt;', r'int\\s+main\\s*\\(', r'std::'],\n        'go': [r'package\\s+main', r'func\\s+main\\s*\\('],\n        'ruby': [r'def\\s+\\w+', r'puts\\s+', r'class\\s+\\w+'],\n    }\n\n    for lang, lang_patterns in patterns.items():\n        if any(re.search(pattern, code) for pattern in lang_patterns):\n            return lang\n\n    return 'python'  # Default\n\n# Use detected language\ncode = \"def hello():\\n    print('Hello')\\n\"\nlang = detect_language(code)\n\nwith SandboxSession(lang=lang) as session:\n    result = session.run(code)\n</code></pre>"},{"location":"languages/#optimization-tips","title":"Optimization Tips","text":"<ol> <li> <p>Pre-built Images <pre><code># Build image with pre-installed packages\nFROM python:3.11\nRUN pip install numpy pandas matplotlib scikit-learn\n</code></pre></p> </li> <li> <p>Keep Templates <pre><code># Reuse containers for faster execution\nwith SandboxSession(keep_template=True) as session:\n    pass\n</code></pre></p> </li> <li> <p>Language-Specific Optimizations <pre><code># Python: Use slim images\nimage=\"python:3.11-slim\"\n\n# Java: Use JDK vs JRE based on needs\nimage=\"openjdk:11-jre-slim\"  # For running only\n\n# Go: Use multi-stage builds\n# Build in one stage, run in minimal image\n</code></pre></p> </li> </ol>"},{"location":"languages/#next-steps","title":"Next Steps","text":"<ul> <li>Explore LLM Integrations</li> <li>Learn about Security Policies</li> <li>See practical Examples</li> <li>Read the API Reference</li> </ul>"},{"location":"mcp-integration/","title":"Model Context Protocol (MCP) Integration","text":"<p>LLM Sandbox provides a Model Context Protocol (MCP) server that enables AI assistants like Claude Desktop to execute code securely in sandboxed environments. This integration allows LLMs to run code directly with automatic visualization capture and multi-language support.</p>"},{"location":"mcp-integration/#features","title":"Features","text":"<ul> <li>Secure Code Execution: Execute code in isolated containers with your preferred backend</li> <li>Multi-Language Support: Run Python, JavaScript, Java, C++, Go, R, and Ruby code</li> <li>Automatic Visualization Capture: Automatically capture and return plots and visualizations</li> <li>Library Management: Install packages and dependencies on-the-fly</li> <li>Flexible Backend Support: Choose from Docker, Podman, or Kubernetes backends</li> </ul>"},{"location":"mcp-integration/#installation","title":"Installation","text":"<p>Install LLM Sandbox with MCP support using your preferred backend:</p> <pre><code># For Docker backend\npip install 'llm-sandbox[mcp-docker]'\n\n# For Podman backend\npip install 'llm-sandbox[mcp-podman]'\n\n# For Kubernetes backend\npip install 'llm-sandbox[mcp-k8s]'\n</code></pre>"},{"location":"mcp-integration/#configuration","title":"Configuration","text":"<p>Add the following configuration to your MCP client (e.g., <code>claude_desktop_config.json</code> for Claude Desktop):</p> <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n    }\n  }\n}\n</code></pre>"},{"location":"mcp-integration/#backend-specific-configuration","title":"Backend-Specific Configuration","text":"<p>For specific backends, set the <code>BACKEND</code> environment variable:</p> <p>Docker (default): <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"docker\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Podman: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"podman\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Kubernetes: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"kubernetes\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Kubernetes with Custom Namespace: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"kubernetes\",\n        \"NAMESPACE\": \"llm-sandbox\"\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"mcp-integration/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter connection issues with your backend, you may need to specify additional environment variables:</p> <p>Docker Connection Issues: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"docker\",\n        \"DOCKER_HOST\": \"unix:///var/run/docker.sock\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Podman Connection Issues: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"podman\",\n        \"DOCKER_HOST\": \"unix:///var/run/podman/podman.sock\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Kubernetes Connection Issues: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"kubernetes\",\n        \"KUBECONFIG\": \"/path/to/your/kubeconfig\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Common Environment Variables:</p> <ul> <li><code>DOCKER_HOST</code>: Specify the Docker daemon socket (default: <code>unix:///var/run/docker.sock</code>)</li> <li><code>KUBECONFIG</code>: Path to your Kubernetes configuration file</li> <li><code>BACKEND</code>: Choose your container backend (<code>docker</code>, <code>podman</code>, or <code>kubernetes</code>)</li> <li><code>COMMIT_CONTAINER</code>: Control whether container changes are saved to the image (default: <code>true</code>)</li> <li><code>KEEP_TEMPLATE</code>: Control whether template containers are preserved (default: <code>true</code>)</li> <li><code>NAMESPACE</code>: Specify Kubernetes namespace for pod creation (default: <code>default</code>)</li> </ul>"},{"location":"mcp-integration/#container-behavior-control","title":"Container Behavior Control","text":"<p>The MCP server provides fine-grained control over container behavior through environment variables:</p> <p>Prevent Container Image Changes: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"docker\",\n        \"COMMIT_CONTAINER\": \"false\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Prevent Template Container Preservation: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"docker\",\n        \"KEEP_TEMPLATE\": \"false\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Both Settings for Minimal Container Footprint: <pre><code>{\n  \"mcpServers\": {\n    \"llm-sandbox\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"llm_sandbox.mcp_server.server\"],\n      \"env\": {\n        \"BACKEND\": \"docker\",\n        \"COMMIT_CONTAINER\": \"false\",\n        \"KEEP_TEMPLATE\": \"false\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Environment Variable Values: Both <code>COMMIT_CONTAINER</code> and <code>KEEP_TEMPLATE</code> accept: - <code>\"true\"</code>, <code>\"1\"</code>, <code>\"yes\"</code>, <code>\"on\"</code> \u2192 <code>True</code> - <code>\"false\"</code>, <code>\"0\"</code>, <code>\"no\"</code>, <code>\"off\"</code> \u2192 <code>False</code></p> <p>Use Cases: - <code>COMMIT_CONTAINER=false</code>: Prevent Docker images from growing over time, useful in CI/CD or automated environments - <code>KEEP_TEMPLATE=false</code>: Clean up template containers automatically, reduces Docker container clutter - <code>NAMESPACE=\"custom-namespace\"</code>: Organize Kubernetes pods in specific namespaces for multi-tenant environments - Both disabled: Minimal resource usage, ideal for ephemeral environments</p>"},{"location":"mcp-integration/#available-tools","title":"Available Tools","text":"<p>The MCP server provides the following tools:</p>"},{"location":"mcp-integration/#execute_code","title":"execute_code","text":"<p>Execute code in a secure sandbox environment with automatic visualization capture.</p> <p>Parameters:</p> <ul> <li><code>code</code> (string): The code to execute</li> <li><code>language</code> (string): Programming language (python, javascript, java, cpp, go, r, ruby)</li> <li><code>libraries</code> (array, optional): List of libraries/packages to install</li> <li><code>timeout</code> (integer, optional): Execution timeout in seconds (default: 30)</li> </ul> <p>Returns: List of content items including execution results and any generated visualizations.</p>"},{"location":"mcp-integration/#get_supported_languages","title":"get_supported_languages","text":"<p>Get the list of supported programming languages.</p> <p>Returns: JSON array of supported language names.</p>"},{"location":"mcp-integration/#get_language_details","title":"get_language_details","text":"<p>Get detailed information about a specific programming language.</p> <p>Parameters:</p> <ul> <li><code>language</code> (string): The language to get details for</li> </ul> <p>Returns: JSON object with language details including version, package manager, examples, and capabilities.</p>"},{"location":"mcp-integration/#available-resources","title":"Available Resources","text":""},{"location":"mcp-integration/#language_details","title":"language_details","text":"<p>Resource endpoint <code>sandbox://languages</code> that provides comprehensive information about all supported languages including their capabilities, examples, and configuration options.</p>"},{"location":"mcp-integration/#usage-examples","title":"Usage Examples","text":"<p>Once configured, you can ask your AI assistant to run code, and it will automatically use the LLM Sandbox MCP server:</p>"},{"location":"mcp-integration/#basic-code-execution","title":"Basic Code Execution","text":"<pre><code>\"Write a Python function to calculate the factorial of a number and test it with n=5\"\n</code></pre>"},{"location":"mcp-integration/#data-visualization","title":"Data Visualization","text":"<pre><code>\"Create a scatter plot showing the relationship between x and y data points using matplotlib\"\n</code></pre>"},{"location":"mcp-integration/#multi-language-support","title":"Multi-Language Support","text":"<pre><code>\"Write a JavaScript function to sort an array of numbers and demonstrate it\"\n</code></pre> <p>The assistant will execute the code in a secure sandbox and automatically capture any generated plots or visualizations.</p>"},{"location":"mcp-integration/#development-and-testing","title":"Development and Testing","text":"<p>For development and testing of the MCP server:</p> <pre><code># Install in development mode\npip install -e '.[mcp-docker]'\n\n# Run the MCP server directly\npython -m llm_sandbox.mcp_server.server\n\n# Test with MCP client tools\n# Follow MCP client documentation for testing\n</code></pre>"},{"location":"security/","title":"Security Guide","text":"<p>LLM Sandbox provides comprehensive security features to safely execute untrusted code. This guide covers the security policy system for pre-execution code analysis and best practices.</p>"},{"location":"security/#overview","title":"Overview","text":"<p>Security in LLM Sandbox is implemented through multiple layers:</p> <ol> <li>Container Isolation - Code runs in isolated containers (configured via <code>runtime_config</code> or pod manifests)</li> <li>Security Policies - Pre-execution regex-based code analysis (this module's focus)</li> <li>Resource Limits - Prevent resource exhaustion (configured via container runtime)</li> <li>Network Controls - Limit network access (configured via container runtime)</li> <li>File System Restrictions - Control file access (configured via container runtime)</li> </ol> <p>Note: Container-level security (resource limits, network controls, file system restrictions) is configured through <code>runtime_config</code> for Docker/Podman or pod manifests for Kubernetes as described in the Configuration Guide. This module focuses on the Security Policy system for code analysis.</p>"},{"location":"security/#security-policy-system","title":"Security Policy System","text":""},{"location":"security/#overview_1","title":"Overview","text":"<p>The security policy system analyzes code before execution using regex pattern matching to detect potentially dangerous operations. It provides:</p> <ul> <li>Pattern-based detection of dangerous code constructs</li> <li>Language-specific module restriction based on import statements</li> <li>Severity-based filtering with configurable thresholds</li> <li>Comment filtering to avoid false positives from documentation</li> </ul>"},{"location":"security/#understanding-security-policies","title":"Understanding Security Policies","text":"<pre><code>from llm_sandbox.security import (\n    SecurityPolicy,\n    SecurityPattern,\n    RestrictedModule,\n    SecurityIssueSeverity\n)\n\n# Create a basic security policy\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[\n        SecurityPattern(\n            pattern=r\"os\\.system\\s*\\(\",\n            description=\"System command execution\",\n            severity=SecurityIssueSeverity.HIGH\n        )\n    ],\n    restricted_modules=[\n        RestrictedModule(\n            name=\"os\",\n            description=\"Operating system interface\",\n            severity=SecurityIssueSeverity.HIGH\n        )\n    ]\n)\n</code></pre>"},{"location":"security/#severity-levels","title":"Severity Levels","text":"<p>Security issues are classified by severity with configurable blocking thresholds:</p> Level Value Description Example Use Case <code>SAFE</code> 0 No security concerns Allow everything <code>LOW</code> 1 Minor concerns Development environments <code>MEDIUM</code> 2 Moderate risk Production with controlled access <code>HIGH</code> 3 High risk Strict security requirements <p>Threshold Behavior: Setting <code>severity_threshold=SecurityIssueSeverity.MEDIUM</code> will block MEDIUM, HIGH violations but allow LOW, SAFE patterns.</p>"},{"location":"security/#security-patterns","title":"Security Patterns","text":"<p>Define regex patterns to detect dangerous code constructs:</p> <pre><code># System command execution\nSecurityPattern(\n    pattern=r\"\\bos\\.system\\s*\\(\",\n    description=\"System command execution\",\n    severity=SecurityIssueSeverity.HIGH\n)\n\n# Dynamic code evaluation\nSecurityPattern(\n    pattern=r\"\\beval\\s*\\(\",\n    description=\"Dynamic code evaluation\",\n    severity=SecurityIssueSeverity.MEDIUM\n)\n\n# File write operations\nSecurityPattern(\n    pattern=r\"\\bopen\\s*\\([^)]*['\\\"][wa]['\\\"][^)]*\\)\",\n    description=\"File write operations\",\n    severity=SecurityIssueSeverity.MEDIUM\n)\n\n# Network socket creation\nSecurityPattern(\n    pattern=r\"\\bsocket\\.socket\\s*\\(\",\n    description=\"Raw socket creation\",\n    severity=SecurityIssueSeverity.MEDIUM\n)\n</code></pre>"},{"location":"security/#restricted-modules","title":"Restricted Modules","text":"<p>Block dangerous modules using language-specific detection. Simply specify the module name - the language handler automatically generates appropriate patterns to detect various import styles:</p> <pre><code># Block dangerous system access modules\nRestrictedModule(\n    name=\"os\",\n    description=\"Operating system interface\",\n    severity=SecurityIssueSeverity.HIGH\n)\n\nRestrictedModule(\n    name=\"subprocess\",\n    description=\"Process execution\",\n    severity=SecurityIssueSeverity.HIGH\n)\n\n# Block networking modules\nRestrictedModule(\n    name=\"socket\",\n    description=\"Network operations\",\n    severity=SecurityIssueSeverity.MEDIUM\n)\n\nRestrictedModule(\n    name=\"requests\",\n    description=\"HTTP library\",\n    severity=SecurityIssueSeverity.MEDIUM\n)\n</code></pre> <p>How Language-Specific Detection Works:</p> <p>When you specify a restricted module like <code>\"os\"</code>, the language handler automatically generates patterns to detect:</p> <p>For Python:</p> <ul> <li><code>import os</code></li> <li><code>import os as operating_system</code></li> <li><code>from os import system</code></li> <li><code>from os import system, environ</code></li> <li><code>from os import system as sys_call</code></li> </ul> <p>For JavaScript:</p> <ul> <li><code>import os from 'os'</code></li> <li><code>const os = require('os')</code></li> <li><code>import { exec } from 'child_process'</code></li> </ul> <p>For Other Languages: Each language handler implements its own import detection patterns appropriate for that language's syntax.</p>"},{"location":"security/#creating-security-policies","title":"Creating Security Policies","text":""},{"location":"security/#basic-usage","title":"Basic Usage","text":"<pre><code>from llm_sandbox import SandboxSession\nfrom llm_sandbox.security import SecurityPolicy, RestrictedModule, SecurityIssueSeverity\n\n# Create a simple policy\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    restricted_modules=[\n        RestrictedModule(\n            name=\"os\",\n            description=\"Operating system interface\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        RestrictedModule(\n            name=\"subprocess\",\n            description=\"Process execution\",\n            severity=SecurityIssueSeverity.HIGH\n        )\n    ]\n)\n\nwith SandboxSession(lang=\"python\", security_policy=policy) as session:\n    # Check if code is safe before execution\n    code = \"import os\\nos.system('ls')\"\n    is_safe, violations = session.is_safe(code)\n\n    if is_safe:\n        result = session.run(code)\n        print(result.stdout)\n    else:\n        print(\"Code failed security check:\")\n        for violation in violations:\n            print(f\"  - {violation.description} (Severity: {violation.severity.name})\")\n</code></pre>"},{"location":"security/#custom-security-policies","title":"Custom Security Policies","text":"<pre><code># Create comprehensive custom policy\ncustom_policy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[\n        # Block cloud SDKs\n        SecurityPattern(\n            pattern=r\"\\b(boto3|google\\.cloud|azure)\\b\",\n            description=\"Cloud SDK usage\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        # Block specific domains\n        SecurityPattern(\n            pattern=r\"requests\\.(get|post)\\s*\\(['\\\"].*internal\\.company\\.com\",\n            description=\"Internal network access\",\n            severity=SecurityIssueSeverity.HIGH\n        ),\n        # Monitor external APIs\n        SecurityPattern(\n            pattern=r\"requests\\.(get|post)\\s*\\(\",\n            description=\"External API call\",\n            severity=SecurityIssueSeverity.LOW\n        )\n    ],\n    restricted_modules=[\n        RestrictedModule(\n            name=\"psutil\",\n            description=\"System monitoring\",\n            severity=SecurityIssueSeverity.MEDIUM\n        ),\n        RestrictedModule(\n            name=\"ctypes\",\n            description=\"Foreign function library\",\n            severity=SecurityIssueSeverity.HIGH\n        )\n    ]\n)\n</code></pre>"},{"location":"security/#dynamic-policy-modification","title":"Dynamic Policy Modification","text":"<pre><code># Start with base policy and customize\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    patterns=[],\n    restricted_modules=[]\n)\n\n# Add custom patterns\npolicy.add_pattern(SecurityPattern(\n    pattern=r\"\\b(tensorflow|torch|keras)\\b\",\n    description=\"ML framework usage\",\n    severity=SecurityIssueSeverity.LOW\n))\n\n# Add restricted modules (language handler will generate detection patterns)\npolicy.add_restricted_module(RestrictedModule(\n    name=\"cryptography\",\n    description=\"Cryptographic operations\",\n    severity=SecurityIssueSeverity.MEDIUM\n))\n</code></pre>"},{"location":"security/#language-specific-examples","title":"Language-Specific Examples","text":""},{"location":"security/#python-security-patterns","title":"Python Security Patterns","text":"<pre><code># Python-specific dangerous patterns\npython_patterns = [\n    # Dynamic imports\n    SecurityPattern(r\"\\b__import__\\s*\\(\", \"Dynamic imports\", SecurityIssueSeverity.MEDIUM),\n\n    # Attribute manipulation\n    SecurityPattern(r\"\\b(getattr|setattr|delattr)\\s*\\(\", \"Dynamic attributes\", SecurityIssueSeverity.LOW),\n\n    # Pickle operations (deserialization risk)\n    SecurityPattern(r\"\\bpickle\\.(loads?|load)\\s*\\(\", \"Pickle deserialization\", SecurityIssueSeverity.MEDIUM),\n\n    # Code execution\n    SecurityPattern(r\"\\b(eval|exec|compile)\\s*\\(\", \"Code execution\", SecurityIssueSeverity.HIGH)\n]\n\n# Python-specific restricted modules\npython_modules = [\n    RestrictedModule(\"os\", \"Operating system interface\", SecurityIssueSeverity.HIGH),\n    RestrictedModule(\"subprocess\", \"Process execution\", SecurityIssueSeverity.HIGH),\n    RestrictedModule(\"ctypes\", \"Foreign function library\", SecurityIssueSeverity.HIGH),\n    RestrictedModule(\"importlib\", \"Dynamic imports\", SecurityIssueSeverity.MEDIUM)\n]\n</code></pre>"},{"location":"security/#javascriptnodejs-security-patterns","title":"JavaScript/Node.js Security Patterns","text":"<pre><code># JavaScript-specific patterns (when lang=\"javascript\")\njs_patterns = [\n    # Process access\n    SecurityPattern(r\"process\\.exit\\s*\\(\", \"Process termination\", SecurityIssueSeverity.HIGH),\n\n    # Child processes\n    SecurityPattern(r\"child_process\", \"Child process access\", SecurityIssueSeverity.HIGH),\n\n    # File system\n    SecurityPattern(r\"fs\\.(writeFile|unlink)\\s*\\(\", \"File system operations\", SecurityIssueSeverity.MEDIUM)\n]\n\n# JavaScript-specific restricted modules\njs_modules = [\n    RestrictedModule(\"fs\", \"File system access\", SecurityIssueSeverity.MEDIUM),\n    RestrictedModule(\"child_process\", \"Process execution\", SecurityIssueSeverity.HIGH),\n    RestrictedModule(\"cluster\", \"Process clustering\", SecurityIssueSeverity.HIGH)\n]\n</code></pre> <p>Note: Security presets (like <code>get_security_policy(\"production\")</code>) will be introduced in future versions and will be language-specific to provide appropriate defaults for each programming language.</p>"},{"location":"security/#advanced-pattern-examples","title":"Advanced Pattern Examples","text":""},{"location":"security/#network-security-patterns","title":"Network Security Patterns","text":"<pre><code># Monitor and control network operations\nnetwork_patterns = [\n    SecurityPattern(\n        pattern=r\"\\bsocket\\.socket\\s*\\(\",\n        description=\"Raw socket creation\",\n        severity=SecurityIssueSeverity.MEDIUM\n    ),\n    SecurityPattern(\n        pattern=r\"\\b\\w+\\.connect\\s*\\(\",\n        description=\"Network connections\",\n        severity=SecurityIssueSeverity.MEDIUM\n    ),\n    SecurityPattern(\n        pattern=r\"requests\\.(get|post|put|delete)\\s*\\(\",\n        description=\"HTTP requests\",\n        severity=SecurityIssueSeverity.LOW\n    )\n]\n</code></pre>"},{"location":"security/#file-system-security-patterns","title":"File System Security Patterns","text":"<pre><code># File system operation patterns\nfile_patterns = [\n    SecurityPattern(\n        pattern=r\"\\bopen\\s*\\([^)]*['\\\"][wa]['\\\"][^)]*\\)\",\n        description=\"File write operations\",\n        severity=SecurityIssueSeverity.MEDIUM\n    ),\n    SecurityPattern(\n        pattern=r\"\\bos\\.(remove|unlink|rmdir)\\s*\\(\",\n        description=\"File deletion operations\",\n        severity=SecurityIssueSeverity.HIGH\n    ),\n    SecurityPattern(\n        pattern=r\"\\bshutil\\.(rmtree|move|copy)\\s*\\(\",\n        description=\"File system manipulation\",\n        severity=SecurityIssueSeverity.MEDIUM\n    )\n]\n</code></pre>"},{"location":"security/#security-implementation-details","title":"Security Implementation Details","text":""},{"location":"security/#comment-filtering","title":"Comment Filtering","text":"<p>The security scanner filters comments to avoid false positives:</p> <pre><code># This comment won't trigger security alerts: import os\nprint(\"This string mentioning 'os.system' won't trigger alerts either\")\n\n# But this will be detected:\nimport os\nos.system('whoami')\n</code></pre>"},{"location":"security/#pattern-matching-process","title":"Pattern Matching Process","text":"<ol> <li>Filter Comments: Remove comments using language-specific handlers</li> <li>Generate Module Patterns: Convert restricted modules to regex patterns via language handlers</li> <li>Apply Patterns: Match all patterns against filtered code</li> <li>Severity Check: Apply severity threshold to determine blocking</li> <li>Return Results: Report safety status and violations</li> </ol>"},{"location":"security/#example-workflow","title":"Example Workflow","text":"<pre><code># Code to analyze\ncode = \"\"\"\nimport os  # This imports the OS module\n# os.system('commented out') - this won't be detected\nos.system('whoami')  # This will be detected\n\"\"\"\n\n# Policy with os module restricted\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    restricted_modules=[\n        RestrictedModule(\"os\", \"OS interface\", SecurityIssueSeverity.HIGH)\n    ],\n    patterns=[\n        SecurityPattern(r\"os\\.system\\s*\\(\", \"System commands\", SecurityIssueSeverity.HIGH)\n    ]\n)\n\n# Analysis process:\n# 1. Filter comments -&gt; \"import os\\nos.system('whoami')\"\n# 2. Language handler generates pattern for \"os\" import -&gt; VIOLATION (HIGH)\n# 3. Check os.system pattern -&gt; VIOLATION (HIGH)\n# 4. Result: is_safe=False, violations=[2]\n</code></pre>"},{"location":"security/#best-practices","title":"Best Practices","text":""},{"location":"security/#1-layer-security-policies-with-container-controls","title":"1. Layer Security Policies with Container Controls","text":"<pre><code># Combine security policy with container restrictions\nwith SandboxSession(\n    lang=\"python\",\n    # Code analysis layer\n    security_policy=custom_policy,\n    # Container restriction layer (see Configuration Guide)\n    runtime_configs={\n        \"mem_limit\": \"256m\",\n        \"cpu_count\": 1,\n        \"timeout\": 30,\n        \"user\": \"nobody:nogroup\"\n    }\n) as session:\n    # Double protection: policy blocks + container limits\n    pass\n</code></pre>"},{"location":"security/#2-use-language-appropriate-restrictions","title":"2. Use Language-Appropriate Restrictions","text":"<pre><code># Python-focused restrictions\npython_policy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    restricted_modules=[\n        RestrictedModule(\"os\", \"Operating system\", SecurityIssueSeverity.HIGH),\n        RestrictedModule(\"subprocess\", \"Process execution\", SecurityIssueSeverity.HIGH),\n        RestrictedModule(\"ctypes\", \"Foreign functions\", SecurityIssueSeverity.HIGH),\n        RestrictedModule(\"importlib\", \"Dynamic imports\", SecurityIssueSeverity.MEDIUM),\n        RestrictedModule(\"pickle\", \"Serialization\", SecurityIssueSeverity.MEDIUM)\n    ]\n)\n\n# JavaScript-focused restrictions (when available)\njavascript_policy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    restricted_modules=[\n        RestrictedModule(\"fs\", \"File system\", SecurityIssueSeverity.MEDIUM),\n        RestrictedModule(\"child_process\", \"Process execution\", SecurityIssueSeverity.HIGH),\n        RestrictedModule(\"cluster\", \"Process clustering\", SecurityIssueSeverity.HIGH),\n        RestrictedModule(\"worker_threads\", \"Threading\", SecurityIssueSeverity.MEDIUM)\n    ]\n)\n</code></pre>"},{"location":"security/#3-test-security-policies","title":"3. Test Security Policies","text":"<pre><code>def test_security_policy(policy: SecurityPolicy, lang: str = \"python\"):\n    \"\"\"Test security policy effectiveness\"\"\"\n    test_cases = [\n        # Should pass\n        (\"print('Hello')\", True),\n        (\"x = 1 + 2\", True),\n\n        # Should fail based on restricted modules\n        (\"import os; os.system('ls')\", False),\n        (\"eval('malicious_code')\", False),\n\n        # Edge cases\n        (\"# import os\", True),  # Comment\n        (\"'import os in string'\", True),  # String literal\n    ]\n\n    with SandboxSession(lang=lang, security_policy=policy) as session:\n        for code, expected_safe in test_cases:\n            is_safe, _ = session.is_safe(code)\n            assert is_safe == expected_safe, f\"Failed for: {code}\"\n</code></pre>"},{"location":"security/#4-monitor-and-log-security-events","title":"4. Monitor and Log Security Events","text":"<pre><code>import logging\nimport hashlib\nfrom datetime import datetime\n\nclass SecurityAuditor:\n    def __init__(self):\n        self.logger = logging.getLogger('security_audit')\n\n    def audit_execution(self, code: str, user_id: str, is_safe: bool, violations: list):\n        \"\"\"Log security events for monitoring\"\"\"\n        audit_entry = {\n            'timestamp': datetime.utcnow().isoformat(),\n            'user_id': user_id,\n            'code_hash': hashlib.sha256(code.encode()).hexdigest(),\n            'code_length': len(code),\n            'is_safe': is_safe,\n            'violations': [v.description for v in violations]\n        }\n\n        if violations:\n            self.logger.warning(f\"Security violations detected: {audit_entry}\")\n        else:\n            self.logger.info(f\"Safe code execution: {audit_entry}\")\n\n# Usage\nauditor = SecurityAuditor()\npolicy = SecurityPolicy(\n    severity_threshold=SecurityIssueSeverity.MEDIUM,\n    restricted_modules=[\n        RestrictedModule(\"os\", \"Operating system\", SecurityIssueSeverity.HIGH)\n    ]\n)\n\nwith SandboxSession(lang=\"python\", security_policy=policy) as session:\n    is_safe, violations = session.is_safe(user_code)\n    auditor.audit_execution(user_code, user_id, is_safe, violations)\n\n    if is_safe:\n        result = session.run(user_code)\n</code></pre>"},{"location":"security/#5-handle-security-violations-gracefully","title":"5. Handle Security Violations Gracefully","text":"<pre><code>class SecurityViolationError(Exception):\n    def __init__(self, violations: list):\n        self.violations = violations\n        super().__init__(f\"Security policy violations: {[v.description for v in violations]}\")\n\ndef safe_execute(code: str, user_id: str, lang: str = \"python\") -&gt; ExecutionResult:\n    \"\"\"Execute code with comprehensive security handling\"\"\"\n\n    # Input validation\n    if len(code) &gt; 50000:  # 50KB limit\n        raise ValueError(\"Code too long\")\n\n    if '\\x00' in code:\n        raise ValueError(\"Invalid null bytes in code\")\n\n    # Security check\n    policy = SecurityPolicy(\n        severity_threshold=SecurityIssueSeverity.MEDIUM,\n        restricted_modules=[\n            RestrictedModule(\"os\", \"Operating system\", SecurityIssueSeverity.HIGH),\n            RestrictedModule(\"subprocess\", \"Process execution\", SecurityIssueSeverity.HIGH)\n        ]\n    )\n\n    with SandboxSession(lang=lang, security_policy=policy) as session:\n        is_safe, violations = session.is_safe(code)\n\n        if not is_safe:\n            # Log security violation\n            logging.warning(f\"Security violation by user {user_id}: {[v.description for v in violations]}\")\n            raise SecurityViolationError(violations)\n\n        # Execute safely\n        try:\n            result = session.run(code)\n            logging.info(f\"Successful execution by user {user_id}\")\n            return result\n        except Exception as e:\n            logging.error(f\"Execution error for user {user_id}: {e}\")\n            raise\n</code></pre>"},{"location":"security/#troubleshooting","title":"Troubleshooting","text":""},{"location":"security/#common-issues","title":"Common Issues","text":""},{"location":"security/#false-positives-in-stringscomments","title":"False Positives in Strings/Comments","text":"<pre><code># Problem: Security scanner detects patterns in strings\ncode = 'print(\"Use os.system() carefully\")'  # May be blocked\n\n# Solution: The scanner automatically filters comments and should handle strings\n# If issues persist, adjust patterns to be more specific\n</code></pre>"},{"location":"security/#import-detection-edge-cases","title":"Import Detection Edge Cases","text":"<pre><code># Detected patterns (via language handler):\nimport os                    # \u2713 Detected\nfrom os import system        # \u2713 Detected\nimport os as operating_sys   # \u2713 Detected\n\n# May not be detected (advanced evasion):\n__import__('os')             # Depends on dynamic import patterns\nimportlib.import_module('os') # Requires specific patterns\n</code></pre>"},{"location":"security/#performance-with-large-codebases","title":"Performance with Large Codebases","text":"<pre><code># For very large code files, consider:\n# 1. Setting reasonable size limits\n# 2. Using more specific patterns\n# 3. Implementing caching for repeated analysis\n</code></pre>"},{"location":"security/#debugging-security-policies","title":"Debugging Security Policies","text":"<pre><code># Enable verbose logging to understand policy behavior\nimport logging\nlogging.getLogger('llm_sandbox').setLevel(logging.DEBUG)\n\n# Test individual patterns\npattern = SecurityPattern(r\"os\\.system\\s*\\(\", \"Test\", SecurityIssueSeverity.HIGH)\ntest_code = \"os.system('test')\"\n\nimport re\nif re.search(pattern.pattern, test_code):\n    print(f\"Pattern matches: {pattern.description}\")\n</code></pre>"},{"location":"security/#api-reference","title":"API Reference","text":"<p>For complete API documentation, see:</p> <ul> <li>Docker: docker-py documentation</li> <li>Podman: podman-py documentation</li> <li>Kubernetes: kubernetes-client documentation</li> </ul> <p>For container-level security configuration (resource limits, network controls, file system restrictions), see the Configuration Guide.</p>"}]}